{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@timestamp</th>\n",
       "      <th>system.cpu.user.pct</th>\n",
       "      <th>system.cpu.system.pct</th>\n",
       "      <th>system.cpu.idle.pct</th>\n",
       "      <th>system.cpu.iowait.pct</th>\n",
       "      <th>system.cpu.softirq.pct</th>\n",
       "      <th>system.cpu.total.pct</th>\n",
       "      <th>system.memory.used.pct</th>\n",
       "      <th>system.network.in.bytes</th>\n",
       "      <th>system.network.in.packets</th>\n",
       "      <th>system.network.in.dropped</th>\n",
       "      <th>system.network.out.bytes</th>\n",
       "      <th>system.network.out.packets</th>\n",
       "      <th>system.network.out.errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>3.1702</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>13038</td>\n",
       "      <td>1</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>12179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:00:10</td>\n",
       "      <td>0.6695</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>3.2410</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>13178</td>\n",
       "      <td>1</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>12232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:00:20</td>\n",
       "      <td>0.5851</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>3.3162</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>12945</td>\n",
       "      <td>1</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>12161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:00:30</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>3.3552</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.6448</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>13850</td>\n",
       "      <td>1</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>12750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:00:40</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>3.2926</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>12838</td>\n",
       "      <td>0</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>11985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45481</th>\n",
       "      <td>2018-01-01 16:31:10</td>\n",
       "      <td>0.2491</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>3.6916</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>6924</td>\n",
       "      <td>1</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>7347</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45482</th>\n",
       "      <td>2018-01-01 16:31:20</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>3.7182</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>7967</td>\n",
       "      <td>0</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>8275</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45483</th>\n",
       "      <td>2018-01-01 16:31:30</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>3.7020</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>6603</td>\n",
       "      <td>1</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>7238</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45484</th>\n",
       "      <td>2018-01-01 16:31:40</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>3.7211</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.2789</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>6934</td>\n",
       "      <td>1</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>7315</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45485</th>\n",
       "      <td>2018-01-01 16:31:50</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>3.5800</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>8835</td>\n",
       "      <td>0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>9187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45486 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                @timestamp  system.cpu.user.pct  system.cpu.system.pct  \\\n",
       "0      2018-01-01 00:00:00               0.7110                 0.0675   \n",
       "1      2018-01-01 00:00:10               0.6695                 0.0633   \n",
       "2      2018-01-01 00:00:20               0.5851                 0.0755   \n",
       "3      2018-01-01 00:00:30               0.5350                 0.0836   \n",
       "4      2018-01-01 00:00:40               0.6239                 0.0584   \n",
       "...                    ...                  ...                    ...   \n",
       "45481  2018-01-01 16:31:10               0.2491                 0.0472   \n",
       "45482  2018-01-01 16:31:20               0.2162                 0.0535   \n",
       "45483  2018-01-01 16:31:30               0.2237                 0.0582   \n",
       "45484  2018-01-01 16:31:40               0.2142                 0.0515   \n",
       "45485  2018-01-01 16:31:50               0.3366                 0.0643   \n",
       "\n",
       "       system.cpu.idle.pct  system.cpu.iowait.pct  system.cpu.softirq.pct  \\\n",
       "0                   3.1702                 0.0302                  0.0211   \n",
       "1                   3.2410                 0.0101                  0.0161   \n",
       "2                   3.3162                 0.0020                  0.0211   \n",
       "3                   3.3552                 0.0050                  0.0212   \n",
       "4                   3.2926                 0.0040                  0.0211   \n",
       "...                    ...                    ...                     ...   \n",
       "45481               3.6916                 0.0030                  0.0090   \n",
       "45482               3.7182                 0.0030                  0.0091   \n",
       "45483               3.7020                 0.0050                  0.0110   \n",
       "45484               3.7211                 0.0051                  0.0081   \n",
       "45485               3.5800                 0.0040                  0.0151   \n",
       "\n",
       "       system.cpu.total.pct  system.memory.used.pct  system.network.in.bytes  \\\n",
       "0                    0.8298                  0.8429                3000000.0   \n",
       "1                    0.7590                  0.8471                3000000.0   \n",
       "2                    0.6838                  0.8489                4000000.0   \n",
       "3                    0.6448                  0.8547                3000000.0   \n",
       "4                    0.7074                  0.8558                3000000.0   \n",
       "...                     ...                     ...                      ...   \n",
       "45481                0.3084                  0.9683                4000000.0   \n",
       "45482                0.2818                  0.9683                3000000.0   \n",
       "45483                0.2980                  0.9685                4000000.0   \n",
       "45484                0.2789                  0.9686                4000000.0   \n",
       "45485                0.4200                  0.9658                4000000.0   \n",
       "\n",
       "       system.network.in.packets  system.network.in.dropped  \\\n",
       "0                          13038                          1   \n",
       "1                          13178                          1   \n",
       "2                          12945                          1   \n",
       "3                          13850                          1   \n",
       "4                          12838                          0   \n",
       "...                          ...                        ...   \n",
       "45481                       6924                          1   \n",
       "45482                       7967                          0   \n",
       "45483                       6603                          1   \n",
       "45484                       6934                          1   \n",
       "45485                       8835                          0   \n",
       "\n",
       "       system.network.out.bytes  system.network.out.packets  \\\n",
       "0                     3000000.0                       12179   \n",
       "1                     4000000.0                       12232   \n",
       "2                     3000000.0                       12161   \n",
       "3                     3000000.0                       12750   \n",
       "4                     4000000.0                       11985   \n",
       "...                         ...                         ...   \n",
       "45481                 4000000.0                        7347   \n",
       "45482                 4000000.0                        8275   \n",
       "45483                 4000000.0                        7238   \n",
       "45484                 4000000.0                        7315   \n",
       "45485                 3000000.0                        9187   \n",
       "\n",
       "       system.network.out.errors  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "45481                          7  \n",
       "45482                          7  \n",
       "45483                          2  \n",
       "45484                          9  \n",
       "45485                          1  \n",
       "\n",
       "[45486 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scenarios = [1,2,6,7,8,10,11]\n",
    "#scenarios = [1]\n",
    "names = ['cpu', 'memory', 'network_io']\n",
    "all_data = pd.DataFrame()\n",
    "for name in names:\n",
    "    labels = []\n",
    "    sce_data = pd.DataFrame()\n",
    "    for sce in scenarios:\n",
    "        if sce != 11:\n",
    "            normal_data = pd.read_csv('./normal_datasets/part_'+str(sce)+'/'+name+'_parameters.csv')\n",
    "            sce_data = pd.concat([sce_data, normal_data], ignore_index=True)\n",
    "            abnormal_data = pd.read_csv('./anomalous_datasets/scenario_'+str(sce)+'/'+name +'_parameters.csv')\n",
    "            sce_data = pd.concat([sce_data, abnormal_data], ignore_index=True)\n",
    "            labels += [0]*len(normal_data)\n",
    "            labels += [1]*len(abnormal_data)\n",
    "        else:\n",
    "            normal_data = pd.read_csv('./normal_datasets/part_'+str(sce)+'/'+name+'_parameters.csv')\n",
    "            sce_data = pd.concat([sce_data, normal_data], ignore_index=True)\n",
    "            labels += [0]*len(normal_data)\n",
    "    if name == 'cpu':\n",
    "        all_data = pd.concat([all_data, sce_data], axis=1)\n",
    "    else:\n",
    "        all_data = pd.concat([all_data, sce_data.iloc[:,1:]], axis=1)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data.iloc[:,1:]\n",
    "labels = pd.DataFrame(labels, columns=['label'])\n",
    "test_data_label = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145065</td>\n",
       "      <td>0.052808</td>\n",
       "      <td>0.839834</td>\n",
       "      <td>0.029801</td>\n",
       "      <td>0.696370</td>\n",
       "      <td>0.160166</td>\n",
       "      <td>0.251708</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.863835</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.877829</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133912</td>\n",
       "      <td>0.049370</td>\n",
       "      <td>0.858825</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0.531353</td>\n",
       "      <td>0.141175</td>\n",
       "      <td>0.275626</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.873112</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.881649</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111231</td>\n",
       "      <td>0.059358</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.696370</td>\n",
       "      <td>0.121003</td>\n",
       "      <td>0.285877</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.857673</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.876532</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097767</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>0.889458</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.699670</td>\n",
       "      <td>0.110542</td>\n",
       "      <td>0.318907</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.917638</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.918985</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121658</td>\n",
       "      <td>0.045358</td>\n",
       "      <td>0.872666</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.696370</td>\n",
       "      <td>0.127334</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.850583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.863846</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45481</th>\n",
       "      <td>0.020935</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>0.979694</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.965831</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.458720</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.529552</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45482</th>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.041346</td>\n",
       "      <td>0.986829</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.300330</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.965831</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.527829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.596439</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45483</th>\n",
       "      <td>0.014109</td>\n",
       "      <td>0.045194</td>\n",
       "      <td>0.982484</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.363036</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>0.966970</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.437450</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.521695</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45484</th>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.039709</td>\n",
       "      <td>0.987607</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>0.967540</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.459382</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527245</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45485</th>\n",
       "      <td>0.044449</td>\n",
       "      <td>0.050188</td>\n",
       "      <td>0.949759</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.498350</td>\n",
       "      <td>0.050241</td>\n",
       "      <td>0.951595</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.585343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.662174</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45486 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.145065  0.052808  0.839834  0.029801  0.696370  0.160166  0.251708   \n",
       "1      0.133912  0.049370  0.858825  0.009966  0.531353  0.141175  0.275626   \n",
       "2      0.111231  0.059358  0.878997  0.001974  0.696370  0.121003  0.285877   \n",
       "3      0.097767  0.065990  0.889458  0.004934  0.699670  0.110542  0.318907   \n",
       "4      0.121658  0.045358  0.872666  0.003947  0.696370  0.127334  0.325171   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "45481  0.020935  0.036188  0.979694  0.002960  0.297030  0.020306  0.965831   \n",
       "45482  0.012093  0.041346  0.986829  0.002960  0.300330  0.013171  0.965831   \n",
       "45483  0.014109  0.045194  0.982484  0.004934  0.363036  0.017516  0.966970   \n",
       "45484  0.011556  0.039709  0.987607  0.005033  0.267327  0.012393  0.967540   \n",
       "45485  0.044449  0.050188  0.949759  0.003947  0.498350  0.050241  0.951595   \n",
       "\n",
       "             7         8         9         10        11    12  \n",
       "0      0.333333  0.863835  0.142857  0.500000  0.877829  0.00  \n",
       "1      0.333333  0.873112  0.142857  0.666667  0.881649  0.00  \n",
       "2      0.444444  0.857673  0.142857  0.500000  0.876532  0.00  \n",
       "3      0.333333  0.917638  0.142857  0.500000  0.918985  0.00  \n",
       "4      0.333333  0.850583  0.000000  0.666667  0.863846  0.00  \n",
       "...         ...       ...       ...       ...       ...   ...  \n",
       "45481  0.444444  0.458720  0.142857  0.666667  0.529552  0.28  \n",
       "45482  0.333333  0.527829  0.000000  0.666667  0.596439  0.28  \n",
       "45483  0.444444  0.437450  0.142857  0.666667  0.521695  0.08  \n",
       "45484  0.444444  0.459382  0.142857  0.666667  0.527245  0.36  \n",
       "45485  0.444444  0.585343  0.000000  0.500000  0.662174  0.04  \n",
       "\n",
       "[45486 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#normalized_train_data = pd.DataFrame(scaler.fit_transform(train_data))\n",
    "normalized_test_data = pd.DataFrame(scaler.fit_transform(train_data))\n",
    "normalized_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46895787 0.16285295 0.10883544 0.0843251  0.07487702 0.0511416 ]\n",
      "0.9509899744356802\n",
      "[61.08442294 35.99659062 29.4271855  25.90251847 24.40831699 20.17208076]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=6)\n",
    "#pca_train_data = pca.fit_transform(normalized_train_data)\n",
    "pca_test_data = pca.fit_transform(normalized_test_data)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "# supress warnings for clean output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from pyod.models.combination import aom, moa, average, maximization, majority_vote\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_labels(y_test, test_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, test_scores)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    pred_label = []\n",
    "    for each in test_scores:\n",
    "        if each > cutoff:\n",
    "            pred_label.append(1)\n",
    "        else:\n",
    "            pred_label.append(0)    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eval(label, pred_label, scores):\n",
    "    pr = round(metrics.precision_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    re = round(metrics.recall_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    f1 = round(metrics.f1_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    roc = round(roc_auc_score(label, scores), ndigits=4)\n",
    "    return pr,re,f1,roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca_test_data\n",
    "X_test = pca_test_data\n",
    "y_train = test_data_label\n",
    "y_test = test_data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base detector 1 is fitted for prediction\n",
      "Base detector 2 is fitted for prediction\n",
      "Base detector 3 is fitted for prediction\n",
      "Base detector 4 is fitted for prediction\n",
      "178.2644\n"
     ]
    }
   ],
   "source": [
    "outliers_fraction = np.count_nonzero(y_train) / len(y_train)\n",
    "outliers_percentage = round(outliers_fraction * 100, ndigits=4)\n",
    "    \n",
    "random_state = np.random.RandomState(42)\n",
    "classifiers = {\n",
    "        'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                    random_state=random_state),\n",
    "        'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "        'Local Outlier Factor (LOF)': LOF(\n",
    "            contamination=outliers_fraction),\n",
    "        'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction)\n",
    "    }\n",
    "\n",
    "n_clf = len(classifiers)\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
    "p_labels = np.zeros([X_test.shape[0], n_clf])\n",
    "\n",
    "i = 0\n",
    "train_duration = 0\n",
    "test_duration = 0\n",
    "for clf_name, clf in classifiers.items():\n",
    "    t0 = time()\n",
    "    clf.fit(X_train)\n",
    "    t1 = time()\n",
    "    test_sccore = clf.decision_function(X_test)\n",
    "    t_t = time()\n",
    "    test_mean_score = np.nanmean(test_scores)\n",
    "    test_scores[np.isnan(test_scores)] = test_mean_score\n",
    "    test_scores[:, i] = test_sccore\n",
    "    p_labels[:, i] = pred_labels(y_test, test_sccore)\n",
    "    i += 1\n",
    "    print('Base detector %i is fitted for prediction' % i)\n",
    "    train_duration += round(t1 - t0, ndigits=4)\n",
    "    test_duration += round(t_t - t1, ndigits=4)\n",
    "    \n",
    "# standardize test score\n",
    "test_scores_norm = standardizer(test_scores)\n",
    "print(train_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from time import time\n",
    "\n",
    "test_scores_norm = test_scores_norm.reshape((test_scores_norm.shape[0], test_scores_norm.shape[1], 1))\n",
    "train_x, test_x, train_y, test_y = train_test_split(test_scores_norm, y_test, test_size=0.9, random_state=random_state)\n",
    "#train_x, test_x, train_y, test_y = train_test_split(test_scores_norm[:,3], y_test, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ensemble_cnn():\n",
    "    df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "    enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    t2 = time()\n",
    "#     # Input - Layer\n",
    "#     model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(4, 1)))\n",
    "#     #model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(units=50, activation='relu', return_sequences=False))\n",
    "#     #model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(4,1)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    # compiling the model\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "      \n",
    "    results = model.fit(\n",
    "     train_x, train_y,\n",
    "     epochs= 100,\n",
    "     batch_size = 20,\n",
    "     validation_data = (train_x, train_y)\n",
    "    )\n",
    "    t3 = time()\n",
    "    #print(results.history['val_accuracy'])\n",
    "    #pred_test = model.predict(test_scores_norm[:,0]).reshape(len(test_scores_norm),1)\n",
    "    pred_test = model.predict(test_scores_norm)\n",
    "    #pred_test = model.predict(test_x)\n",
    "    t4 = time()\n",
    "    train_time = t3 - t2\n",
    "    test_time = t4 - t3\n",
    "    train_time_mlp =  round(train_duration+train_time, ndigits=4)\n",
    "    test_time_mlp = round(test_duration+test_time, ndigits=4)\n",
    "    \n",
    "    pred_nn = []\n",
    "    for each in pred_test:\n",
    "        if each[0] > 0.5:\n",
    "            pred_nn.append(1)\n",
    "        else:\n",
    "            pred_nn.append(0)\n",
    "    #pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(test_y, pred_nn, pred_test)\n",
    "    pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(y_test, pred_nn, pred_test)\n",
    "    enm_mlp = pd.DataFrame([pr_mlp, re_mlp, f1_mlp, roc_mlp, train_time_mlp, test_time_mlp]).transpose()\n",
    "    enm_mlp.columns = df_columns\n",
    "    enm_mlp_df = pd.concat([enm_mlp_df, enm_mlp], axis=0)\n",
    "    return enm_mlp_df, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 14:02:28.822625: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-26 14:02:29.059475: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "228/228 [==============================] - 16s 3ms/step - loss: 0.4299 - accuracy: 0.8868 - val_loss: 0.1958 - val_accuracy: 0.9367\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9431 - val_loss: 0.1633 - val_accuracy: 0.9415\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9470 - val_loss: 0.1560 - val_accuracy: 0.9446\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9508 - val_loss: 0.1511 - val_accuracy: 0.9521\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9545 - val_loss: 0.1513 - val_accuracy: 0.9534\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9511 - val_loss: 0.1477 - val_accuracy: 0.9516\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9587 - val_loss: 0.1459 - val_accuracy: 0.9545\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9566 - val_loss: 0.1458 - val_accuracy: 0.9556\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9606 - val_loss: 0.1448 - val_accuracy: 0.9549\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9583 - val_loss: 0.1436 - val_accuracy: 0.9551\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9471 - val_loss: 0.1423 - val_accuracy: 0.9558\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9516 - val_loss: 0.1417 - val_accuracy: 0.9565\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9562 - val_loss: 0.1408 - val_accuracy: 0.9558\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9521 - val_loss: 0.1412 - val_accuracy: 0.9547\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9574 - val_loss: 0.1402 - val_accuracy: 0.9547\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9556 - val_loss: 0.1395 - val_accuracy: 0.9558\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9549 - val_loss: 0.1400 - val_accuracy: 0.9554\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9569 - val_loss: 0.1394 - val_accuracy: 0.9551\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9514 - val_loss: 0.1380 - val_accuracy: 0.9573\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9551 - val_loss: 0.1382 - val_accuracy: 0.9571\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9609 - val_loss: 0.1374 - val_accuracy: 0.9571\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9534 - val_loss: 0.1401 - val_accuracy: 0.9573\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9551 - val_loss: 0.1385 - val_accuracy: 0.9582\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9535 - val_loss: 0.1369 - val_accuracy: 0.9558\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9580 - val_loss: 0.1374 - val_accuracy: 0.9576\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9550 - val_loss: 0.1378 - val_accuracy: 0.9576\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9602 - val_loss: 0.1366 - val_accuracy: 0.9562\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9550 - val_loss: 0.1360 - val_accuracy: 0.9562\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9492 - val_loss: 0.1366 - val_accuracy: 0.9565\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9596 - val_loss: 0.1375 - val_accuracy: 0.9556\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9523 - val_loss: 0.1352 - val_accuracy: 0.9578\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9588 - val_loss: 0.1342 - val_accuracy: 0.9565\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9647 - val_loss: 0.1337 - val_accuracy: 0.9587\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9588 - val_loss: 0.1369 - val_accuracy: 0.9562\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9528 - val_loss: 0.1348 - val_accuracy: 0.9584\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9535 - val_loss: 0.1329 - val_accuracy: 0.9589\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9617 - val_loss: 0.1323 - val_accuracy: 0.9580\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9569 - val_loss: 0.1323 - val_accuracy: 0.9591\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9582 - val_loss: 0.1337 - val_accuracy: 0.9582\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9612 - val_loss: 0.1332 - val_accuracy: 0.9591\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9592 - val_loss: 0.1320 - val_accuracy: 0.9602\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9560 - val_loss: 0.1327 - val_accuracy: 0.9593\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9619 - val_loss: 0.1324 - val_accuracy: 0.9595\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9600 - val_loss: 0.1311 - val_accuracy: 0.9595\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9665 - val_loss: 0.1319 - val_accuracy: 0.9600\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9619 - val_loss: 0.1308 - val_accuracy: 0.9606\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9596 - val_loss: 0.1304 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9548 - val_loss: 0.1307 - val_accuracy: 0.9595\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9571 - val_loss: 0.1309 - val_accuracy: 0.9617\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9548 - val_loss: 0.1324 - val_accuracy: 0.9602\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9607 - val_loss: 0.1315 - val_accuracy: 0.9606\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9662 - val_loss: 0.1297 - val_accuracy: 0.9613\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9623 - val_loss: 0.1305 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9682 - val_loss: 0.1306 - val_accuracy: 0.9606\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9609 - val_loss: 0.1309 - val_accuracy: 0.9606\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9642 - val_loss: 0.1300 - val_accuracy: 0.9606\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9606 - val_loss: 0.1297 - val_accuracy: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9584 - val_loss: 0.1294 - val_accuracy: 0.9606\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9558 - val_loss: 0.1304 - val_accuracy: 0.9620\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9590 - val_loss: 0.1297 - val_accuracy: 0.9606\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9581 - val_loss: 0.1288 - val_accuracy: 0.9615\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9590 - val_loss: 0.1284 - val_accuracy: 0.9622\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9619 - val_loss: 0.1285 - val_accuracy: 0.9613\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9603 - val_loss: 0.1345 - val_accuracy: 0.9569\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9630 - val_loss: 0.1290 - val_accuracy: 0.9631\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9645 - val_loss: 0.1285 - val_accuracy: 0.9628\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9603 - val_loss: 0.1286 - val_accuracy: 0.9631\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9633 - val_loss: 0.1291 - val_accuracy: 0.9620\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9651 - val_loss: 0.1289 - val_accuracy: 0.9606\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9619 - val_loss: 0.1277 - val_accuracy: 0.9631\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9606 - val_loss: 0.1286 - val_accuracy: 0.9617\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9601 - val_loss: 0.1292 - val_accuracy: 0.9620\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9612 - val_loss: 0.1286 - val_accuracy: 0.9617\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9648 - val_loss: 0.1282 - val_accuracy: 0.9617\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9615 - val_loss: 0.1280 - val_accuracy: 0.9611\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9636 - val_loss: 0.1267 - val_accuracy: 0.9626\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9603 - val_loss: 0.1301 - val_accuracy: 0.9595\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9620 - val_loss: 0.1273 - val_accuracy: 0.9615\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9593 - val_loss: 0.1276 - val_accuracy: 0.9609\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9633 - val_loss: 0.1269 - val_accuracy: 0.9622\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9666 - val_loss: 0.1271 - val_accuracy: 0.9624\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9566 - val_loss: 0.1262 - val_accuracy: 0.9633\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9636 - val_loss: 0.1292 - val_accuracy: 0.9628\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9593 - val_loss: 0.1281 - val_accuracy: 0.9631\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9646 - val_loss: 0.1275 - val_accuracy: 0.9633\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9637 - val_loss: 0.1272 - val_accuracy: 0.9631\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9638 - val_loss: 0.1260 - val_accuracy: 0.9642\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9633 - val_loss: 0.1258 - val_accuracy: 0.9637\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9649 - val_loss: 0.1257 - val_accuracy: 0.9635\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9617 - val_loss: 0.1256 - val_accuracy: 0.9633\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9579 - val_loss: 0.1272 - val_accuracy: 0.9635\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9597 - val_loss: 0.1263 - val_accuracy: 0.9628\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9638 - val_loss: 0.1346 - val_accuracy: 0.9609\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9682 - val_loss: 0.1252 - val_accuracy: 0.9637\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9631 - val_loss: 0.1263 - val_accuracy: 0.9615\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9628 - val_loss: 0.1251 - val_accuracy: 0.9635\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9655 - val_loss: 0.1259 - val_accuracy: 0.9628\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9630 - val_loss: 0.1285 - val_accuracy: 0.9620\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9592 - val_loss: 0.1284 - val_accuracy: 0.9622\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9613 - val_loss: 0.1244 - val_accuracy: 0.9637\n",
      "1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8540 - val_loss: 0.1948 - val_accuracy: 0.9378\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9379 - val_loss: 0.1632 - val_accuracy: 0.9433\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9474 - val_loss: 0.1569 - val_accuracy: 0.9457\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9481 - val_loss: 0.1535 - val_accuracy: 0.9483\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9594 - val_loss: 0.1515 - val_accuracy: 0.9536\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9534 - val_loss: 0.1484 - val_accuracy: 0.9556\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9548 - val_loss: 0.1465 - val_accuracy: 0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9562 - val_loss: 0.1455 - val_accuracy: 0.9556\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9541 - val_loss: 0.1461 - val_accuracy: 0.9547\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9542 - val_loss: 0.1436 - val_accuracy: 0.9549\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9539 - val_loss: 0.1430 - val_accuracy: 0.9547\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9571 - val_loss: 0.1434 - val_accuracy: 0.9567\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9613 - val_loss: 0.1419 - val_accuracy: 0.9569\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9544 - val_loss: 0.1412 - val_accuracy: 0.9560\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9556 - val_loss: 0.1424 - val_accuracy: 0.9571\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9504 - val_loss: 0.1398 - val_accuracy: 0.9569\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9588 - val_loss: 0.1405 - val_accuracy: 0.9573\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9544 - val_loss: 0.1396 - val_accuracy: 0.9573\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9534 - val_loss: 0.1388 - val_accuracy: 0.9569\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9553 - val_loss: 0.1400 - val_accuracy: 0.9576\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9552 - val_loss: 0.1417 - val_accuracy: 0.9569\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9623 - val_loss: 0.1399 - val_accuracy: 0.9584\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9622 - val_loss: 0.1392 - val_accuracy: 0.9580\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9584 - val_loss: 0.1375 - val_accuracy: 0.9571\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9588 - val_loss: 0.1381 - val_accuracy: 0.9580\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9551 - val_loss: 0.1380 - val_accuracy: 0.9562\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9586 - val_loss: 0.1372 - val_accuracy: 0.9576\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9566 - val_loss: 0.1376 - val_accuracy: 0.9582\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9584 - val_loss: 0.1382 - val_accuracy: 0.9560\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9541 - val_loss: 0.1366 - val_accuracy: 0.9573\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9606 - val_loss: 0.1375 - val_accuracy: 0.9571\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9561 - val_loss: 0.1363 - val_accuracy: 0.9595\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9583 - val_loss: 0.1364 - val_accuracy: 0.9580\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9575 - val_loss: 0.1378 - val_accuracy: 0.9560\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9529 - val_loss: 0.1361 - val_accuracy: 0.9578\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9565 - val_loss: 0.1367 - val_accuracy: 0.9582\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9552 - val_loss: 0.1364 - val_accuracy: 0.9582\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9606 - val_loss: 0.1353 - val_accuracy: 0.9578\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9601 - val_loss: 0.1353 - val_accuracy: 0.9576\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9565 - val_loss: 0.1369 - val_accuracy: 0.9580\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9623 - val_loss: 0.1368 - val_accuracy: 0.9580\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9568 - val_loss: 0.1347 - val_accuracy: 0.9571\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9587 - val_loss: 0.1343 - val_accuracy: 0.9593\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9572 - val_loss: 0.1352 - val_accuracy: 0.9576\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9552 - val_loss: 0.1344 - val_accuracy: 0.9584\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9577 - val_loss: 0.1347 - val_accuracy: 0.9576\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9574 - val_loss: 0.1336 - val_accuracy: 0.9593\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9570 - val_loss: 0.1342 - val_accuracy: 0.9593\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9546 - val_loss: 0.1340 - val_accuracy: 0.9587\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9599 - val_loss: 0.1335 - val_accuracy: 0.9587\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9544 - val_loss: 0.1334 - val_accuracy: 0.9589\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9577 - val_loss: 0.1330 - val_accuracy: 0.9595\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9596 - val_loss: 0.1350 - val_accuracy: 0.9584\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9553 - val_loss: 0.1330 - val_accuracy: 0.9589\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9618 - val_loss: 0.1340 - val_accuracy: 0.9593\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9611 - val_loss: 0.1331 - val_accuracy: 0.9598\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9573 - val_loss: 0.1335 - val_accuracy: 0.9584\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9546 - val_loss: 0.1344 - val_accuracy: 0.9578\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9618 - val_loss: 0.1362 - val_accuracy: 0.9569\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9615 - val_loss: 0.1361 - val_accuracy: 0.9582\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9575 - val_loss: 0.1325 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9645 - val_loss: 0.1327 - val_accuracy: 0.9598\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9612 - val_loss: 0.1334 - val_accuracy: 0.9591\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.1329 - val_accuracy: 0.9589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9604 - val_loss: 0.1315 - val_accuracy: 0.9609\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9589 - val_loss: 0.1317 - val_accuracy: 0.9591\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9576 - val_loss: 0.1326 - val_accuracy: 0.9582\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9583 - val_loss: 0.1333 - val_accuracy: 0.9595\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9548 - val_loss: 0.1318 - val_accuracy: 0.9609\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9621 - val_loss: 0.1344 - val_accuracy: 0.9584\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1240 - accuracy: 0.9567 - val_loss: 0.1397 - val_accuracy: 0.9598\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9631 - val_loss: 0.1320 - val_accuracy: 0.9609\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9600 - val_loss: 0.1313 - val_accuracy: 0.9600\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9576 - val_loss: 0.1325 - val_accuracy: 0.9573\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9583 - val_loss: 0.1311 - val_accuracy: 0.9611\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9617 - val_loss: 0.1313 - val_accuracy: 0.9600\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9553 - val_loss: 0.1325 - val_accuracy: 0.9609\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9626 - val_loss: 0.1365 - val_accuracy: 0.9573\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9570 - val_loss: 0.1324 - val_accuracy: 0.9617\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9563 - val_loss: 0.1312 - val_accuracy: 0.9617\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9604 - val_loss: 0.1306 - val_accuracy: 0.9593\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9609 - val_loss: 0.1313 - val_accuracy: 0.9613\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9662 - val_loss: 0.1311 - val_accuracy: 0.9591\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9550 - val_loss: 0.1318 - val_accuracy: 0.9591\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9544 - val_loss: 0.1312 - val_accuracy: 0.9598\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9650 - val_loss: 0.1321 - val_accuracy: 0.9602\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9595 - val_loss: 0.1305 - val_accuracy: 0.9611\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9601 - val_loss: 0.1336 - val_accuracy: 0.9562\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9579 - val_loss: 0.1305 - val_accuracy: 0.9615\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9628 - val_loss: 0.1319 - val_accuracy: 0.9589\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9627 - val_loss: 0.1301 - val_accuracy: 0.9615\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9628 - val_loss: 0.1299 - val_accuracy: 0.9595\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9597 - val_loss: 0.1305 - val_accuracy: 0.9615\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9626 - val_loss: 0.1297 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9544 - val_loss: 0.1298 - val_accuracy: 0.9615\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9580 - val_loss: 0.1296 - val_accuracy: 0.9602\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9546 - val_loss: 0.1313 - val_accuracy: 0.9622\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9595 - val_loss: 0.1301 - val_accuracy: 0.9595\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9571 - val_loss: 0.1309 - val_accuracy: 0.9582\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9566 - val_loss: 0.1297 - val_accuracy: 0.9615\n",
      "2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.4140 - accuracy: 0.9312 - val_loss: 0.1916 - val_accuracy: 0.9356\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9375 - val_loss: 0.1614 - val_accuracy: 0.9420\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9430 - val_loss: 0.1534 - val_accuracy: 0.9507\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9560 - val_loss: 0.1504 - val_accuracy: 0.9527\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9528 - val_loss: 0.1494 - val_accuracy: 0.9532\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9534 - val_loss: 0.1462 - val_accuracy: 0.9545\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9589 - val_loss: 0.1452 - val_accuracy: 0.9562\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9521 - val_loss: 0.1442 - val_accuracy: 0.9554\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9570 - val_loss: 0.1431 - val_accuracy: 0.9558\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9517 - val_loss: 0.1443 - val_accuracy: 0.9543\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9490 - val_loss: 0.1448 - val_accuracy: 0.9538\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9526 - val_loss: 0.1426 - val_accuracy: 0.9573\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9573 - val_loss: 0.1415 - val_accuracy: 0.9549\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9592 - val_loss: 0.1401 - val_accuracy: 0.9565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9565 - val_loss: 0.1407 - val_accuracy: 0.9551\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9506 - val_loss: 0.1428 - val_accuracy: 0.9536\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9580 - val_loss: 0.1403 - val_accuracy: 0.9554\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9553 - val_loss: 0.1393 - val_accuracy: 0.9576\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9615 - val_loss: 0.1395 - val_accuracy: 0.9560\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9543 - val_loss: 0.1388 - val_accuracy: 0.9576\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9500 - val_loss: 0.1410 - val_accuracy: 0.9556\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9550 - val_loss: 0.1403 - val_accuracy: 0.9573\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9518 - val_loss: 0.1380 - val_accuracy: 0.9571\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9597 - val_loss: 0.1395 - val_accuracy: 0.9571\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9635 - val_loss: 0.1375 - val_accuracy: 0.9567\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9579 - val_loss: 0.1378 - val_accuracy: 0.9584\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9532 - val_loss: 0.1368 - val_accuracy: 0.9580\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9584 - val_loss: 0.1369 - val_accuracy: 0.9567\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9536 - val_loss: 0.1369 - val_accuracy: 0.9576\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9604 - val_loss: 0.1365 - val_accuracy: 0.9573\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9542 - val_loss: 0.1371 - val_accuracy: 0.9571\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9535 - val_loss: 0.1361 - val_accuracy: 0.9571\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9565 - val_loss: 0.1358 - val_accuracy: 0.9571\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9609 - val_loss: 0.1376 - val_accuracy: 0.9560\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9572 - val_loss: 0.1359 - val_accuracy: 0.9573\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9591 - val_loss: 0.1354 - val_accuracy: 0.9578\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9573 - val_loss: 0.1352 - val_accuracy: 0.9569\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9564 - val_loss: 0.1347 - val_accuracy: 0.9578\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9634 - val_loss: 0.1352 - val_accuracy: 0.9578\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9531 - val_loss: 0.1350 - val_accuracy: 0.9576\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9610 - val_loss: 0.1357 - val_accuracy: 0.9578\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9576 - val_loss: 0.1343 - val_accuracy: 0.9578\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9619 - val_loss: 0.1346 - val_accuracy: 0.9582\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9559 - val_loss: 0.1343 - val_accuracy: 0.9571\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9546 - val_loss: 0.1337 - val_accuracy: 0.9571\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9528 - val_loss: 0.1341 - val_accuracy: 0.9573\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9586 - val_loss: 0.1337 - val_accuracy: 0.9582\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9606 - val_loss: 0.1339 - val_accuracy: 0.9573\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9571 - val_loss: 0.1350 - val_accuracy: 0.9571\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9537 - val_loss: 0.1364 - val_accuracy: 0.9584\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9535 - val_loss: 0.1340 - val_accuracy: 0.9584\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9621 - val_loss: 0.1329 - val_accuracy: 0.9587\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9524 - val_loss: 0.1340 - val_accuracy: 0.9578\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9552 - val_loss: 0.1346 - val_accuracy: 0.9573\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9583 - val_loss: 0.1325 - val_accuracy: 0.9576\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9562 - val_loss: 0.1331 - val_accuracy: 0.9576\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9506 - val_loss: 0.1341 - val_accuracy: 0.9580\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9545 - val_loss: 0.1334 - val_accuracy: 0.9573\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9600 - val_loss: 0.1338 - val_accuracy: 0.9576\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9564 - val_loss: 0.1316 - val_accuracy: 0.9578\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9501 - val_loss: 0.1324 - val_accuracy: 0.9571\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9552 - val_loss: 0.1323 - val_accuracy: 0.9587\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9632 - val_loss: 0.1320 - val_accuracy: 0.9573\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1335 - val_accuracy: 0.9580\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9538 - val_loss: 0.1330 - val_accuracy: 0.9578\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9545 - val_loss: 0.1324 - val_accuracy: 0.9578\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9527 - val_loss: 0.1315 - val_accuracy: 0.9576\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9592 - val_loss: 0.1347 - val_accuracy: 0.9573\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9570 - val_loss: 0.1341 - val_accuracy: 0.9576\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9563 - val_loss: 0.1312 - val_accuracy: 0.9584\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9606 - val_loss: 0.1311 - val_accuracy: 0.9587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9588 - val_loss: 0.1330 - val_accuracy: 0.9576\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9596 - val_loss: 0.1309 - val_accuracy: 0.9584\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9612 - val_loss: 0.1317 - val_accuracy: 0.9587\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9533 - val_loss: 0.1301 - val_accuracy: 0.9584\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9533 - val_loss: 0.1300 - val_accuracy: 0.9591\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9577 - val_loss: 0.1304 - val_accuracy: 0.9578\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9580 - val_loss: 0.1307 - val_accuracy: 0.9576\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9593 - val_loss: 0.1305 - val_accuracy: 0.9589\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9572 - val_loss: 0.1303 - val_accuracy: 0.9589\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9606 - val_loss: 0.1304 - val_accuracy: 0.9587\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9579 - val_loss: 0.1317 - val_accuracy: 0.9598\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9620 - val_loss: 0.1322 - val_accuracy: 0.9578\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9510 - val_loss: 0.1302 - val_accuracy: 0.9593\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9563 - val_loss: 0.1296 - val_accuracy: 0.9584\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9604 - val_loss: 0.1315 - val_accuracy: 0.9578\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9621 - val_loss: 0.1293 - val_accuracy: 0.9595\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9624 - val_loss: 0.1302 - val_accuracy: 0.9589\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9596 - val_loss: 0.1288 - val_accuracy: 0.9584\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9590 - val_loss: 0.1286 - val_accuracy: 0.9595\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9587 - val_loss: 0.1286 - val_accuracy: 0.9591\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9567 - val_loss: 0.1299 - val_accuracy: 0.9589\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9558 - val_loss: 0.1295 - val_accuracy: 0.9591\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9558 - val_loss: 0.1306 - val_accuracy: 0.9587\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9590 - val_loss: 0.1287 - val_accuracy: 0.9591\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9590 - val_loss: 0.1300 - val_accuracy: 0.9595\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9597 - val_loss: 0.1291 - val_accuracy: 0.9589\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9618 - val_loss: 0.1287 - val_accuracy: 0.9598\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9566 - val_loss: 0.1292 - val_accuracy: 0.9591\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9587 - val_loss: 0.1281 - val_accuracy: 0.9595\n",
      "3\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.8682 - val_loss: 0.2042 - val_accuracy: 0.9316\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9340 - val_loss: 0.1664 - val_accuracy: 0.9402\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9305 - val_loss: 0.1569 - val_accuracy: 0.9442\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9490 - val_loss: 0.1514 - val_accuracy: 0.9538\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9594 - val_loss: 0.1493 - val_accuracy: 0.9512\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9575 - val_loss: 0.1484 - val_accuracy: 0.9518\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9544 - val_loss: 0.1481 - val_accuracy: 0.9523\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9567 - val_loss: 0.1470 - val_accuracy: 0.9556\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9550 - val_loss: 0.1443 - val_accuracy: 0.9545\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9561 - val_loss: 0.1433 - val_accuracy: 0.9567\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9550 - val_loss: 0.1424 - val_accuracy: 0.9571\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9555 - val_loss: 0.1413 - val_accuracy: 0.9567\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9547 - val_loss: 0.1414 - val_accuracy: 0.9558\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9555 - val_loss: 0.1406 - val_accuracy: 0.9554\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9615 - val_loss: 0.1406 - val_accuracy: 0.9549\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9543 - val_loss: 0.1395 - val_accuracy: 0.9567\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9562 - val_loss: 0.1412 - val_accuracy: 0.9587\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9581 - val_loss: 0.1384 - val_accuracy: 0.9576\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9595 - val_loss: 0.1380 - val_accuracy: 0.9584\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9587 - val_loss: 0.1379 - val_accuracy: 0.9569\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9627 - val_loss: 0.1394 - val_accuracy: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9567 - val_loss: 0.1377 - val_accuracy: 0.9573\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9579 - val_loss: 0.1380 - val_accuracy: 0.9589\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9595 - val_loss: 0.1377 - val_accuracy: 0.9576\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9618 - val_loss: 0.1380 - val_accuracy: 0.9582\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9543 - val_loss: 0.1374 - val_accuracy: 0.9569\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9622 - val_loss: 0.1367 - val_accuracy: 0.9584\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9554 - val_loss: 0.1363 - val_accuracy: 0.9580\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9588 - val_loss: 0.1353 - val_accuracy: 0.9593\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9589 - val_loss: 0.1350 - val_accuracy: 0.9571\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9567 - val_loss: 0.1351 - val_accuracy: 0.9589\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9552 - val_loss: 0.1359 - val_accuracy: 0.9580\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9542 - val_loss: 0.1359 - val_accuracy: 0.9589\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9610 - val_loss: 0.1357 - val_accuracy: 0.9595\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9578 - val_loss: 0.1362 - val_accuracy: 0.9573\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9536 - val_loss: 0.1372 - val_accuracy: 0.9565\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9588 - val_loss: 0.1339 - val_accuracy: 0.9582\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9601 - val_loss: 0.1351 - val_accuracy: 0.9589\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9549 - val_loss: 0.1337 - val_accuracy: 0.9587\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9535 - val_loss: 0.1348 - val_accuracy: 0.9569\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9624 - val_loss: 0.1326 - val_accuracy: 0.9595\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9590 - val_loss: 0.1327 - val_accuracy: 0.9595\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9589 - val_loss: 0.1342 - val_accuracy: 0.9591\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9595 - val_loss: 0.1323 - val_accuracy: 0.9615\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9624 - val_loss: 0.1326 - val_accuracy: 0.9589\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9569 - val_loss: 0.1333 - val_accuracy: 0.9580\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9583 - val_loss: 0.1316 - val_accuracy: 0.9589\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9596 - val_loss: 0.1321 - val_accuracy: 0.9584\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9581 - val_loss: 0.1315 - val_accuracy: 0.9595\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9572 - val_loss: 0.1303 - val_accuracy: 0.9613\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9583 - val_loss: 0.1348 - val_accuracy: 0.9549\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9570 - val_loss: 0.1306 - val_accuracy: 0.9609\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9636 - val_loss: 0.1310 - val_accuracy: 0.9598\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9644 - val_loss: 0.1310 - val_accuracy: 0.9589\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9594 - val_loss: 0.1299 - val_accuracy: 0.9615\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9581 - val_loss: 0.1295 - val_accuracy: 0.9613\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9573 - val_loss: 0.1315 - val_accuracy: 0.9593\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9600 - val_loss: 0.1326 - val_accuracy: 0.9613\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9649 - val_loss: 0.1302 - val_accuracy: 0.9622\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9630 - val_loss: 0.1295 - val_accuracy: 0.9628\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9597 - val_loss: 0.1292 - val_accuracy: 0.9628\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9646 - val_loss: 0.1310 - val_accuracy: 0.9617\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9610 - val_loss: 0.1306 - val_accuracy: 0.9595\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9576 - val_loss: 0.1302 - val_accuracy: 0.9626\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9615 - val_loss: 0.1309 - val_accuracy: 0.9587\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9606 - val_loss: 0.1289 - val_accuracy: 0.9611\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9568 - val_loss: 0.1293 - val_accuracy: 0.9633\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9570 - val_loss: 0.1280 - val_accuracy: 0.9628\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9625 - val_loss: 0.1304 - val_accuracy: 0.9615\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9653 - val_loss: 0.1283 - val_accuracy: 0.9631\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9610 - val_loss: 0.1288 - val_accuracy: 0.9611\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9685 - val_loss: 0.1285 - val_accuracy: 0.9633\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9626 - val_loss: 0.1278 - val_accuracy: 0.9637\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9665 - val_loss: 0.1283 - val_accuracy: 0.9631\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9613 - val_loss: 0.1284 - val_accuracy: 0.9622\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9613 - val_loss: 0.1272 - val_accuracy: 0.9637\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9633 - val_loss: 0.1277 - val_accuracy: 0.9635\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9578 - val_loss: 0.1301 - val_accuracy: 0.9624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9670 - val_loss: 0.1283 - val_accuracy: 0.9626\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9608 - val_loss: 0.1303 - val_accuracy: 0.9591\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9615 - val_loss: 0.1270 - val_accuracy: 0.9639\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9639 - val_loss: 0.1287 - val_accuracy: 0.9613\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9626 - val_loss: 0.1266 - val_accuracy: 0.9635\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9605 - val_loss: 0.1269 - val_accuracy: 0.9642\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9597 - val_loss: 0.1289 - val_accuracy: 0.9633\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9611 - val_loss: 0.1285 - val_accuracy: 0.9604\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9671 - val_loss: 0.1265 - val_accuracy: 0.9648\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9603 - val_loss: 0.1269 - val_accuracy: 0.9637\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9632 - val_loss: 0.1268 - val_accuracy: 0.9626\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9643 - val_loss: 0.1291 - val_accuracy: 0.9611\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9614 - val_loss: 0.1286 - val_accuracy: 0.9606\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9646 - val_loss: 0.1281 - val_accuracy: 0.9606\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9648 - val_loss: 0.1334 - val_accuracy: 0.9584\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9658 - val_loss: 0.1296 - val_accuracy: 0.9648\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9621 - val_loss: 0.1261 - val_accuracy: 0.9639\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9583 - val_loss: 0.1275 - val_accuracy: 0.9611\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9623 - val_loss: 0.1260 - val_accuracy: 0.9639\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9637 - val_loss: 0.1281 - val_accuracy: 0.9628\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9629 - val_loss: 0.1258 - val_accuracy: 0.9642\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9658 - val_loss: 0.1257 - val_accuracy: 0.9637\n",
      "4\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 2s 3ms/step - loss: 0.3912 - accuracy: 0.9277 - val_loss: 0.1859 - val_accuracy: 0.9380\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9370 - val_loss: 0.1568 - val_accuracy: 0.9492\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9501 - val_loss: 0.1494 - val_accuracy: 0.9512\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.9540 - val_loss: 0.1460 - val_accuracy: 0.9540\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9533 - val_loss: 0.1460 - val_accuracy: 0.9562\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9527 - val_loss: 0.1427 - val_accuracy: 0.9554\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9541 - val_loss: 0.1441 - val_accuracy: 0.9556\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9542 - val_loss: 0.1416 - val_accuracy: 0.9554\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9519 - val_loss: 0.1402 - val_accuracy: 0.9565\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9576 - val_loss: 0.1404 - val_accuracy: 0.9545\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9532 - val_loss: 0.1412 - val_accuracy: 0.9571\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9533 - val_loss: 0.1398 - val_accuracy: 0.9547\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9615 - val_loss: 0.1386 - val_accuracy: 0.9549\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9572 - val_loss: 0.1384 - val_accuracy: 0.9565\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9570 - val_loss: 0.1375 - val_accuracy: 0.9549\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9577 - val_loss: 0.1373 - val_accuracy: 0.9569\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9566 - val_loss: 0.1395 - val_accuracy: 0.9554\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9556 - val_loss: 0.1372 - val_accuracy: 0.9582\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9571 - val_loss: 0.1379 - val_accuracy: 0.9573\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9611 - val_loss: 0.1365 - val_accuracy: 0.9571\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9598 - val_loss: 0.1360 - val_accuracy: 0.9576\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9580 - val_loss: 0.1361 - val_accuracy: 0.9578\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9541 - val_loss: 0.1374 - val_accuracy: 0.9569\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9544 - val_loss: 0.1357 - val_accuracy: 0.9582\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9611 - val_loss: 0.1359 - val_accuracy: 0.9580\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9595 - val_loss: 0.1347 - val_accuracy: 0.9569\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9575 - val_loss: 0.1347 - val_accuracy: 0.9567\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9596 - val_loss: 0.1352 - val_accuracy: 0.9591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9546 - val_loss: 0.1340 - val_accuracy: 0.9573\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9521 - val_loss: 0.1360 - val_accuracy: 0.9576\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9629 - val_loss: 0.1351 - val_accuracy: 0.9562\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9595 - val_loss: 0.1336 - val_accuracy: 0.9569\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9561 - val_loss: 0.1327 - val_accuracy: 0.9578\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9559 - val_loss: 0.1324 - val_accuracy: 0.9587\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9607 - val_loss: 0.1334 - val_accuracy: 0.9562\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9574 - val_loss: 0.1330 - val_accuracy: 0.9584\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9628 - val_loss: 0.1329 - val_accuracy: 0.9569\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9594 - val_loss: 0.1328 - val_accuracy: 0.9569\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9660 - val_loss: 0.1349 - val_accuracy: 0.9606\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9616 - val_loss: 0.1333 - val_accuracy: 0.9569\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9560 - val_loss: 0.1315 - val_accuracy: 0.9595\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9586 - val_loss: 0.1318 - val_accuracy: 0.9595\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9640 - val_loss: 0.1324 - val_accuracy: 0.9595\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9596 - val_loss: 0.1325 - val_accuracy: 0.9578\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9525 - val_loss: 0.1313 - val_accuracy: 0.9613\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9633 - val_loss: 0.1313 - val_accuracy: 0.9582\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9630 - val_loss: 0.1323 - val_accuracy: 0.9584\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9577 - val_loss: 0.1299 - val_accuracy: 0.9600\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9648 - val_loss: 0.1300 - val_accuracy: 0.9606\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.1404 - accuracy: 0.9573 - val_loss: 0.1313 - val_accuracy: 0.9604\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9623 - val_loss: 0.1298 - val_accuracy: 0.9624\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9605 - val_loss: 0.1306 - val_accuracy: 0.9606\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.1289 - accuracy: 0.9616 - val_loss: 0.1298 - val_accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9652 - val_loss: 0.1307 - val_accuracy: 0.9613\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9671 - val_loss: 0.1305 - val_accuracy: 0.9609\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9592 - val_loss: 0.1316 - val_accuracy: 0.9602\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9569 - val_loss: 0.1307 - val_accuracy: 0.9604\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9587 - val_loss: 0.1314 - val_accuracy: 0.9613\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9637 - val_loss: 0.1296 - val_accuracy: 0.9609\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9599 - val_loss: 0.1285 - val_accuracy: 0.9635\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9641 - val_loss: 0.1282 - val_accuracy: 0.9628\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9560 - val_loss: 0.1291 - val_accuracy: 0.9624\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9587 - val_loss: 0.1289 - val_accuracy: 0.9609\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9600 - val_loss: 0.1301 - val_accuracy: 0.9617\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9618 - val_loss: 0.1290 - val_accuracy: 0.9606\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9599 - val_loss: 0.1292 - val_accuracy: 0.9606\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9638 - val_loss: 0.1313 - val_accuracy: 0.9595\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1359 - accuracy: 0.9602 - val_loss: 0.1279 - val_accuracy: 0.9620\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9618 - val_loss: 0.1277 - val_accuracy: 0.9620\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9615 - val_loss: 0.1277 - val_accuracy: 0.9628\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9616 - val_loss: 0.1275 - val_accuracy: 0.9633\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9586 - val_loss: 0.1273 - val_accuracy: 0.9631\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1227 - accuracy: 0.9670 - val_loss: 0.1296 - val_accuracy: 0.9626\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9622 - val_loss: 0.1301 - val_accuracy: 0.9613\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9611 - val_loss: 0.1283 - val_accuracy: 0.9611\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9594 - val_loss: 0.1283 - val_accuracy: 0.9609\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9587 - val_loss: 0.1273 - val_accuracy: 0.9606\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9579 - val_loss: 0.1273 - val_accuracy: 0.9622\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9573 - val_loss: 0.1275 - val_accuracy: 0.9620\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9612 - val_loss: 0.1270 - val_accuracy: 0.9631\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9647 - val_loss: 0.1277 - val_accuracy: 0.9628\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9660 - val_loss: 0.1266 - val_accuracy: 0.9628\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9602 - val_loss: 0.1284 - val_accuracy: 0.9628\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9617 - val_loss: 0.1281 - val_accuracy: 0.9622\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9555 - val_loss: 0.1294 - val_accuracy: 0.9631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9621 - val_loss: 0.1261 - val_accuracy: 0.9628\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1184 - accuracy: 0.9642 - val_loss: 0.1259 - val_accuracy: 0.9637\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9648 - val_loss: 0.1303 - val_accuracy: 0.9591\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9592 - val_loss: 0.1262 - val_accuracy: 0.9628\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9641 - val_loss: 0.1266 - val_accuracy: 0.9620\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9628 - val_loss: 0.1264 - val_accuracy: 0.9622\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9599 - val_loss: 0.1261 - val_accuracy: 0.9624\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9654 - val_loss: 0.1254 - val_accuracy: 0.9631\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9588 - val_loss: 0.1274 - val_accuracy: 0.9613\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9638 - val_loss: 0.1266 - val_accuracy: 0.9613\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9630 - val_loss: 0.1259 - val_accuracy: 0.9622\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9638 - val_loss: 0.1251 - val_accuracy: 0.9635\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9641 - val_loss: 0.1274 - val_accuracy: 0.9633\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9577 - val_loss: 0.1275 - val_accuracy: 0.9613\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9568 - val_loss: 0.1253 - val_accuracy: 0.9626\n",
      "5\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.4130 - accuracy: 0.9033 - val_loss: 0.1863 - val_accuracy: 0.9369\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9399 - val_loss: 0.1577 - val_accuracy: 0.9510\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9429 - val_loss: 0.1515 - val_accuracy: 0.9503\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9481 - val_loss: 0.1486 - val_accuracy: 0.9521\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9525 - val_loss: 0.1464 - val_accuracy: 0.9551\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9566 - val_loss: 0.1448 - val_accuracy: 0.9558\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9531 - val_loss: 0.1445 - val_accuracy: 0.9551\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9550 - val_loss: 0.1433 - val_accuracy: 0.9567\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9536 - val_loss: 0.1421 - val_accuracy: 0.9565\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9587 - val_loss: 0.1415 - val_accuracy: 0.9578\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9593 - val_loss: 0.1409 - val_accuracy: 0.9554\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9543 - val_loss: 0.1408 - val_accuracy: 0.9554\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9578 - val_loss: 0.1397 - val_accuracy: 0.9565\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9539 - val_loss: 0.1395 - val_accuracy: 0.9565\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9565 - val_loss: 0.1400 - val_accuracy: 0.9551\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9597 - val_loss: 0.1381 - val_accuracy: 0.9578\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9610 - val_loss: 0.1396 - val_accuracy: 0.9582\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9539 - val_loss: 0.1389 - val_accuracy: 0.9573\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9527 - val_loss: 0.1368 - val_accuracy: 0.9576\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9530 - val_loss: 0.1365 - val_accuracy: 0.9567\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9534 - val_loss: 0.1379 - val_accuracy: 0.9578\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9573 - val_loss: 0.1361 - val_accuracy: 0.9569\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9555 - val_loss: 0.1354 - val_accuracy: 0.9569\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9564 - val_loss: 0.1353 - val_accuracy: 0.9580\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9568 - val_loss: 0.1351 - val_accuracy: 0.9580\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9566 - val_loss: 0.1383 - val_accuracy: 0.9556\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9558 - val_loss: 0.1354 - val_accuracy: 0.9578\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9565 - val_loss: 0.1342 - val_accuracy: 0.9580\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9575 - val_loss: 0.1336 - val_accuracy: 0.9584\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9551 - val_loss: 0.1360 - val_accuracy: 0.9587\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9537 - val_loss: 0.1341 - val_accuracy: 0.9591\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9628 - val_loss: 0.1327 - val_accuracy: 0.9589\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9628 - val_loss: 0.1340 - val_accuracy: 0.9582\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9562 - val_loss: 0.1328 - val_accuracy: 0.9591\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9623 - val_loss: 0.1321 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9616 - val_loss: 0.1329 - val_accuracy: 0.9595\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9614 - val_loss: 0.1324 - val_accuracy: 0.9595\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9544 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9568 - val_loss: 0.1317 - val_accuracy: 0.9591\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9579 - val_loss: 0.1309 - val_accuracy: 0.9589\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9568 - val_loss: 0.1357 - val_accuracy: 0.9571\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9556 - val_loss: 0.1304 - val_accuracy: 0.9611\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9593 - val_loss: 0.1352 - val_accuracy: 0.9558\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9618 - val_loss: 0.1326 - val_accuracy: 0.9593\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9630 - val_loss: 0.1321 - val_accuracy: 0.9580\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9557 - val_loss: 0.1299 - val_accuracy: 0.9609\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9635 - val_loss: 0.1294 - val_accuracy: 0.9620\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9554 - val_loss: 0.1305 - val_accuracy: 0.9602\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9608 - val_loss: 0.1303 - val_accuracy: 0.9613\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9609 - val_loss: 0.1304 - val_accuracy: 0.9611\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9661 - val_loss: 0.1299 - val_accuracy: 0.9598\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9568 - val_loss: 0.1301 - val_accuracy: 0.9620\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9636 - val_loss: 0.1293 - val_accuracy: 0.9611\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9577 - val_loss: 0.1283 - val_accuracy: 0.9624\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9597 - val_loss: 0.1303 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9618 - val_loss: 0.1282 - val_accuracy: 0.9613\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9584 - val_loss: 0.1283 - val_accuracy: 0.9635\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9614 - val_loss: 0.1284 - val_accuracy: 0.9631\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9601 - val_loss: 0.1291 - val_accuracy: 0.9602\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9623 - val_loss: 0.1283 - val_accuracy: 0.9617\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9654 - val_loss: 0.1285 - val_accuracy: 0.9620\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9549 - val_loss: 0.1291 - val_accuracy: 0.9609\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9649 - val_loss: 0.1278 - val_accuracy: 0.9611\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9613 - val_loss: 0.1306 - val_accuracy: 0.9598\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9645 - val_loss: 0.1274 - val_accuracy: 0.9626\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9577 - val_loss: 0.1301 - val_accuracy: 0.9602\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9569 - val_loss: 0.1277 - val_accuracy: 0.9620\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9601 - val_loss: 0.1280 - val_accuracy: 0.9613\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9577 - val_loss: 0.1282 - val_accuracy: 0.9611\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9607 - val_loss: 0.1269 - val_accuracy: 0.9617\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9587 - val_loss: 0.1268 - val_accuracy: 0.9637\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9575 - val_loss: 0.1279 - val_accuracy: 0.9626\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9636 - val_loss: 0.1280 - val_accuracy: 0.9611\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9645 - val_loss: 0.1281 - val_accuracy: 0.9613\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9605 - val_loss: 0.1326 - val_accuracy: 0.9582\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9622 - val_loss: 0.1283 - val_accuracy: 0.9602\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9593 - val_loss: 0.1314 - val_accuracy: 0.9609\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9626 - val_loss: 0.1275 - val_accuracy: 0.9617\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9595 - val_loss: 0.1273 - val_accuracy: 0.9617\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9616 - val_loss: 0.1269 - val_accuracy: 0.9628\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9622 - val_loss: 0.1267 - val_accuracy: 0.9615\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9599 - val_loss: 0.1279 - val_accuracy: 0.9617\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9624 - val_loss: 0.1333 - val_accuracy: 0.9573\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9576 - val_loss: 0.1266 - val_accuracy: 0.9622\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9631 - val_loss: 0.1273 - val_accuracy: 0.9611\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9592 - val_loss: 0.1277 - val_accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9629 - val_loss: 0.1269 - val_accuracy: 0.9626\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9632 - val_loss: 0.1269 - val_accuracy: 0.9631\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9612 - val_loss: 0.1276 - val_accuracy: 0.9602\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9589 - val_loss: 0.1271 - val_accuracy: 0.9609\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9664 - val_loss: 0.1272 - val_accuracy: 0.9620\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9667 - val_loss: 0.1298 - val_accuracy: 0.9626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9659 - val_loss: 0.1253 - val_accuracy: 0.9631\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9612 - val_loss: 0.1256 - val_accuracy: 0.9633\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9589 - val_loss: 0.1267 - val_accuracy: 0.9631\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9629 - val_loss: 0.1271 - val_accuracy: 0.9617\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9603 - val_loss: 0.1249 - val_accuracy: 0.9633\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9590 - val_loss: 0.1256 - val_accuracy: 0.9637\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9609 - val_loss: 0.1274 - val_accuracy: 0.9617\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9582 - val_loss: 0.1252 - val_accuracy: 0.9628\n",
      "6\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8886 - val_loss: 0.1880 - val_accuracy: 0.9376\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.9452 - val_loss: 0.1584 - val_accuracy: 0.9496\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9514 - val_loss: 0.1513 - val_accuracy: 0.9521\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9483 - val_loss: 0.1484 - val_accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9576 - val_loss: 0.1493 - val_accuracy: 0.9562\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9580 - val_loss: 0.1457 - val_accuracy: 0.9556\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9517 - val_loss: 0.1442 - val_accuracy: 0.9571\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9583 - val_loss: 0.1442 - val_accuracy: 0.9571\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9587 - val_loss: 0.1419 - val_accuracy: 0.9567\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9607 - val_loss: 0.1428 - val_accuracy: 0.9576\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9571 - val_loss: 0.1414 - val_accuracy: 0.9584\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9585 - val_loss: 0.1402 - val_accuracy: 0.9545\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9494 - val_loss: 0.1411 - val_accuracy: 0.9580\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9550 - val_loss: 0.1408 - val_accuracy: 0.9567\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9581 - val_loss: 0.1386 - val_accuracy: 0.9558\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9555 - val_loss: 0.1380 - val_accuracy: 0.9578\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9521 - val_loss: 0.1383 - val_accuracy: 0.9573\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9576 - val_loss: 0.1383 - val_accuracy: 0.9582\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9528 - val_loss: 0.1378 - val_accuracy: 0.9584\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9528 - val_loss: 0.1383 - val_accuracy: 0.9584\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9571 - val_loss: 0.1370 - val_accuracy: 0.9576\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9594 - val_loss: 0.1364 - val_accuracy: 0.9573\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9567 - val_loss: 0.1358 - val_accuracy: 0.9556\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9538 - val_loss: 0.1353 - val_accuracy: 0.9558\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9567 - val_loss: 0.1355 - val_accuracy: 0.9576\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9584 - val_loss: 0.1352 - val_accuracy: 0.9573\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9553 - val_loss: 0.1358 - val_accuracy: 0.9551\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9516 - val_loss: 0.1359 - val_accuracy: 0.9598\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9521 - val_loss: 0.1339 - val_accuracy: 0.9571\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9565 - val_loss: 0.1345 - val_accuracy: 0.9582\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9569 - val_loss: 0.1340 - val_accuracy: 0.9589\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9609 - val_loss: 0.1336 - val_accuracy: 0.9576\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9582 - val_loss: 0.1329 - val_accuracy: 0.9589\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9567 - val_loss: 0.1330 - val_accuracy: 0.9584\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9557 - val_loss: 0.1337 - val_accuracy: 0.9576\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9582 - val_loss: 0.1325 - val_accuracy: 0.9606\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9600 - val_loss: 0.1365 - val_accuracy: 0.9538\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9557 - val_loss: 0.1341 - val_accuracy: 0.9598\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9569 - val_loss: 0.1315 - val_accuracy: 0.9587\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9492 - val_loss: 0.1322 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9638 - val_loss: 0.1316 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9676 - val_loss: 0.1321 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9625 - val_loss: 0.1319 - val_accuracy: 0.9604\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9591 - val_loss: 0.1318 - val_accuracy: 0.9595\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9607 - val_loss: 0.1315 - val_accuracy: 0.9604\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9633 - val_loss: 0.1316 - val_accuracy: 0.9591\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9559 - val_loss: 0.1308 - val_accuracy: 0.9595\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9634 - val_loss: 0.1302 - val_accuracy: 0.9598\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9592 - val_loss: 0.1330 - val_accuracy: 0.9602\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9613 - val_loss: 0.1305 - val_accuracy: 0.9615\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9568 - val_loss: 0.1307 - val_accuracy: 0.9615\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9591 - val_loss: 0.1297 - val_accuracy: 0.9624\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9606 - val_loss: 0.1302 - val_accuracy: 0.9622\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9600 - val_loss: 0.1300 - val_accuracy: 0.9609\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9597 - val_loss: 0.1305 - val_accuracy: 0.9615\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9610 - val_loss: 0.1296 - val_accuracy: 0.9613\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9606 - val_loss: 0.1284 - val_accuracy: 0.9617\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9617 - val_loss: 0.1285 - val_accuracy: 0.9628\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9607 - val_loss: 0.1284 - val_accuracy: 0.9631\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9628 - val_loss: 0.1288 - val_accuracy: 0.9620\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9623 - val_loss: 0.1291 - val_accuracy: 0.9620\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9648 - val_loss: 0.1279 - val_accuracy: 0.9633\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9680 - val_loss: 0.1295 - val_accuracy: 0.9615\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9613 - val_loss: 0.1280 - val_accuracy: 0.9624\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9587 - val_loss: 0.1282 - val_accuracy: 0.9635\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9655 - val_loss: 0.1275 - val_accuracy: 0.9631\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9706 - val_loss: 0.1273 - val_accuracy: 0.9635\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9546 - val_loss: 0.1274 - val_accuracy: 0.9617\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9597 - val_loss: 0.1288 - val_accuracy: 0.9613\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9646 - val_loss: 0.1276 - val_accuracy: 0.9633\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9650 - val_loss: 0.1282 - val_accuracy: 0.9620\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9567 - val_loss: 0.1265 - val_accuracy: 0.9628\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9609 - val_loss: 0.1277 - val_accuracy: 0.9631\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9639 - val_loss: 0.1264 - val_accuracy: 0.9635\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9612 - val_loss: 0.1264 - val_accuracy: 0.9633\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9632 - val_loss: 0.1283 - val_accuracy: 0.9620\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9649 - val_loss: 0.1277 - val_accuracy: 0.9615\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9589 - val_loss: 0.1303 - val_accuracy: 0.9626\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9636 - val_loss: 0.1281 - val_accuracy: 0.9615\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9603 - val_loss: 0.1263 - val_accuracy: 0.9631\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9630 - val_loss: 0.1277 - val_accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9632 - val_loss: 0.1266 - val_accuracy: 0.9622\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9547 - val_loss: 0.1255 - val_accuracy: 0.9637\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9674 - val_loss: 0.1276 - val_accuracy: 0.9615\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9613 - val_loss: 0.1255 - val_accuracy: 0.9626\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9653 - val_loss: 0.1256 - val_accuracy: 0.9633\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9573 - val_loss: 0.1261 - val_accuracy: 0.9635\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9622 - val_loss: 0.1280 - val_accuracy: 0.9606\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9584 - val_loss: 0.1251 - val_accuracy: 0.9633\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9579 - val_loss: 0.1254 - val_accuracy: 0.9631\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9643 - val_loss: 0.1260 - val_accuracy: 0.9617\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9649 - val_loss: 0.1252 - val_accuracy: 0.9628\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9629 - val_loss: 0.1322 - val_accuracy: 0.9565\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9624 - val_loss: 0.1263 - val_accuracy: 0.9615\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9590 - val_loss: 0.1269 - val_accuracy: 0.9620\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1302 - accuracy: 0.9621 - val_loss: 0.1254 - val_accuracy: 0.9622\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9601 - val_loss: 0.1246 - val_accuracy: 0.9628\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9642 - val_loss: 0.1262 - val_accuracy: 0.9617\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9655 - val_loss: 0.1256 - val_accuracy: 0.9624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9661 - val_loss: 0.1243 - val_accuracy: 0.9639\n",
      "7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.9275 - val_loss: 0.1921 - val_accuracy: 0.9380\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.9287 - val_loss: 0.1654 - val_accuracy: 0.9395\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9425 - val_loss: 0.1537 - val_accuracy: 0.9510\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9472 - val_loss: 0.1501 - val_accuracy: 0.9527\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9534 - val_loss: 0.1487 - val_accuracy: 0.9529\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9537 - val_loss: 0.1461 - val_accuracy: 0.9536\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9546 - val_loss: 0.1468 - val_accuracy: 0.9536\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9527 - val_loss: 0.1447 - val_accuracy: 0.9547\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9551 - val_loss: 0.1429 - val_accuracy: 0.9554\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9587 - val_loss: 0.1418 - val_accuracy: 0.9562\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9490 - val_loss: 0.1413 - val_accuracy: 0.9547\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9516 - val_loss: 0.1410 - val_accuracy: 0.9558\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9552 - val_loss: 0.1400 - val_accuracy: 0.9560\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9553 - val_loss: 0.1432 - val_accuracy: 0.9534\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9544 - val_loss: 0.1386 - val_accuracy: 0.9549\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9596 - val_loss: 0.1379 - val_accuracy: 0.9569\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9569 - val_loss: 0.1373 - val_accuracy: 0.9576\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9600 - val_loss: 0.1376 - val_accuracy: 0.9602\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9563 - val_loss: 0.1374 - val_accuracy: 0.9580\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9549 - val_loss: 0.1369 - val_accuracy: 0.9591\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9562 - val_loss: 0.1372 - val_accuracy: 0.9589\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1493 - accuracy: 0.9537 - val_loss: 0.1356 - val_accuracy: 0.9562\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.1235 - accuracy: 0.9596 - val_loss: 0.1369 - val_accuracy: 0.9613\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9555 - val_loss: 0.1345 - val_accuracy: 0.9576\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9587 - val_loss: 0.1352 - val_accuracy: 0.9611\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9598 - val_loss: 0.1349 - val_accuracy: 0.9571\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9574 - val_loss: 0.1350 - val_accuracy: 0.9569\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9599 - val_loss: 0.1349 - val_accuracy: 0.9598\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9573 - val_loss: 0.1335 - val_accuracy: 0.9613\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9524 - val_loss: 0.1335 - val_accuracy: 0.9611\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9576 - val_loss: 0.1343 - val_accuracy: 0.9578\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9589 - val_loss: 0.1330 - val_accuracy: 0.9613\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9610 - val_loss: 0.1332 - val_accuracy: 0.9620\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9631 - val_loss: 0.1322 - val_accuracy: 0.9615\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9609 - val_loss: 0.1325 - val_accuracy: 0.9613\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9651 - val_loss: 0.1326 - val_accuracy: 0.9609\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9603 - val_loss: 0.1323 - val_accuracy: 0.9606\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9644 - val_loss: 0.1311 - val_accuracy: 0.9620\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9642 - val_loss: 0.1326 - val_accuracy: 0.9622\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9602 - val_loss: 0.1332 - val_accuracy: 0.9611\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9596 - val_loss: 0.1322 - val_accuracy: 0.9598\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9597 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9634 - val_loss: 0.1340 - val_accuracy: 0.9595\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9603 - val_loss: 0.1303 - val_accuracy: 0.9620\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9563 - val_loss: 0.1347 - val_accuracy: 0.9591\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9656 - val_loss: 0.1328 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9584 - val_loss: 0.1310 - val_accuracy: 0.9609\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9606 - val_loss: 0.1294 - val_accuracy: 0.9626\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9647 - val_loss: 0.1295 - val_accuracy: 0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9649 - val_loss: 0.1317 - val_accuracy: 0.9622\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9643 - val_loss: 0.1309 - val_accuracy: 0.9609\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9650 - val_loss: 0.1300 - val_accuracy: 0.9609\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9653 - val_loss: 0.1293 - val_accuracy: 0.9624\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9610 - val_loss: 0.1296 - val_accuracy: 0.9626\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9646 - val_loss: 0.1317 - val_accuracy: 0.9593\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9625 - val_loss: 0.1300 - val_accuracy: 0.9609\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9592 - val_loss: 0.1313 - val_accuracy: 0.9598\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9604 - val_loss: 0.1306 - val_accuracy: 0.9604\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9604 - val_loss: 0.1294 - val_accuracy: 0.9622\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9656 - val_loss: 0.1299 - val_accuracy: 0.9620\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9582 - val_loss: 0.1306 - val_accuracy: 0.9609\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9660 - val_loss: 0.1282 - val_accuracy: 0.9631\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9628 - val_loss: 0.1288 - val_accuracy: 0.9617\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9615 - val_loss: 0.1294 - val_accuracy: 0.9606\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9616 - val_loss: 0.1285 - val_accuracy: 0.9633\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9650 - val_loss: 0.1286 - val_accuracy: 0.9628\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9615 - val_loss: 0.1283 - val_accuracy: 0.9633\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9617 - val_loss: 0.1281 - val_accuracy: 0.9626\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9594 - val_loss: 0.1279 - val_accuracy: 0.9624\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9542 - val_loss: 0.1278 - val_accuracy: 0.9624\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.1294 - val_accuracy: 0.9611\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9576 - val_loss: 0.1283 - val_accuracy: 0.9637\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9621 - val_loss: 0.1291 - val_accuracy: 0.9611\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9584 - val_loss: 0.1277 - val_accuracy: 0.9633\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9612 - val_loss: 0.1277 - val_accuracy: 0.9633\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9699 - val_loss: 0.1318 - val_accuracy: 0.9595\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9615 - val_loss: 0.1268 - val_accuracy: 0.9628\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9653 - val_loss: 0.1272 - val_accuracy: 0.9613\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9665 - val_loss: 0.1281 - val_accuracy: 0.9620\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9650 - val_loss: 0.1301 - val_accuracy: 0.9611\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9602 - val_loss: 0.1276 - val_accuracy: 0.9622\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9589 - val_loss: 0.1275 - val_accuracy: 0.9620\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9575 - val_loss: 0.1279 - val_accuracy: 0.9628\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9592 - val_loss: 0.1261 - val_accuracy: 0.9628\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9607 - val_loss: 0.1265 - val_accuracy: 0.9628\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9605 - val_loss: 0.1264 - val_accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9647 - val_loss: 0.1286 - val_accuracy: 0.9613\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9616 - val_loss: 0.1289 - val_accuracy: 0.9598\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9575 - val_loss: 0.1289 - val_accuracy: 0.9613\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9656 - val_loss: 0.1290 - val_accuracy: 0.9593\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9577 - val_loss: 0.1260 - val_accuracy: 0.9635\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9625 - val_loss: 0.1300 - val_accuracy: 0.9587\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9596 - val_loss: 0.1259 - val_accuracy: 0.9642\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9627 - val_loss: 0.1275 - val_accuracy: 0.9613\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9589 - val_loss: 0.1309 - val_accuracy: 0.9584\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9650 - val_loss: 0.1293 - val_accuracy: 0.9598\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9588 - val_loss: 0.1277 - val_accuracy: 0.9622\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9632 - val_loss: 0.1254 - val_accuracy: 0.9635\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9626 - val_loss: 0.1255 - val_accuracy: 0.9622\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9641 - val_loss: 0.1249 - val_accuracy: 0.9626\n",
      "8\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.9320 - val_loss: 0.1933 - val_accuracy: 0.9371\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9375 - val_loss: 0.1615 - val_accuracy: 0.9464\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9486 - val_loss: 0.1531 - val_accuracy: 0.9496\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9541 - val_loss: 0.1578 - val_accuracy: 0.9507\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9536 - val_loss: 0.1468 - val_accuracy: 0.9543\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9469 - val_loss: 0.1454 - val_accuracy: 0.9551\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9517 - val_loss: 0.1443 - val_accuracy: 0.9547\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9561 - val_loss: 0.1455 - val_accuracy: 0.9558\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9543 - val_loss: 0.1431 - val_accuracy: 0.9556\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9520 - val_loss: 0.1428 - val_accuracy: 0.9558\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9551 - val_loss: 0.1416 - val_accuracy: 0.9556\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9551 - val_loss: 0.1425 - val_accuracy: 0.9538\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9565 - val_loss: 0.1446 - val_accuracy: 0.9551\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9533 - val_loss: 0.1403 - val_accuracy: 0.9556\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9505 - val_loss: 0.1410 - val_accuracy: 0.9554\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9481 - val_loss: 0.1400 - val_accuracy: 0.9558\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9561 - val_loss: 0.1400 - val_accuracy: 0.9567\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9591 - val_loss: 0.1395 - val_accuracy: 0.9565\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9603 - val_loss: 0.1402 - val_accuracy: 0.9573\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9494 - val_loss: 0.1390 - val_accuracy: 0.9560\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9544 - val_loss: 0.1406 - val_accuracy: 0.9578\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9575 - val_loss: 0.1406 - val_accuracy: 0.9573\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9535 - val_loss: 0.1405 - val_accuracy: 0.9549\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9583 - val_loss: 0.1391 - val_accuracy: 0.9578\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9534 - val_loss: 0.1411 - val_accuracy: 0.9540\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9540 - val_loss: 0.1385 - val_accuracy: 0.9549\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9613 - val_loss: 0.1374 - val_accuracy: 0.9565\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9549 - val_loss: 0.1371 - val_accuracy: 0.9562\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9524 - val_loss: 0.1381 - val_accuracy: 0.9554\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9454 - val_loss: 0.1432 - val_accuracy: 0.9556\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.1399 - val_accuracy: 0.9560\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9534 - val_loss: 0.1364 - val_accuracy: 0.9580\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9577 - val_loss: 0.1366 - val_accuracy: 0.9580\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9552 - val_loss: 0.1355 - val_accuracy: 0.9569\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9606 - val_loss: 0.1355 - val_accuracy: 0.9578\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9555 - val_loss: 0.1353 - val_accuracy: 0.9589\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9552 - val_loss: 0.1370 - val_accuracy: 0.9556\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9554 - val_loss: 0.1391 - val_accuracy: 0.9571\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9588 - val_loss: 0.1352 - val_accuracy: 0.9582\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9558 - val_loss: 0.1352 - val_accuracy: 0.9569\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9596 - val_loss: 0.1353 - val_accuracy: 0.9569\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9551 - val_loss: 0.1355 - val_accuracy: 0.9576\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9578 - val_loss: 0.1336 - val_accuracy: 0.9582\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9634 - val_loss: 0.1342 - val_accuracy: 0.9571\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9648 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9642 - val_loss: 0.1334 - val_accuracy: 0.9589\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9587 - val_loss: 0.1398 - val_accuracy: 0.9562\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9606 - val_loss: 0.1336 - val_accuracy: 0.9602\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9578 - val_loss: 0.1332 - val_accuracy: 0.9580\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9591 - val_loss: 0.1323 - val_accuracy: 0.9598\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9594 - val_loss: 0.1319 - val_accuracy: 0.9606\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9582 - val_loss: 0.1325 - val_accuracy: 0.9598\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9625 - val_loss: 0.1331 - val_accuracy: 0.9582\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1365 - accuracy: 0.9602 - val_loss: 0.1326 - val_accuracy: 0.9587\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9601 - val_loss: 0.1315 - val_accuracy: 0.9613\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9625 - val_loss: 0.1320 - val_accuracy: 0.9591\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9582 - val_loss: 0.1321 - val_accuracy: 0.9617\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9598 - val_loss: 0.1315 - val_accuracy: 0.9602\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9589 - val_loss: 0.1353 - val_accuracy: 0.9582\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9568 - val_loss: 0.1308 - val_accuracy: 0.9609\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9649 - val_loss: 0.1308 - val_accuracy: 0.9613\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9670 - val_loss: 0.1339 - val_accuracy: 0.9609\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9585 - val_loss: 0.1315 - val_accuracy: 0.9604\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9630 - val_loss: 0.1301 - val_accuracy: 0.9628\n",
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9613 - val_loss: 0.1307 - val_accuracy: 0.9633\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9664 - val_loss: 0.1332 - val_accuracy: 0.9578\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9604 - val_loss: 0.1312 - val_accuracy: 0.9617\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9579 - val_loss: 0.1305 - val_accuracy: 0.9615\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9628 - val_loss: 0.1293 - val_accuracy: 0.9633\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9607 - val_loss: 0.1300 - val_accuracy: 0.9622\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9625 - val_loss: 0.1304 - val_accuracy: 0.9622\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9660 - val_loss: 0.1303 - val_accuracy: 0.9620\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9577 - val_loss: 0.1299 - val_accuracy: 0.9617\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9657 - val_loss: 0.1294 - val_accuracy: 0.9622\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9572 - val_loss: 0.1316 - val_accuracy: 0.9587\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9626 - val_loss: 0.1292 - val_accuracy: 0.9633\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9612 - val_loss: 0.1286 - val_accuracy: 0.9628\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9608 - val_loss: 0.1294 - val_accuracy: 0.9628\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9563 - val_loss: 0.1314 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9613 - val_loss: 0.1286 - val_accuracy: 0.9620\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9632 - val_loss: 0.1282 - val_accuracy: 0.9633\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9562 - val_loss: 0.1287 - val_accuracy: 0.9639\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9635 - val_loss: 0.1283 - val_accuracy: 0.9620\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9606 - val_loss: 0.1282 - val_accuracy: 0.9622\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9646 - val_loss: 0.1288 - val_accuracy: 0.9615\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9588 - val_loss: 0.1295 - val_accuracy: 0.9631\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9618 - val_loss: 0.1306 - val_accuracy: 0.9589\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9572 - val_loss: 0.1284 - val_accuracy: 0.9613\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9583 - val_loss: 0.1277 - val_accuracy: 0.9646\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9639 - val_loss: 0.1277 - val_accuracy: 0.9633\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9624 - val_loss: 0.1285 - val_accuracy: 0.9624\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9647 - val_loss: 0.1288 - val_accuracy: 0.9635\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9647 - val_loss: 0.1273 - val_accuracy: 0.9626\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9651 - val_loss: 0.1310 - val_accuracy: 0.9598\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9612 - val_loss: 0.1268 - val_accuracy: 0.9644\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9615 - val_loss: 0.1270 - val_accuracy: 0.9628\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9627 - val_loss: 0.1285 - val_accuracy: 0.9609\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9641 - val_loss: 0.1282 - val_accuracy: 0.9617\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9630 - val_loss: 0.1273 - val_accuracy: 0.9620\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9587 - val_loss: 0.1274 - val_accuracy: 0.9624\n",
      "9\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.4276 - accuracy: 0.9022 - val_loss: 0.2007 - val_accuracy: 0.9369\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9361 - val_loss: 0.1674 - val_accuracy: 0.9420\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9407 - val_loss: 0.1560 - val_accuracy: 0.9485\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9490 - val_loss: 0.1523 - val_accuracy: 0.9523\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9472 - val_loss: 0.1500 - val_accuracy: 0.9534\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9544 - val_loss: 0.1480 - val_accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9477 - val_loss: 0.1486 - val_accuracy: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9524 - val_loss: 0.1455 - val_accuracy: 0.9549\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9541 - val_loss: 0.1460 - val_accuracy: 0.9554\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9579 - val_loss: 0.1445 - val_accuracy: 0.9556\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9519 - val_loss: 0.1422 - val_accuracy: 0.9560\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9595 - val_loss: 0.1415 - val_accuracy: 0.9556\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9564 - val_loss: 0.1428 - val_accuracy: 0.9543\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9528 - val_loss: 0.1411 - val_accuracy: 0.9556\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9566 - val_loss: 0.1414 - val_accuracy: 0.9560\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9560 - val_loss: 0.1403 - val_accuracy: 0.9558\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9582 - val_loss: 0.1398 - val_accuracy: 0.9571\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9556 - val_loss: 0.1385 - val_accuracy: 0.9569\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9590 - val_loss: 0.1390 - val_accuracy: 0.9551\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9540 - val_loss: 0.1385 - val_accuracy: 0.9576\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9565 - val_loss: 0.1400 - val_accuracy: 0.9556\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9564 - val_loss: 0.1392 - val_accuracy: 0.9569\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9596 - val_loss: 0.1368 - val_accuracy: 0.9569\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9586 - val_loss: 0.1405 - val_accuracy: 0.9565\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9571 - val_loss: 0.1372 - val_accuracy: 0.9576\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9563 - val_loss: 0.1379 - val_accuracy: 0.9558\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9565 - val_loss: 0.1382 - val_accuracy: 0.9578\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9600 - val_loss: 0.1368 - val_accuracy: 0.9580\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9577 - val_loss: 0.1352 - val_accuracy: 0.9578\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9555 - val_loss: 0.1393 - val_accuracy: 0.9549\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9539 - val_loss: 0.1350 - val_accuracy: 0.9584\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9581 - val_loss: 0.1363 - val_accuracy: 0.9580\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9590 - val_loss: 0.1344 - val_accuracy: 0.9573\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9605 - val_loss: 0.1345 - val_accuracy: 0.9571\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9595 - val_loss: 0.1343 - val_accuracy: 0.9593\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9560 - val_loss: 0.1340 - val_accuracy: 0.9591\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9551 - val_loss: 0.1338 - val_accuracy: 0.9584\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9582 - val_loss: 0.1330 - val_accuracy: 0.9589\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9637 - val_loss: 0.1334 - val_accuracy: 0.9580\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9610 - val_loss: 0.1348 - val_accuracy: 0.9578\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9595 - val_loss: 0.1351 - val_accuracy: 0.9573\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9579 - val_loss: 0.1335 - val_accuracy: 0.9591\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9554 - val_loss: 0.1368 - val_accuracy: 0.9558\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9615 - val_loss: 0.1324 - val_accuracy: 0.9589\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9554 - val_loss: 0.1325 - val_accuracy: 0.9589\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9591 - val_loss: 0.1320 - val_accuracy: 0.9602\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9599 - val_loss: 0.1337 - val_accuracy: 0.9571\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.9604 - val_loss: 0.1341 - val_accuracy: 0.9580\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9592 - val_loss: 0.1333 - val_accuracy: 0.9598\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9551 - val_loss: 0.1309 - val_accuracy: 0.9602\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9565 - val_loss: 0.1324 - val_accuracy: 0.9580\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9606 - val_loss: 0.1310 - val_accuracy: 0.9611\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9599 - val_loss: 0.1304 - val_accuracy: 0.9613\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9625 - val_loss: 0.1303 - val_accuracy: 0.9622\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9625 - val_loss: 0.1300 - val_accuracy: 0.9615\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9617 - val_loss: 0.1300 - val_accuracy: 0.9620\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9587 - val_loss: 0.1300 - val_accuracy: 0.9606\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9587 - val_loss: 0.1304 - val_accuracy: 0.9613\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9591 - val_loss: 0.1308 - val_accuracy: 0.9609\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9627 - val_loss: 0.1318 - val_accuracy: 0.9595\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9575 - val_loss: 0.1296 - val_accuracy: 0.9611\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9599 - val_loss: 0.1310 - val_accuracy: 0.9598\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9600 - val_loss: 0.1327 - val_accuracy: 0.9591\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9603 - val_loss: 0.1304 - val_accuracy: 0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9585 - val_loss: 0.1301 - val_accuracy: 0.9624\n",
      "Epoch 66/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9601 - val_loss: 0.1287 - val_accuracy: 0.9624\n",
      "Epoch 67/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9643 - val_loss: 0.1320 - val_accuracy: 0.9584\n",
      "Epoch 68/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9620 - val_loss: 0.1295 - val_accuracy: 0.9609\n",
      "Epoch 69/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9577 - val_loss: 0.1307 - val_accuracy: 0.9591\n",
      "Epoch 70/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9587 - val_loss: 0.1287 - val_accuracy: 0.9624\n",
      "Epoch 71/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9595 - val_loss: 0.1337 - val_accuracy: 0.9604\n",
      "Epoch 72/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9606 - val_loss: 0.1293 - val_accuracy: 0.9622\n",
      "Epoch 73/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9601 - val_loss: 0.1291 - val_accuracy: 0.9611\n",
      "Epoch 74/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9622 - val_loss: 0.1306 - val_accuracy: 0.9602\n",
      "Epoch 75/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9611 - val_loss: 0.1295 - val_accuracy: 0.9598\n",
      "Epoch 76/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9598 - val_loss: 0.1290 - val_accuracy: 0.9600\n",
      "Epoch 77/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9620 - val_loss: 0.1274 - val_accuracy: 0.9624\n",
      "Epoch 78/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9620 - val_loss: 0.1272 - val_accuracy: 0.9615\n",
      "Epoch 79/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9576 - val_loss: 0.1273 - val_accuracy: 0.9622\n",
      "Epoch 80/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9659 - val_loss: 0.1273 - val_accuracy: 0.9620\n",
      "Epoch 81/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9595 - val_loss: 0.1268 - val_accuracy: 0.9622\n",
      "Epoch 82/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9614 - val_loss: 0.1283 - val_accuracy: 0.9613\n",
      "Epoch 83/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9621 - val_loss: 0.1274 - val_accuracy: 0.9613\n",
      "Epoch 84/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9641 - val_loss: 0.1281 - val_accuracy: 0.9613\n",
      "Epoch 85/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9619 - val_loss: 0.1279 - val_accuracy: 0.9617\n",
      "Epoch 86/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9645 - val_loss: 0.1273 - val_accuracy: 0.9628\n",
      "Epoch 87/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9612 - val_loss: 0.1279 - val_accuracy: 0.9624\n",
      "Epoch 88/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9609 - val_loss: 0.1278 - val_accuracy: 0.9615\n",
      "Epoch 89/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9597 - val_loss: 0.1276 - val_accuracy: 0.9613\n",
      "Epoch 90/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9615 - val_loss: 0.1272 - val_accuracy: 0.9622\n",
      "Epoch 91/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9577 - val_loss: 0.1267 - val_accuracy: 0.9626\n",
      "Epoch 92/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9634 - val_loss: 0.1263 - val_accuracy: 0.9613\n",
      "Epoch 93/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9601 - val_loss: 0.1264 - val_accuracy: 0.9626\n",
      "Epoch 94/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9591 - val_loss: 0.1311 - val_accuracy: 0.9587\n",
      "Epoch 95/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9636 - val_loss: 0.1271 - val_accuracy: 0.9615\n",
      "Epoch 96/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9602 - val_loss: 0.1344 - val_accuracy: 0.9582\n",
      "Epoch 97/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9578 - val_loss: 0.1264 - val_accuracy: 0.9635\n",
      "Epoch 98/100\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9599 - val_loss: 0.1265 - val_accuracy: 0.9624\n",
      "Epoch 99/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9599 - val_loss: 0.1260 - val_accuracy: 0.9631\n",
      "Epoch 100/100\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9574 - val_loss: 0.1264 - val_accuracy: 0.9637\n"
     ]
    }
   ],
   "source": [
    "df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "t_enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    enm_mlp, model = ensemble_cnn()\n",
    "    t_enm_mlp_df = pd.concat([t_enm_mlp_df, enm_mlp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble mlp\n",
      "[0.8861, 0.7677, 0.8142, 0.9122, 210.0808, 94.2617]\n",
      "[0.0109, 0.0093, 0.0045, 0.0024, 5.4006, 0.0998]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>224.6962</td>\n",
       "      <td>94.3867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>210.7810</td>\n",
       "      <td>94.2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.7665</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>206.4811</td>\n",
       "      <td>94.2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>208.2645</td>\n",
       "      <td>94.3958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.8206</td>\n",
       "      <td>0.9131</td>\n",
       "      <td>210.6583</td>\n",
       "      <td>94.1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.9137</td>\n",
       "      <td>206.3098</td>\n",
       "      <td>94.1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>0.8155</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>207.1096</td>\n",
       "      <td>94.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8706</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>210.4540</td>\n",
       "      <td>94.1586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.7481</td>\n",
       "      <td>0.8049</td>\n",
       "      <td>0.9137</td>\n",
       "      <td>207.7235</td>\n",
       "      <td>94.1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8848</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.9131</td>\n",
       "      <td>208.3298</td>\n",
       "      <td>94.2332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision  Recall  F1 score     AUC  Train time  Test time\n",
       "0     0.8853  0.7730    0.8180  0.9134    224.6962    94.3867\n",
       "1     0.8924  0.7604    0.8109  0.9074    210.7810    94.2406\n",
       "2     0.8818  0.7665    0.8122  0.9081    206.4811    94.2130\n",
       "3     0.8899  0.7664    0.8147  0.9125    208.2645    94.3958\n",
       "4     0.8874  0.7756    0.8206  0.9131    210.6583    94.1891\n",
       "5     0.8686  0.7760    0.8145  0.9137    206.3098    94.1886\n",
       "6     0.8956  0.7651    0.8155  0.9127    207.1096    94.4228\n",
       "7     0.8706  0.7807    0.8184  0.9141    210.4540    94.1586\n",
       "8     0.9050  0.7481    0.8049  0.9137    207.7235    94.1891\n",
       "9     0.8848  0.7651    0.8122  0.9131    208.3298    94.2332"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Ensemble mlp')\n",
    "metrics_name = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "mean_mlp = []\n",
    "std_mlp = []\n",
    "for each in metrics_name:\n",
    "    mean_mlp.append(round(t_enm_mlp_df[each].mean(), ndigits=4))\n",
    "    std_mlp.append(round(t_enm_mlp_df[each].std(), ndigits=4))\n",
    "print(mean_mlp)\n",
    "print(std_mlp)\n",
    "t_enm_mlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
