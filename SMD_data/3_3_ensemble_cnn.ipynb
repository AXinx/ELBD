{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09459601811861372"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "data_name = 'SMD'\n",
    "data_file = os.path.join(path, 'processed', data_name)\n",
    "train_data_ = open(os.path.join(data_file, 'machine-1-1_train.pkl'),'rb')\n",
    "train_data = pd.DataFrame(pkl.load(train_data_))\n",
    "test_data_ = open(os.path.join(data_file, 'machine-1-1_test.pkl'),'rb')\n",
    "test_data = pd.DataFrame(pkl.load(test_data_))\n",
    "\n",
    "test_data_label_ = open(os.path.join(data_file, 'machine-1-1_test_label.pkl'),'rb')\n",
    "test_data_label = pd.DataFrame(pkl.load(test_data_label_),columns=['label'])\n",
    "\n",
    "anomaly_num = len(test_data_label[test_data_label.label==1])\n",
    "anomaly_num / len(test_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.068156</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.269886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.068036</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.064432</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.073742</td>\n",
       "      <td>0.075582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.070020</td>\n",
       "      <td>0.050437</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.065228</td>\n",
       "      <td>0.065224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.064619</td>\n",
       "      <td>0.069273</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.069684</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.067111</td>\n",
       "      <td>0.067178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.048729</td>\n",
       "      <td>0.061452</td>\n",
       "      <td>0.069768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.268940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027250</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.073253</td>\n",
       "      <td>0.051467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.066676</td>\n",
       "      <td>0.066744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.051907</td>\n",
       "      <td>0.060335</td>\n",
       "      <td>0.069768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.269886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.070932</td>\n",
       "      <td>0.051467</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.066604</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28474</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.051907</td>\n",
       "      <td>0.045810</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896551</td>\n",
       "      <td>0.252841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>0.040144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.042931</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28475</th>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.036871</td>\n",
       "      <td>0.043024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893678</td>\n",
       "      <td>0.252841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.047438</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.046619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28476</th>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.048044</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896551</td>\n",
       "      <td>0.253788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.046797</td>\n",
       "      <td>0.040144</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28477</th>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.056144</td>\n",
       "      <td>0.045810</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890805</td>\n",
       "      <td>0.252841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.041884</td>\n",
       "      <td>0.043232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.039890</td>\n",
       "      <td>0.039959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28478</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.039106</td>\n",
       "      <td>0.043024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879311</td>\n",
       "      <td>0.251894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28479 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3    4         5         6    7   \\\n",
       "0      0.065217  0.065678  0.068156  0.073256  0.0  0.925287  0.269886  0.0   \n",
       "1      0.076087  0.080508  0.073742  0.075582  0.0  0.922414  0.270833  0.0   \n",
       "2      0.065217  0.064619  0.069273  0.073256  0.0  0.919540  0.270833  0.0   \n",
       "3      0.076087  0.048729  0.061452  0.069768  0.0  0.919540  0.268940  0.0   \n",
       "4      0.076087  0.051907  0.060335  0.069768  0.0  0.925287  0.269886  0.0   \n",
       "...         ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "28474  0.065217  0.051907  0.045810  0.046512  0.0  0.896551  0.252841  0.0   \n",
       "28475  0.054347  0.025424  0.036871  0.043024  0.0  0.893678  0.252841  0.0   \n",
       "28476  0.054347  0.080508  0.048044  0.046512  0.0  0.896551  0.253788  0.0   \n",
       "28477  0.054347  0.056144  0.045810  0.045350  0.0  0.890805  0.252841  0.0   \n",
       "28478  0.000000  0.029661  0.039106  0.043024  0.0  0.879311  0.251894  0.0   \n",
       "\n",
       "             8         9   ...   28        29        30        31        32  \\\n",
       "0      0.031081  0.000000  ...  0.0  0.004317  0.068036  0.048893  0.000386   \n",
       "1      0.031081  0.000122  ...  0.0  0.004317  0.070020  0.050437  0.000386   \n",
       "2      0.030940  0.000366  ...  0.0  0.004317  0.069684  0.055069  0.000386   \n",
       "3      0.027250  0.000244  ...  0.0  0.005756  0.073253  0.051467  0.000000   \n",
       "4      0.030940  0.000244  ...  0.0  0.004317  0.070932  0.051467  0.000386   \n",
       "...         ...       ...  ...  ...       ...       ...       ...       ...   \n",
       "28474  0.043571  0.000244  ...  0.0  0.027339  0.046733  0.040144  0.000000   \n",
       "28475  0.032501  0.000000  ...  0.0  0.027339  0.047438  0.048893  0.000000   \n",
       "28476  0.026114  0.000611  ...  0.0  0.027339  0.046797  0.040144  0.000386   \n",
       "28477  0.033210  0.000122  ...  0.0  0.027339  0.041884  0.043232  0.000000   \n",
       "28478  0.030656  0.001966  ...  0.0  0.030216  0.000000  0.000000  0.000386   \n",
       "\n",
       "             33        34        35   36   37  \n",
       "0      0.000023  0.064432  0.064500  0.0  0.0  \n",
       "1      0.000011  0.065228  0.065224  0.0  0.0  \n",
       "2      0.000034  0.067111  0.067178  0.0  0.0  \n",
       "3      0.000023  0.066676  0.066744  0.0  0.0  \n",
       "4      0.000011  0.066604  0.066671  0.0  0.0  \n",
       "...         ...       ...       ...  ...  ...  \n",
       "28474  0.000011  0.042931  0.043000  0.0  0.0  \n",
       "28475  0.000045  0.046550  0.046619  0.0  0.0  \n",
       "28476  0.000034  0.043003  0.043000  0.0  0.0  \n",
       "28477  0.000034  0.039890  0.039959  0.0  0.0  \n",
       "28478  0.000135  0.000000  0.000000  0.0  0.0  \n",
       "\n",
       "[28479 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_train_data = pd.DataFrame(scaler.fit_transform(train_data))\n",
    "normalized_test_data = pd.DataFrame(scaler.fit_transform(test_data))\n",
    "normalized_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6472445  0.23495755 0.03814479 0.01958584 0.01584372]\n",
      "[67.19858   40.487465  16.313362  11.6895275 10.513673 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca_train_data = pca.fit_transform(normalized_train_data)\n",
    "pca_test_data = pca.fit_transform(normalized_test_data)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "# supress warnings for clean output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from pyod.models.combination import aom, moa, average, maximization, majority_vote\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_labels(y_test, test_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, test_scores)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    pred_label = []\n",
    "    for each in test_scores:\n",
    "        if each > cutoff:\n",
    "            pred_label.append(1)\n",
    "        else:\n",
    "            pred_label.append(0)    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eval(label, pred_label, scores):\n",
    "    pr = round(metrics.precision_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    re = round(metrics.recall_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    f1 = round(metrics.f1_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    roc = round(roc_auc_score(label, scores), ndigits=4)\n",
    "    return pr,re,f1,roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca_test_data\n",
    "X_test = pca_test_data\n",
    "y_train = test_data_label\n",
    "y_test = test_data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base detector 1 is fitted for prediction\n",
      "Base detector 2 is fitted for prediction\n",
      "Base detector 3 is fitted for prediction\n",
      "Base detector 4 is fitted for prediction\n",
      "79.72319999999999\n"
     ]
    }
   ],
   "source": [
    "outliers_fraction = np.count_nonzero(y_train) / len(y_train)\n",
    "outliers_percentage = round(outliers_fraction * 100, ndigits=4)\n",
    "    \n",
    "random_state = np.random.RandomState(42)\n",
    "classifiers = {\n",
    "        'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                    random_state=random_state),\n",
    "        'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "        'Local Outlier Factor (LOF)': LOF(\n",
    "            contamination=outliers_fraction),\n",
    "        'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction)\n",
    "    }\n",
    "\n",
    "n_clf = len(classifiers)\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
    "p_labels = np.zeros([X_test.shape[0], n_clf])\n",
    "\n",
    "i = 0\n",
    "train_duration = 0\n",
    "test_duration = 0\n",
    "for clf_name, clf in classifiers.items():\n",
    "    t0 = time()\n",
    "    clf.fit(X_train)\n",
    "    t1 = time()\n",
    "    test_sccore = clf.decision_function(X_test)\n",
    "    t_t = time()\n",
    "    test_mean_score = np.nanmean(test_scores)\n",
    "    test_scores[np.isnan(test_scores)] = test_mean_score\n",
    "    test_scores[:, i] = test_sccore\n",
    "    p_labels[:, i] = pred_labels(y_test, test_sccore)\n",
    "    i += 1\n",
    "    print('Base detector %i is fitted for prediction' % i)\n",
    "    train_duration += round(t1 - t0, ndigits=4)\n",
    "    test_duration += round(t_t - t1, ndigits=4)\n",
    "    \n",
    "# standardize test score\n",
    "test_scores_norm = standardizer(test_scores)\n",
    "print(train_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from time import time\n",
    "\n",
    "test_scores_norm = test_scores_norm.reshape((test_scores_norm.shape[0], test_scores_norm.shape[1], 1))\n",
    "train_x, test_x, train_y, test_y = train_test_split(test_scores_norm, y_test, test_size=0.9, random_state=random_state)\n",
    "#train_x, test_x, train_y, test_y = train_test_split(test_scores_norm[:,3], y_test, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ensemble_cnn():\n",
    "    df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "    enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    t2 = time()\n",
    "#     # Input - Layer\n",
    "#     model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(4, 1)))\n",
    "#     #model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(units=50, activation='relu', return_sequences=False))\n",
    "#     #model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(4,1)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    # compiling the model\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "      \n",
    "    results = model.fit(\n",
    "     train_x, train_y,\n",
    "     epochs= 100,\n",
    "     batch_size = 20,\n",
    "     validation_data = (train_x, train_y)\n",
    "    )\n",
    "    t3 = time()\n",
    "    #print(results.history['val_accuracy'])\n",
    "    #pred_test = model.predict(test_scores_norm[:,0]).reshape(len(test_scores_norm),1)\n",
    "    pred_test = model.predict(test_scores_norm)\n",
    "    #pred_test = model.predict(test_x)\n",
    "    t4 = time()\n",
    "    train_time = t3 - t2\n",
    "    test_time = t4 - t3\n",
    "    train_time_mlp =  round(train_duration+train_time, ndigits=4)\n",
    "    test_time_mlp = round(test_duration+test_time, ndigits=4)\n",
    "    \n",
    "    pred_nn = []\n",
    "    for each in pred_test:\n",
    "        if each[0] > 0.5:\n",
    "            pred_nn.append(1)\n",
    "        else:\n",
    "            pred_nn.append(0)\n",
    "    #pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(test_y, pred_nn, pred_test)\n",
    "    pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(y_test, pred_nn, pred_test)\n",
    "    enm_mlp = pd.DataFrame([pr_mlp, re_mlp, f1_mlp, roc_mlp, train_time_mlp, test_time_mlp]).transpose()\n",
    "    enm_mlp.columns = df_columns\n",
    "    enm_mlp_df = pd.concat([enm_mlp_df, enm_mlp], axis=0)\n",
    "    return enm_mlp_df, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 14:14:32.811098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-26 14:14:33.045337: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 [==============================] - 15s 4ms/step - loss: 0.4785 - accuracy: 0.8974 - val_loss: 0.2267 - val_accuracy: 0.9125\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.9155 - val_loss: 0.2057 - val_accuracy: 0.9185\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.9098 - val_loss: 0.1994 - val_accuracy: 0.9224\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9244 - val_loss: 0.1979 - val_accuracy: 0.9234\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9141 - val_loss: 0.1973 - val_accuracy: 0.9259\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9262 - val_loss: 0.1955 - val_accuracy: 0.9241\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9309 - val_loss: 0.1955 - val_accuracy: 0.9245\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9262 - val_loss: 0.1982 - val_accuracy: 0.9255\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9203 - val_loss: 0.1941 - val_accuracy: 0.9231\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9199 - val_loss: 0.1938 - val_accuracy: 0.9238\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.9137 - val_loss: 0.1945 - val_accuracy: 0.9266\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9200 - val_loss: 0.1932 - val_accuracy: 0.9266\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9250 - val_loss: 0.1922 - val_accuracy: 0.9255\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9199 - val_loss: 0.1917 - val_accuracy: 0.9283\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9194 - val_loss: 0.1922 - val_accuracy: 0.9234\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.9198 - val_loss: 0.1912 - val_accuracy: 0.9266\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9215 - val_loss: 0.1909 - val_accuracy: 0.9259\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.9305 - val_loss: 0.1906 - val_accuracy: 0.9273\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9314 - val_loss: 0.1905 - val_accuracy: 0.9262\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9327 - val_loss: 0.1903 - val_accuracy: 0.9252\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9306 - val_loss: 0.1898 - val_accuracy: 0.9276\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.9204 - val_loss: 0.1911 - val_accuracy: 0.9238\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9275 - val_loss: 0.1891 - val_accuracy: 0.9283\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9349 - val_loss: 0.1897 - val_accuracy: 0.9283\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9305 - val_loss: 0.1908 - val_accuracy: 0.9273\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9234 - val_loss: 0.1892 - val_accuracy: 0.9259\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.9300 - val_loss: 0.1898 - val_accuracy: 0.9266\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9308 - val_loss: 0.1883 - val_accuracy: 0.9259\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9269 - val_loss: 0.1907 - val_accuracy: 0.9234\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9239 - val_loss: 0.1903 - val_accuracy: 0.9269\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9244 - val_loss: 0.1919 - val_accuracy: 0.9224\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9296 - val_loss: 0.1874 - val_accuracy: 0.9269\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9306 - val_loss: 0.1873 - val_accuracy: 0.9290\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.9273 - val_loss: 0.1875 - val_accuracy: 0.9269\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9275 - val_loss: 0.1876 - val_accuracy: 0.9269\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9251 - val_loss: 0.1917 - val_accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9253 - val_loss: 0.1872 - val_accuracy: 0.9290\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9218 - val_loss: 0.1873 - val_accuracy: 0.9280\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9278 - val_loss: 0.1868 - val_accuracy: 0.9269\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9231 - val_loss: 0.1866 - val_accuracy: 0.9308\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9315 - val_loss: 0.1896 - val_accuracy: 0.9294\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9326 - val_loss: 0.1857 - val_accuracy: 0.9298\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9224 - val_loss: 0.1873 - val_accuracy: 0.9290\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9305 - val_loss: 0.1856 - val_accuracy: 0.9290\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.9234 - val_loss: 0.1855 - val_accuracy: 0.9301\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9299 - val_loss: 0.1861 - val_accuracy: 0.9280\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9232 - val_loss: 0.1854 - val_accuracy: 0.9276\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9269 - val_loss: 0.1847 - val_accuracy: 0.9287\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9209 - val_loss: 0.1848 - val_accuracy: 0.9315\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9325 - val_loss: 0.1849 - val_accuracy: 0.9301\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9338 - val_loss: 0.1843 - val_accuracy: 0.9301\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9229 - val_loss: 0.1842 - val_accuracy: 0.9290\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9270 - val_loss: 0.1848 - val_accuracy: 0.9294\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9302 - val_loss: 0.1840 - val_accuracy: 0.9305\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9302 - val_loss: 0.1857 - val_accuracy: 0.9290\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9269 - val_loss: 0.1847 - val_accuracy: 0.9290\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9336 - val_loss: 0.1873 - val_accuracy: 0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9266 - val_loss: 0.1849 - val_accuracy: 0.9305\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9341 - val_loss: 0.1855 - val_accuracy: 0.9329\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9299 - val_loss: 0.1870 - val_accuracy: 0.9301\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.9265 - val_loss: 0.1844 - val_accuracy: 0.9287\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9301 - val_loss: 0.1835 - val_accuracy: 0.9301\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9366 - val_loss: 0.1835 - val_accuracy: 0.9305\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9350 - val_loss: 0.1840 - val_accuracy: 0.9312\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9237 - val_loss: 0.1837 - val_accuracy: 0.9305\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9292 - val_loss: 0.1838 - val_accuracy: 0.9319\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9322 - val_loss: 0.1836 - val_accuracy: 0.9301\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9320 - val_loss: 0.1830 - val_accuracy: 0.9308\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9261 - val_loss: 0.1829 - val_accuracy: 0.9301\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9309 - val_loss: 0.1829 - val_accuracy: 0.9294\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9298 - val_loss: 0.1826 - val_accuracy: 0.9294\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9225 - val_loss: 0.1823 - val_accuracy: 0.9308\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9301 - val_loss: 0.1823 - val_accuracy: 0.9315\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9256 - val_loss: 0.1823 - val_accuracy: 0.9312\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9328 - val_loss: 0.1820 - val_accuracy: 0.9298\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9267 - val_loss: 0.1823 - val_accuracy: 0.9308\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9177 - val_loss: 0.1832 - val_accuracy: 0.9283\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.1815 - val_accuracy: 0.9312\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2097 - accuracy: 0.9207 - val_loss: 0.1828 - val_accuracy: 0.9308\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9279 - val_loss: 0.1819 - val_accuracy: 0.9315\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9291 - val_loss: 0.1818 - val_accuracy: 0.9326\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9254 - val_loss: 0.1816 - val_accuracy: 0.9315\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.9307 - val_loss: 0.1824 - val_accuracy: 0.9294\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9207 - val_loss: 0.1827 - val_accuracy: 0.9287\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9298 - val_loss: 0.1815 - val_accuracy: 0.9305\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9302 - val_loss: 0.1820 - val_accuracy: 0.9329\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.9345 - val_loss: 0.1820 - val_accuracy: 0.9305\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9322 - val_loss: 0.1812 - val_accuracy: 0.9315\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9247 - val_loss: 0.1808 - val_accuracy: 0.9308\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9193 - val_loss: 0.1815 - val_accuracy: 0.9305\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9321 - val_loss: 0.1832 - val_accuracy: 0.9312\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9236 - val_loss: 0.1810 - val_accuracy: 0.9305\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.9284 - val_loss: 0.1848 - val_accuracy: 0.9301\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9316 - val_loss: 0.1805 - val_accuracy: 0.9315\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9200 - val_loss: 0.1814 - val_accuracy: 0.9312\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9335 - val_loss: 0.1808 - val_accuracy: 0.9305\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9278 - val_loss: 0.1826 - val_accuracy: 0.9308\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9366 - val_loss: 0.1808 - val_accuracy: 0.9301\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9296 - val_loss: 0.1807 - val_accuracy: 0.9298\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9351 - val_loss: 0.1808 - val_accuracy: 0.9308\n",
      "1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.8936 - val_loss: 0.2322 - val_accuracy: 0.9097\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9039 - val_loss: 0.2077 - val_accuracy: 0.9150\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9183 - val_loss: 0.1990 - val_accuracy: 0.9234\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9319 - val_loss: 0.2015 - val_accuracy: 0.9241\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9241 - val_loss: 0.1954 - val_accuracy: 0.9255\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9279 - val_loss: 0.1959 - val_accuracy: 0.9252\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9280 - val_loss: 0.1965 - val_accuracy: 0.9217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9228 - val_loss: 0.2018 - val_accuracy: 0.9182\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9199 - val_loss: 0.1938 - val_accuracy: 0.9266\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9305 - val_loss: 0.1926 - val_accuracy: 0.9269\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9261 - val_loss: 0.1942 - val_accuracy: 0.9259\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9301 - val_loss: 0.1919 - val_accuracy: 0.9298\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9302 - val_loss: 0.1915 - val_accuracy: 0.9255\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9241 - val_loss: 0.1914 - val_accuracy: 0.9276\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9202 - val_loss: 0.1911 - val_accuracy: 0.9273\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9265 - val_loss: 0.1910 - val_accuracy: 0.9287\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9259 - val_loss: 0.1919 - val_accuracy: 0.9259\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9287 - val_loss: 0.1912 - val_accuracy: 0.9255\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9211 - val_loss: 0.1903 - val_accuracy: 0.9287\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9317 - val_loss: 0.1901 - val_accuracy: 0.9259\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9253 - val_loss: 0.1931 - val_accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9276 - val_loss: 0.1916 - val_accuracy: 0.9259\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9285 - val_loss: 0.1897 - val_accuracy: 0.9280\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9324 - val_loss: 0.1890 - val_accuracy: 0.9290\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9342 - val_loss: 0.1895 - val_accuracy: 0.9298\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9300 - val_loss: 0.1888 - val_accuracy: 0.9266\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9327 - val_loss: 0.1897 - val_accuracy: 0.9269\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9252 - val_loss: 0.1902 - val_accuracy: 0.9262\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9176 - val_loss: 0.1881 - val_accuracy: 0.9259\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9243 - val_loss: 0.1884 - val_accuracy: 0.9298\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9200 - val_loss: 0.1899 - val_accuracy: 0.9245\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9230 - val_loss: 0.1881 - val_accuracy: 0.9283\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9324 - val_loss: 0.1874 - val_accuracy: 0.9301\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9295 - val_loss: 0.1871 - val_accuracy: 0.9280\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9210 - val_loss: 0.1877 - val_accuracy: 0.9287\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9219 - val_loss: 0.1870 - val_accuracy: 0.9280\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9246 - val_loss: 0.1867 - val_accuracy: 0.9294\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9333 - val_loss: 0.1872 - val_accuracy: 0.9273\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9284 - val_loss: 0.1862 - val_accuracy: 0.9298\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9331 - val_loss: 0.1862 - val_accuracy: 0.9283\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9303 - val_loss: 0.1862 - val_accuracy: 0.9308\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9289 - val_loss: 0.1859 - val_accuracy: 0.9305\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9292 - val_loss: 0.1859 - val_accuracy: 0.9294\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9297 - val_loss: 0.1857 - val_accuracy: 0.9290\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9248 - val_loss: 0.1854 - val_accuracy: 0.9294\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9221 - val_loss: 0.1852 - val_accuracy: 0.9283\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9305 - val_loss: 0.1860 - val_accuracy: 0.9280\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9367 - val_loss: 0.1855 - val_accuracy: 0.9276\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9329 - val_loss: 0.1865 - val_accuracy: 0.9252\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9323 - val_loss: 0.1876 - val_accuracy: 0.9308\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9335 - val_loss: 0.1855 - val_accuracy: 0.9308\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9269 - val_loss: 0.1849 - val_accuracy: 0.9308\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9305 - val_loss: 0.1848 - val_accuracy: 0.9294\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9334 - val_loss: 0.1855 - val_accuracy: 0.9273\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9246 - val_loss: 0.1849 - val_accuracy: 0.9273\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9306 - val_loss: 0.1845 - val_accuracy: 0.9290\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9242 - val_loss: 0.1865 - val_accuracy: 0.9301\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9218 - val_loss: 0.1853 - val_accuracy: 0.9294\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9292 - val_loss: 0.1838 - val_accuracy: 0.9308\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.9316 - val_loss: 0.1844 - val_accuracy: 0.9294\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9249 - val_loss: 0.1842 - val_accuracy: 0.9312\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9338 - val_loss: 0.1840 - val_accuracy: 0.9322\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9302 - val_loss: 0.1841 - val_accuracy: 0.9283\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9184 - val_loss: 0.1845 - val_accuracy: 0.9301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9325 - val_loss: 0.1855 - val_accuracy: 0.9301\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9292 - val_loss: 0.1835 - val_accuracy: 0.9298\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9364 - val_loss: 0.1848 - val_accuracy: 0.9259\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9250 - val_loss: 0.1838 - val_accuracy: 0.9283\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9237 - val_loss: 0.1835 - val_accuracy: 0.9301\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9271 - val_loss: 0.1835 - val_accuracy: 0.9326\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9295 - val_loss: 0.1834 - val_accuracy: 0.9308\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9376 - val_loss: 0.1843 - val_accuracy: 0.9269\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9215 - val_loss: 0.1856 - val_accuracy: 0.9298\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9332 - val_loss: 0.1832 - val_accuracy: 0.9298\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9283 - val_loss: 0.1834 - val_accuracy: 0.9305\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9315 - val_loss: 0.1842 - val_accuracy: 0.9333\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9257 - val_loss: 0.1834 - val_accuracy: 0.9298\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9224 - val_loss: 0.1830 - val_accuracy: 0.9315\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9303 - val_loss: 0.1833 - val_accuracy: 0.9308\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.9298 - val_loss: 0.1835 - val_accuracy: 0.9319\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9327 - val_loss: 0.1834 - val_accuracy: 0.9276\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9362 - val_loss: 0.1831 - val_accuracy: 0.9298\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.9291 - val_loss: 0.1837 - val_accuracy: 0.9308\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9188 - val_loss: 0.1834 - val_accuracy: 0.9301\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9341 - val_loss: 0.1828 - val_accuracy: 0.9336\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9233 - val_loss: 0.1832 - val_accuracy: 0.9301\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9267 - val_loss: 0.1839 - val_accuracy: 0.9283\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9242 - val_loss: 0.1823 - val_accuracy: 0.9298\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9314 - val_loss: 0.1838 - val_accuracy: 0.9294\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9348 - val_loss: 0.1820 - val_accuracy: 0.9312\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9369 - val_loss: 0.1823 - val_accuracy: 0.9315\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9234 - val_loss: 0.1824 - val_accuracy: 0.9305\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9351 - val_loss: 0.1820 - val_accuracy: 0.9308\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9276 - val_loss: 0.1821 - val_accuracy: 0.9294\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9360 - val_loss: 0.1816 - val_accuracy: 0.9305\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9294 - val_loss: 0.1823 - val_accuracy: 0.9312\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9256 - val_loss: 0.1818 - val_accuracy: 0.9308\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9352 - val_loss: 0.1818 - val_accuracy: 0.9319\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9349 - val_loss: 0.1819 - val_accuracy: 0.9329\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9320 - val_loss: 0.1825 - val_accuracy: 0.9333\n",
      "2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.5034 - accuracy: 0.8713 - val_loss: 0.2218 - val_accuracy: 0.9175\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9115 - val_loss: 0.2029 - val_accuracy: 0.9220\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.9220 - val_loss: 0.2010 - val_accuracy: 0.9245\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9232 - val_loss: 0.1968 - val_accuracy: 0.9238\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9259 - val_loss: 0.1983 - val_accuracy: 0.9210\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9227 - val_loss: 0.1961 - val_accuracy: 0.9266\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9204 - val_loss: 0.1949 - val_accuracy: 0.9248\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9183 - val_loss: 0.1952 - val_accuracy: 0.9220\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9221 - val_loss: 0.1934 - val_accuracy: 0.9269\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9158 - val_loss: 0.1935 - val_accuracy: 0.9241\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9207 - val_loss: 0.1931 - val_accuracy: 0.9273\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9301 - val_loss: 0.1921 - val_accuracy: 0.9266\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9220 - val_loss: 0.1917 - val_accuracy: 0.9262\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9404 - val_loss: 0.1915 - val_accuracy: 0.9269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9298 - val_loss: 0.1910 - val_accuracy: 0.9294\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9322 - val_loss: 0.1910 - val_accuracy: 0.9290\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9264 - val_loss: 0.1902 - val_accuracy: 0.9273\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9233 - val_loss: 0.1904 - val_accuracy: 0.9276\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9293 - val_loss: 0.1898 - val_accuracy: 0.9280\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9220 - val_loss: 0.1896 - val_accuracy: 0.9280\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9222 - val_loss: 0.1893 - val_accuracy: 0.9273\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9280 - val_loss: 0.1899 - val_accuracy: 0.9266\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9287 - val_loss: 0.1886 - val_accuracy: 0.9287\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9293 - val_loss: 0.1883 - val_accuracy: 0.9283\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9286 - val_loss: 0.1881 - val_accuracy: 0.9280\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9260 - val_loss: 0.1890 - val_accuracy: 0.9255\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9210 - val_loss: 0.1881 - val_accuracy: 0.9283\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9279 - val_loss: 0.1894 - val_accuracy: 0.9248\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1772 - accuracy: 0.9307 - val_loss: 0.1880 - val_accuracy: 0.9276\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9257 - val_loss: 0.1877 - val_accuracy: 0.9273\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9311 - val_loss: 0.1871 - val_accuracy: 0.9298\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9283 - val_loss: 0.1878 - val_accuracy: 0.9298\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9301 - val_loss: 0.1868 - val_accuracy: 0.9287\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9278 - val_loss: 0.1867 - val_accuracy: 0.9287\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9294 - val_loss: 0.1873 - val_accuracy: 0.9266\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9284 - val_loss: 0.1880 - val_accuracy: 0.9287\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9176 - val_loss: 0.1872 - val_accuracy: 0.9305\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9302 - val_loss: 0.1862 - val_accuracy: 0.9305\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9357 - val_loss: 0.1869 - val_accuracy: 0.9290\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9396 - val_loss: 0.1868 - val_accuracy: 0.9255\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9320 - val_loss: 0.1860 - val_accuracy: 0.9308\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9252 - val_loss: 0.1857 - val_accuracy: 0.9280\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.9299 - val_loss: 0.1860 - val_accuracy: 0.9283\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9194 - val_loss: 0.1854 - val_accuracy: 0.9308\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9348 - val_loss: 0.1853 - val_accuracy: 0.9301\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9316 - val_loss: 0.1852 - val_accuracy: 0.9301\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9292 - val_loss: 0.1879 - val_accuracy: 0.9245\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9200 - val_loss: 0.1850 - val_accuracy: 0.9294\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9296 - val_loss: 0.1863 - val_accuracy: 0.9287\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9226 - val_loss: 0.1849 - val_accuracy: 0.9301\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9259 - val_loss: 0.1852 - val_accuracy: 0.9305\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9242 - val_loss: 0.1850 - val_accuracy: 0.9287\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9287 - val_loss: 0.1900 - val_accuracy: 0.9262\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9270 - val_loss: 0.1845 - val_accuracy: 0.9305\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9243 - val_loss: 0.1857 - val_accuracy: 0.9280\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.1852 - val_accuracy: 0.9287\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9283 - val_loss: 0.1854 - val_accuracy: 0.9312\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9294 - val_loss: 0.1847 - val_accuracy: 0.9269\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9294 - val_loss: 0.1840 - val_accuracy: 0.9301\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9267 - val_loss: 0.1841 - val_accuracy: 0.9319\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9284 - val_loss: 0.1849 - val_accuracy: 0.9298\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9303 - val_loss: 0.1839 - val_accuracy: 0.9298\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9151 - val_loss: 0.1848 - val_accuracy: 0.9305\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9287 - val_loss: 0.1843 - val_accuracy: 0.9287\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9289 - val_loss: 0.1836 - val_accuracy: 0.9315\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9236 - val_loss: 0.1842 - val_accuracy: 0.9301\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9238 - val_loss: 0.1835 - val_accuracy: 0.9308\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9328 - val_loss: 0.1838 - val_accuracy: 0.9298\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.9237 - val_loss: 0.1866 - val_accuracy: 0.9231\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9289 - val_loss: 0.1840 - val_accuracy: 0.9308\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9217 - val_loss: 0.1835 - val_accuracy: 0.9308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9275 - val_loss: 0.1833 - val_accuracy: 0.9305\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9394 - val_loss: 0.1833 - val_accuracy: 0.9315\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.9251 - val_loss: 0.1835 - val_accuracy: 0.9315\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9224 - val_loss: 0.1840 - val_accuracy: 0.9308\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9161 - val_loss: 0.1830 - val_accuracy: 0.9301\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9287 - val_loss: 0.1834 - val_accuracy: 0.9280\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.9331 - val_loss: 0.1829 - val_accuracy: 0.9312\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.9217 - val_loss: 0.1845 - val_accuracy: 0.9305\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9327 - val_loss: 0.1835 - val_accuracy: 0.9269\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9378 - val_loss: 0.1851 - val_accuracy: 0.9294\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9277 - val_loss: 0.1828 - val_accuracy: 0.9308\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9290 - val_loss: 0.1825 - val_accuracy: 0.9319\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9265 - val_loss: 0.1828 - val_accuracy: 0.9326\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9345 - val_loss: 0.1830 - val_accuracy: 0.9280\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.9315 - val_loss: 0.1822 - val_accuracy: 0.9322\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9305 - val_loss: 0.1836 - val_accuracy: 0.9280\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9361 - val_loss: 0.1825 - val_accuracy: 0.9315\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9335 - val_loss: 0.1841 - val_accuracy: 0.9312\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.9235 - val_loss: 0.1824 - val_accuracy: 0.9308\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9264 - val_loss: 0.1829 - val_accuracy: 0.9315\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9253 - val_loss: 0.1820 - val_accuracy: 0.9322\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9388 - val_loss: 0.1819 - val_accuracy: 0.9319\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.9312 - val_loss: 0.1817 - val_accuracy: 0.9308\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9360 - val_loss: 0.1844 - val_accuracy: 0.9290\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9270 - val_loss: 0.1841 - val_accuracy: 0.9280\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9355 - val_loss: 0.1823 - val_accuracy: 0.9312\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9298 - val_loss: 0.1858 - val_accuracy: 0.9227\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9256 - val_loss: 0.1817 - val_accuracy: 0.9329\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9304 - val_loss: 0.1815 - val_accuracy: 0.9308\n",
      "3\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 0.5724 - accuracy: 0.7606 - val_loss: 0.2478 - val_accuracy: 0.9094\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9163 - val_loss: 0.2100 - val_accuracy: 0.9189\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9252 - val_loss: 0.2011 - val_accuracy: 0.9206\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.9141 - val_loss: 0.1986 - val_accuracy: 0.9217\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.9274 - val_loss: 0.1980 - val_accuracy: 0.9227\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9283 - val_loss: 0.1968 - val_accuracy: 0.9248\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9319 - val_loss: 0.1973 - val_accuracy: 0.9224\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9185 - val_loss: 0.1969 - val_accuracy: 0.9255\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9210 - val_loss: 0.1943 - val_accuracy: 0.9245\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9243 - val_loss: 0.1939 - val_accuracy: 0.9241\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.9155 - val_loss: 0.1972 - val_accuracy: 0.9196\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9253 - val_loss: 0.1940 - val_accuracy: 0.9266\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9287 - val_loss: 0.1949 - val_accuracy: 0.9210\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9230 - val_loss: 0.1929 - val_accuracy: 0.9248\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9337 - val_loss: 0.1922 - val_accuracy: 0.9273\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9297 - val_loss: 0.1918 - val_accuracy: 0.9266\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9351 - val_loss: 0.1923 - val_accuracy: 0.9245\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9277 - val_loss: 0.1910 - val_accuracy: 0.9266\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9256 - val_loss: 0.1917 - val_accuracy: 0.9276\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9236 - val_loss: 0.1911 - val_accuracy: 0.9248\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9226 - val_loss: 0.1909 - val_accuracy: 0.9241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9265 - val_loss: 0.1906 - val_accuracy: 0.9273\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9293 - val_loss: 0.1905 - val_accuracy: 0.9283\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9195 - val_loss: 0.1901 - val_accuracy: 0.9262\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9152 - val_loss: 0.1907 - val_accuracy: 0.9273\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9215 - val_loss: 0.1900 - val_accuracy: 0.9273\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9215 - val_loss: 0.1894 - val_accuracy: 0.9298\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9199 - val_loss: 0.1899 - val_accuracy: 0.9290\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9222 - val_loss: 0.1897 - val_accuracy: 0.9280\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9279 - val_loss: 0.1890 - val_accuracy: 0.9287\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9236 - val_loss: 0.1889 - val_accuracy: 0.9294\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9284 - val_loss: 0.1886 - val_accuracy: 0.9290\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.9223 - val_loss: 0.1887 - val_accuracy: 0.9266\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9247 - val_loss: 0.1887 - val_accuracy: 0.9248\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9224 - val_loss: 0.1883 - val_accuracy: 0.9273\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9204 - val_loss: 0.1887 - val_accuracy: 0.9283\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9282 - val_loss: 0.1876 - val_accuracy: 0.9301\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9233 - val_loss: 0.1879 - val_accuracy: 0.9280\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9201 - val_loss: 0.1879 - val_accuracy: 0.9276\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9295 - val_loss: 0.1872 - val_accuracy: 0.9290\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9260 - val_loss: 0.1883 - val_accuracy: 0.9287\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9309 - val_loss: 0.1871 - val_accuracy: 0.9298\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9344 - val_loss: 0.1870 - val_accuracy: 0.9290\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9264 - val_loss: 0.1873 - val_accuracy: 0.9280\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9267 - val_loss: 0.1870 - val_accuracy: 0.9290\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9253 - val_loss: 0.1874 - val_accuracy: 0.9269\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9289 - val_loss: 0.1874 - val_accuracy: 0.9276\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9219 - val_loss: 0.1865 - val_accuracy: 0.9290\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9218 - val_loss: 0.1874 - val_accuracy: 0.9241\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9230 - val_loss: 0.1862 - val_accuracy: 0.9294\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9287 - val_loss: 0.1860 - val_accuracy: 0.9290\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9284 - val_loss: 0.1869 - val_accuracy: 0.9287\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9317 - val_loss: 0.1865 - val_accuracy: 0.9276\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9330 - val_loss: 0.1877 - val_accuracy: 0.9266\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9317 - val_loss: 0.1861 - val_accuracy: 0.9276\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9234 - val_loss: 0.1857 - val_accuracy: 0.9290\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9238 - val_loss: 0.1872 - val_accuracy: 0.9276\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9248 - val_loss: 0.1859 - val_accuracy: 0.9283\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9321 - val_loss: 0.1875 - val_accuracy: 0.9305\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9369 - val_loss: 0.1853 - val_accuracy: 0.9308\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9307 - val_loss: 0.1853 - val_accuracy: 0.9287\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9309 - val_loss: 0.1855 - val_accuracy: 0.9305\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9322 - val_loss: 0.1869 - val_accuracy: 0.9241\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9324 - val_loss: 0.1848 - val_accuracy: 0.9308\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9301 - val_loss: 0.1863 - val_accuracy: 0.9262\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9329 - val_loss: 0.1852 - val_accuracy: 0.9294\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.9252 - val_loss: 0.1849 - val_accuracy: 0.9298\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9335 - val_loss: 0.1855 - val_accuracy: 0.9308\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9324 - val_loss: 0.1844 - val_accuracy: 0.9305\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9327 - val_loss: 0.1857 - val_accuracy: 0.9308\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9300 - val_loss: 0.1848 - val_accuracy: 0.9287\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9278 - val_loss: 0.1853 - val_accuracy: 0.9294\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9312 - val_loss: 0.1844 - val_accuracy: 0.9301\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9262 - val_loss: 0.1849 - val_accuracy: 0.9305\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9355 - val_loss: 0.1855 - val_accuracy: 0.9283\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9253 - val_loss: 0.1840 - val_accuracy: 0.9312\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9360 - val_loss: 0.1842 - val_accuracy: 0.9305\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9315 - val_loss: 0.1843 - val_accuracy: 0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1708 - accuracy: 0.9371 - val_loss: 0.1846 - val_accuracy: 0.9276\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9283 - val_loss: 0.1839 - val_accuracy: 0.9319\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9402 - val_loss: 0.1839 - val_accuracy: 0.9326\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9340 - val_loss: 0.1838 - val_accuracy: 0.9298\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9282 - val_loss: 0.1835 - val_accuracy: 0.9322\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9274 - val_loss: 0.1836 - val_accuracy: 0.9308\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9348 - val_loss: 0.1835 - val_accuracy: 0.9326\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9271 - val_loss: 0.1839 - val_accuracy: 0.9290\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9250 - val_loss: 0.1841 - val_accuracy: 0.9322\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9356 - val_loss: 0.1835 - val_accuracy: 0.9308\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9412 - val_loss: 0.1844 - val_accuracy: 0.9326\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9291 - val_loss: 0.1834 - val_accuracy: 0.9308\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9373 - val_loss: 0.1834 - val_accuracy: 0.9305\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9300 - val_loss: 0.1830 - val_accuracy: 0.9305\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9325 - val_loss: 0.1831 - val_accuracy: 0.9312\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9301 - val_loss: 0.1831 - val_accuracy: 0.9312\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9352 - val_loss: 0.1831 - val_accuracy: 0.9315\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9346 - val_loss: 0.1848 - val_accuracy: 0.9234\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9280 - val_loss: 0.1830 - val_accuracy: 0.9322\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9290 - val_loss: 0.1829 - val_accuracy: 0.9315\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9299 - val_loss: 0.1845 - val_accuracy: 0.9276\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9250 - val_loss: 0.1835 - val_accuracy: 0.9301\n",
      "4\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 2s 5ms/step - loss: 0.5493 - accuracy: 0.8061 - val_loss: 0.2331 - val_accuracy: 0.9150\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9210 - val_loss: 0.2088 - val_accuracy: 0.9210\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9140 - val_loss: 0.2021 - val_accuracy: 0.9210\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9186 - val_loss: 0.1981 - val_accuracy: 0.9248\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9261 - val_loss: 0.1973 - val_accuracy: 0.9238\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9271 - val_loss: 0.1961 - val_accuracy: 0.9234\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9187 - val_loss: 0.1948 - val_accuracy: 0.9245\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9234 - val_loss: 0.1940 - val_accuracy: 0.9259\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9294 - val_loss: 0.1941 - val_accuracy: 0.9259\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9297 - val_loss: 0.1933 - val_accuracy: 0.9245\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9224 - val_loss: 0.1925 - val_accuracy: 0.9287\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9320 - val_loss: 0.1918 - val_accuracy: 0.9262\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9247 - val_loss: 0.1918 - val_accuracy: 0.9290\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9197 - val_loss: 0.1911 - val_accuracy: 0.9269\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9365 - val_loss: 0.1951 - val_accuracy: 0.9276\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9335 - val_loss: 0.1916 - val_accuracy: 0.9248\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9229 - val_loss: 0.1907 - val_accuracy: 0.9255\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9255 - val_loss: 0.1907 - val_accuracy: 0.9266\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9290 - val_loss: 0.1905 - val_accuracy: 0.9266\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9295 - val_loss: 0.1910 - val_accuracy: 0.9238\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9248 - val_loss: 0.1916 - val_accuracy: 0.9227\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9272 - val_loss: 0.1897 - val_accuracy: 0.9269\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9245 - val_loss: 0.1892 - val_accuracy: 0.9280\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9294 - val_loss: 0.1903 - val_accuracy: 0.9262\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9344 - val_loss: 0.1903 - val_accuracy: 0.9301\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9266 - val_loss: 0.1883 - val_accuracy: 0.9287\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9298 - val_loss: 0.1883 - val_accuracy: 0.9280\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9252 - val_loss: 0.1882 - val_accuracy: 0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9321 - val_loss: 0.1881 - val_accuracy: 0.9287\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9353 - val_loss: 0.1897 - val_accuracy: 0.9269\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9346 - val_loss: 0.1895 - val_accuracy: 0.9238\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9231 - val_loss: 0.1879 - val_accuracy: 0.9273\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9334 - val_loss: 0.1873 - val_accuracy: 0.9287\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9324 - val_loss: 0.1883 - val_accuracy: 0.9245\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9323 - val_loss: 0.1872 - val_accuracy: 0.9287\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9274 - val_loss: 0.1861 - val_accuracy: 0.9294\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9203 - val_loss: 0.1864 - val_accuracy: 0.9290\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9214 - val_loss: 0.1884 - val_accuracy: 0.9287\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9252 - val_loss: 0.1869 - val_accuracy: 0.9283\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9355 - val_loss: 0.1868 - val_accuracy: 0.9294\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9342 - val_loss: 0.1861 - val_accuracy: 0.9290\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9340 - val_loss: 0.1860 - val_accuracy: 0.9305\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9336 - val_loss: 0.1855 - val_accuracy: 0.9290\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9335 - val_loss: 0.1852 - val_accuracy: 0.9308\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9277 - val_loss: 0.1850 - val_accuracy: 0.9298\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9320 - val_loss: 0.1860 - val_accuracy: 0.9273\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9319 - val_loss: 0.1860 - val_accuracy: 0.9326\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9306 - val_loss: 0.1861 - val_accuracy: 0.9276\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9317 - val_loss: 0.1846 - val_accuracy: 0.9283\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9262 - val_loss: 0.1889 - val_accuracy: 0.9245\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9309 - val_loss: 0.1857 - val_accuracy: 0.9298\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9261 - val_loss: 0.1851 - val_accuracy: 0.9280\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9319 - val_loss: 0.1842 - val_accuracy: 0.9298\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9287 - val_loss: 0.1849 - val_accuracy: 0.9276\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9358 - val_loss: 0.1848 - val_accuracy: 0.9294\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9297 - val_loss: 0.1843 - val_accuracy: 0.9301\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9233 - val_loss: 0.1853 - val_accuracy: 0.9276\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9248 - val_loss: 0.1839 - val_accuracy: 0.9287\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9154 - val_loss: 0.1842 - val_accuracy: 0.9276\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9248 - val_loss: 0.1849 - val_accuracy: 0.9283\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9266 - val_loss: 0.1856 - val_accuracy: 0.9255\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9211 - val_loss: 0.1841 - val_accuracy: 0.9298\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9330 - val_loss: 0.1837 - val_accuracy: 0.9301\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9265 - val_loss: 0.1842 - val_accuracy: 0.9276\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9294 - val_loss: 0.1835 - val_accuracy: 0.9298\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9284 - val_loss: 0.1838 - val_accuracy: 0.9280\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9174 - val_loss: 0.1845 - val_accuracy: 0.9283\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9171 - val_loss: 0.1851 - val_accuracy: 0.9290\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9167 - val_loss: 0.1847 - val_accuracy: 0.9290\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9199 - val_loss: 0.1890 - val_accuracy: 0.9238\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9312 - val_loss: 0.1830 - val_accuracy: 0.9301\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9320 - val_loss: 0.1844 - val_accuracy: 0.9329\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9255 - val_loss: 0.1844 - val_accuracy: 0.9283\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9243 - val_loss: 0.1830 - val_accuracy: 0.9290\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9308 - val_loss: 0.1826 - val_accuracy: 0.9298\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9286 - val_loss: 0.1830 - val_accuracy: 0.9308\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9346 - val_loss: 0.1863 - val_accuracy: 0.9280\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9255 - val_loss: 0.1827 - val_accuracy: 0.9308\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9266 - val_loss: 0.1834 - val_accuracy: 0.9287\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9204 - val_loss: 0.1835 - val_accuracy: 0.9287\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9294 - val_loss: 0.1824 - val_accuracy: 0.9287\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9331 - val_loss: 0.1823 - val_accuracy: 0.9298\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9336 - val_loss: 0.1823 - val_accuracy: 0.9294\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9324 - val_loss: 0.1826 - val_accuracy: 0.9298\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9371 - val_loss: 0.1823 - val_accuracy: 0.9308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9360 - val_loss: 0.1821 - val_accuracy: 0.9312\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9207 - val_loss: 0.1839 - val_accuracy: 0.9280\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9259 - val_loss: 0.1834 - val_accuracy: 0.9283\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9287 - val_loss: 0.1834 - val_accuracy: 0.9287\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9367 - val_loss: 0.1820 - val_accuracy: 0.9301\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9250 - val_loss: 0.1817 - val_accuracy: 0.9308\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9261 - val_loss: 0.1840 - val_accuracy: 0.9290\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9271 - val_loss: 0.1813 - val_accuracy: 0.9305\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9359 - val_loss: 0.1835 - val_accuracy: 0.9298\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9278 - val_loss: 0.1820 - val_accuracy: 0.9308\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9337 - val_loss: 0.1826 - val_accuracy: 0.9340\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9353 - val_loss: 0.1822 - val_accuracy: 0.9326\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9299 - val_loss: 0.1809 - val_accuracy: 0.9315\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9306 - val_loss: 0.1805 - val_accuracy: 0.9322\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9253 - val_loss: 0.1807 - val_accuracy: 0.9326\n",
      "5\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.8399 - val_loss: 0.2321 - val_accuracy: 0.9111\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9094 - val_loss: 0.2091 - val_accuracy: 0.9210\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9349 - val_loss: 0.1999 - val_accuracy: 0.9245\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9246 - val_loss: 0.1985 - val_accuracy: 0.9238\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9227 - val_loss: 0.1965 - val_accuracy: 0.9259\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9241 - val_loss: 0.2011 - val_accuracy: 0.9255\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9225 - val_loss: 0.1944 - val_accuracy: 0.9259\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9135 - val_loss: 0.1976 - val_accuracy: 0.9189\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9101 - val_loss: 0.1941 - val_accuracy: 0.9248\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9288 - val_loss: 0.1939 - val_accuracy: 0.9220\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9215 - val_loss: 0.1929 - val_accuracy: 0.9241\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9352 - val_loss: 0.1973 - val_accuracy: 0.9259\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9233 - val_loss: 0.1932 - val_accuracy: 0.9241\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9214 - val_loss: 0.1951 - val_accuracy: 0.9192\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9166 - val_loss: 0.1946 - val_accuracy: 0.9266\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9250 - val_loss: 0.1935 - val_accuracy: 0.9273\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9274 - val_loss: 0.1915 - val_accuracy: 0.9248\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9245 - val_loss: 0.1920 - val_accuracy: 0.9224\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9226 - val_loss: 0.1925 - val_accuracy: 0.9273\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9185 - val_loss: 0.1914 - val_accuracy: 0.9262\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9188 - val_loss: 0.1921 - val_accuracy: 0.9266\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9238 - val_loss: 0.1906 - val_accuracy: 0.9283\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9245 - val_loss: 0.1901 - val_accuracy: 0.9283\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9336 - val_loss: 0.1900 - val_accuracy: 0.9269\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9284 - val_loss: 0.1901 - val_accuracy: 0.9273\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9247 - val_loss: 0.1902 - val_accuracy: 0.9262\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9205 - val_loss: 0.1897 - val_accuracy: 0.9245\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9287 - val_loss: 0.1894 - val_accuracy: 0.9290\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9221 - val_loss: 0.1897 - val_accuracy: 0.9259\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9152 - val_loss: 0.1943 - val_accuracy: 0.9199\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9125 - val_loss: 0.1908 - val_accuracy: 0.9245\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9276 - val_loss: 0.1892 - val_accuracy: 0.9280\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9180 - val_loss: 0.1885 - val_accuracy: 0.9276\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9253 - val_loss: 0.1885 - val_accuracy: 0.9294\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9272 - val_loss: 0.1890 - val_accuracy: 0.9276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9236 - val_loss: 0.1882 - val_accuracy: 0.9273\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9208 - val_loss: 0.1919 - val_accuracy: 0.9220\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9297 - val_loss: 0.1891 - val_accuracy: 0.9298\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9316 - val_loss: 0.1877 - val_accuracy: 0.9283\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9197 - val_loss: 0.1883 - val_accuracy: 0.9269\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9318 - val_loss: 0.1879 - val_accuracy: 0.9262\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9246 - val_loss: 0.1877 - val_accuracy: 0.9287\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9283 - val_loss: 0.1875 - val_accuracy: 0.9298\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9242 - val_loss: 0.1892 - val_accuracy: 0.9280\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9295 - val_loss: 0.1871 - val_accuracy: 0.9298\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9261 - val_loss: 0.1873 - val_accuracy: 0.9280\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9309 - val_loss: 0.1871 - val_accuracy: 0.9276\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9275 - val_loss: 0.1869 - val_accuracy: 0.9290\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9298 - val_loss: 0.1883 - val_accuracy: 0.9238\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9236 - val_loss: 0.1869 - val_accuracy: 0.9290\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9217 - val_loss: 0.1875 - val_accuracy: 0.9294\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9290 - val_loss: 0.1863 - val_accuracy: 0.9308\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9355 - val_loss: 0.1869 - val_accuracy: 0.9294\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9304 - val_loss: 0.1877 - val_accuracy: 0.9280\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9273 - val_loss: 0.1861 - val_accuracy: 0.9287\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9284 - val_loss: 0.1905 - val_accuracy: 0.9280\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9368 - val_loss: 0.1860 - val_accuracy: 0.9287\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9293 - val_loss: 0.1859 - val_accuracy: 0.9294\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9258 - val_loss: 0.1857 - val_accuracy: 0.9298\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9367 - val_loss: 0.1859 - val_accuracy: 0.9294\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9341 - val_loss: 0.1854 - val_accuracy: 0.9301\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9282 - val_loss: 0.1856 - val_accuracy: 0.9294\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9269 - val_loss: 0.1856 - val_accuracy: 0.9276\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9265 - val_loss: 0.1854 - val_accuracy: 0.9294\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9259 - val_loss: 0.1854 - val_accuracy: 0.9269\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9349 - val_loss: 0.1850 - val_accuracy: 0.9308\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9293 - val_loss: 0.1851 - val_accuracy: 0.9283\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9334 - val_loss: 0.1849 - val_accuracy: 0.9305\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9292 - val_loss: 0.1866 - val_accuracy: 0.9315\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9301 - val_loss: 0.1930 - val_accuracy: 0.9283\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9323 - val_loss: 0.1875 - val_accuracy: 0.9319\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9343 - val_loss: 0.1844 - val_accuracy: 0.9305\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9296 - val_loss: 0.1843 - val_accuracy: 0.9301\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9279 - val_loss: 0.1887 - val_accuracy: 0.9248\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9290 - val_loss: 0.1844 - val_accuracy: 0.9315\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9258 - val_loss: 0.1841 - val_accuracy: 0.9290\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9288 - val_loss: 0.1851 - val_accuracy: 0.9252\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9228 - val_loss: 0.1841 - val_accuracy: 0.9319\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9270 - val_loss: 0.1842 - val_accuracy: 0.9301\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9263 - val_loss: 0.1851 - val_accuracy: 0.9283\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9245 - val_loss: 0.1839 - val_accuracy: 0.9312\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9269 - val_loss: 0.1841 - val_accuracy: 0.9298\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9310 - val_loss: 0.1837 - val_accuracy: 0.9298\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9286 - val_loss: 0.1838 - val_accuracy: 0.9301\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9210 - val_loss: 0.1838 - val_accuracy: 0.9315\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9358 - val_loss: 0.1836 - val_accuracy: 0.9301\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9253 - val_loss: 0.1837 - val_accuracy: 0.9298\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9260 - val_loss: 0.1836 - val_accuracy: 0.9305\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9253 - val_loss: 0.1850 - val_accuracy: 0.9298\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9277 - val_loss: 0.1838 - val_accuracy: 0.9283\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9300 - val_loss: 0.1841 - val_accuracy: 0.9322\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9336 - val_loss: 0.1836 - val_accuracy: 0.9294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9242 - val_loss: 0.1831 - val_accuracy: 0.9308\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9317 - val_loss: 0.1838 - val_accuracy: 0.9298\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9276 - val_loss: 0.1886 - val_accuracy: 0.9238\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9249 - val_loss: 0.1835 - val_accuracy: 0.9301\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9303 - val_loss: 0.1829 - val_accuracy: 0.9298\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9257 - val_loss: 0.1837 - val_accuracy: 0.9283\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9299 - val_loss: 0.1884 - val_accuracy: 0.9301\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9277 - val_loss: 0.1829 - val_accuracy: 0.9305\n",
      "6\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 2s 4ms/step - loss: 0.6081 - accuracy: 0.6863 - val_loss: 0.2624 - val_accuracy: 0.9087\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9196 - val_loss: 0.2156 - val_accuracy: 0.9199\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9195 - val_loss: 0.2037 - val_accuracy: 0.9192\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9151 - val_loss: 0.2002 - val_accuracy: 0.9203\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9194 - val_loss: 0.1997 - val_accuracy: 0.9245\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9277 - val_loss: 0.1964 - val_accuracy: 0.9259\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9211 - val_loss: 0.1964 - val_accuracy: 0.9245\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9189 - val_loss: 0.1975 - val_accuracy: 0.9196\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9214 - val_loss: 0.1949 - val_accuracy: 0.9259\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9266 - val_loss: 0.1943 - val_accuracy: 0.9241\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9281 - val_loss: 0.1932 - val_accuracy: 0.9266\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9203 - val_loss: 0.1929 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9262 - val_loss: 0.1930 - val_accuracy: 0.9259\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9213 - val_loss: 0.1923 - val_accuracy: 0.9262\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9297 - val_loss: 0.1926 - val_accuracy: 0.9252\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9246 - val_loss: 0.1930 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9225 - val_loss: 0.1912 - val_accuracy: 0.9269\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9256 - val_loss: 0.1925 - val_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9275 - val_loss: 0.1912 - val_accuracy: 0.9252\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9260 - val_loss: 0.1908 - val_accuracy: 0.9269\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9321 - val_loss: 0.1907 - val_accuracy: 0.9294\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9200 - val_loss: 0.1905 - val_accuracy: 0.9266\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9311 - val_loss: 0.1911 - val_accuracy: 0.9238\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9290 - val_loss: 0.1899 - val_accuracy: 0.9276\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9272 - val_loss: 0.1914 - val_accuracy: 0.9252\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9249 - val_loss: 0.1900 - val_accuracy: 0.9269\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9221 - val_loss: 0.1901 - val_accuracy: 0.9283\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9333 - val_loss: 0.1895 - val_accuracy: 0.9276\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9294 - val_loss: 0.1895 - val_accuracy: 0.9248\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9217 - val_loss: 0.1895 - val_accuracy: 0.9248\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9281 - val_loss: 0.1920 - val_accuracy: 0.9220\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9246 - val_loss: 0.1887 - val_accuracy: 0.9276\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9268 - val_loss: 0.1893 - val_accuracy: 0.9245\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9212 - val_loss: 0.1884 - val_accuracy: 0.9290\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9333 - val_loss: 0.1878 - val_accuracy: 0.9287\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9213 - val_loss: 0.1875 - val_accuracy: 0.9287\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.9202 - val_loss: 0.1882 - val_accuracy: 0.9273\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9312 - val_loss: 0.1874 - val_accuracy: 0.9294\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9190 - val_loss: 0.1884 - val_accuracy: 0.9283\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9263 - val_loss: 0.1873 - val_accuracy: 0.9283\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9279 - val_loss: 0.1883 - val_accuracy: 0.9262\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9246 - val_loss: 0.1881 - val_accuracy: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9263 - val_loss: 0.1870 - val_accuracy: 0.9294\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1733 - accuracy: 0.9331 - val_loss: 0.1868 - val_accuracy: 0.9322\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9327 - val_loss: 0.1865 - val_accuracy: 0.9290\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9334 - val_loss: 0.1866 - val_accuracy: 0.9301\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9237 - val_loss: 0.1862 - val_accuracy: 0.9280\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9227 - val_loss: 0.1863 - val_accuracy: 0.9298\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9312 - val_loss: 0.1870 - val_accuracy: 0.9287\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9233 - val_loss: 0.1858 - val_accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9279 - val_loss: 0.1857 - val_accuracy: 0.9301\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9275 - val_loss: 0.1862 - val_accuracy: 0.9305\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9323 - val_loss: 0.1865 - val_accuracy: 0.9312\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9378 - val_loss: 0.1853 - val_accuracy: 0.9312\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9331 - val_loss: 0.1856 - val_accuracy: 0.9273\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9226 - val_loss: 0.1874 - val_accuracy: 0.9231\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9208 - val_loss: 0.1852 - val_accuracy: 0.9298\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9355 - val_loss: 0.1859 - val_accuracy: 0.9301\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9344 - val_loss: 0.1849 - val_accuracy: 0.9308\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9309 - val_loss: 0.1849 - val_accuracy: 0.9305\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9269 - val_loss: 0.1850 - val_accuracy: 0.9280\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9292 - val_loss: 0.1859 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9272 - val_loss: 0.1841 - val_accuracy: 0.9305\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9354 - val_loss: 0.1852 - val_accuracy: 0.9283\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9350 - val_loss: 0.1843 - val_accuracy: 0.9308\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9352 - val_loss: 0.1847 - val_accuracy: 0.9312\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9300 - val_loss: 0.1843 - val_accuracy: 0.9294\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9307 - val_loss: 0.1837 - val_accuracy: 0.9308\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9308 - val_loss: 0.1834 - val_accuracy: 0.9308\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9323 - val_loss: 0.1836 - val_accuracy: 0.9312\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9343 - val_loss: 0.1842 - val_accuracy: 0.9308\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9364 - val_loss: 0.1850 - val_accuracy: 0.9319\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9271 - val_loss: 0.1839 - val_accuracy: 0.9298\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9326 - val_loss: 0.1843 - val_accuracy: 0.9294\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9275 - val_loss: 0.1836 - val_accuracy: 0.9294\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9285 - val_loss: 0.1833 - val_accuracy: 0.9312\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9252 - val_loss: 0.1859 - val_accuracy: 0.9287\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9375 - val_loss: 0.1830 - val_accuracy: 0.9305\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9318 - val_loss: 0.1830 - val_accuracy: 0.9290\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9279 - val_loss: 0.1829 - val_accuracy: 0.9298\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9207 - val_loss: 0.1826 - val_accuracy: 0.9322\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9320 - val_loss: 0.1824 - val_accuracy: 0.9301\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9235 - val_loss: 0.1831 - val_accuracy: 0.9305\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9383 - val_loss: 0.1820 - val_accuracy: 0.9319\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9299 - val_loss: 0.1821 - val_accuracy: 0.9329\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9303 - val_loss: 0.1827 - val_accuracy: 0.9298\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9304 - val_loss: 0.1820 - val_accuracy: 0.9301\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9314 - val_loss: 0.1824 - val_accuracy: 0.9290\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9250 - val_loss: 0.1823 - val_accuracy: 0.9319\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9241 - val_loss: 0.1815 - val_accuracy: 0.9315\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9323 - val_loss: 0.1816 - val_accuracy: 0.9322\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9301 - val_loss: 0.1814 - val_accuracy: 0.9322\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9302 - val_loss: 0.1827 - val_accuracy: 0.9322\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9299 - val_loss: 0.1823 - val_accuracy: 0.9315\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9418 - val_loss: 0.1817 - val_accuracy: 0.9329\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9349 - val_loss: 0.1813 - val_accuracy: 0.9315\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9342 - val_loss: 0.1818 - val_accuracy: 0.9315\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9259 - val_loss: 0.1809 - val_accuracy: 0.9315\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9275 - val_loss: 0.1824 - val_accuracy: 0.9294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9235 - val_loss: 0.1809 - val_accuracy: 0.9319\n",
      "7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.5193 - accuracy: 0.8949 - val_loss: 0.2267 - val_accuracy: 0.9101\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9098 - val_loss: 0.2047 - val_accuracy: 0.9199\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9129 - val_loss: 0.1995 - val_accuracy: 0.9206\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9197 - val_loss: 0.1967 - val_accuracy: 0.9245\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9181 - val_loss: 0.1959 - val_accuracy: 0.9245\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9283 - val_loss: 0.1978 - val_accuracy: 0.9241\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9151 - val_loss: 0.1945 - val_accuracy: 0.9255\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9191 - val_loss: 0.1936 - val_accuracy: 0.9262\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9256 - val_loss: 0.1926 - val_accuracy: 0.9273\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9247 - val_loss: 0.1929 - val_accuracy: 0.9259\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9214 - val_loss: 0.1931 - val_accuracy: 0.9269\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9282 - val_loss: 0.1914 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9298 - val_loss: 0.1911 - val_accuracy: 0.9273\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9266 - val_loss: 0.1931 - val_accuracy: 0.9280\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9262 - val_loss: 0.1909 - val_accuracy: 0.9273\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9187 - val_loss: 0.1922 - val_accuracy: 0.9252\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9283 - val_loss: 0.1897 - val_accuracy: 0.9273\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9262 - val_loss: 0.1901 - val_accuracy: 0.9273\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9304 - val_loss: 0.1908 - val_accuracy: 0.9255\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9308 - val_loss: 0.1895 - val_accuracy: 0.9276\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9275 - val_loss: 0.1891 - val_accuracy: 0.9298\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9314 - val_loss: 0.1886 - val_accuracy: 0.9287\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9218 - val_loss: 0.1889 - val_accuracy: 0.9276\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9153 - val_loss: 0.1895 - val_accuracy: 0.9269\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9244 - val_loss: 0.1883 - val_accuracy: 0.9298\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9405 - val_loss: 0.1881 - val_accuracy: 0.9262\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9326 - val_loss: 0.1883 - val_accuracy: 0.9266\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9256 - val_loss: 0.1873 - val_accuracy: 0.9273\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9202 - val_loss: 0.1868 - val_accuracy: 0.9283\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9290 - val_loss: 0.1868 - val_accuracy: 0.9298\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9288 - val_loss: 0.1868 - val_accuracy: 0.9290\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9242 - val_loss: 0.1863 - val_accuracy: 0.9301\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9297 - val_loss: 0.1864 - val_accuracy: 0.9273\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9302 - val_loss: 0.1865 - val_accuracy: 0.9287\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9272 - val_loss: 0.1865 - val_accuracy: 0.9298\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9296 - val_loss: 0.1856 - val_accuracy: 0.9294\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9258 - val_loss: 0.1897 - val_accuracy: 0.9269\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9180 - val_loss: 0.1865 - val_accuracy: 0.9273\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9352 - val_loss: 0.1862 - val_accuracy: 0.9322\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9359 - val_loss: 0.1864 - val_accuracy: 0.9269\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9248 - val_loss: 0.1856 - val_accuracy: 0.9287\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9308 - val_loss: 0.1870 - val_accuracy: 0.9252\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9238 - val_loss: 0.1849 - val_accuracy: 0.9305\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9330 - val_loss: 0.1865 - val_accuracy: 0.9245\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9208 - val_loss: 0.1882 - val_accuracy: 0.9283\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9288 - val_loss: 0.1853 - val_accuracy: 0.9287\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9201 - val_loss: 0.1850 - val_accuracy: 0.9319\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9306 - val_loss: 0.1847 - val_accuracy: 0.9276\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9282 - val_loss: 0.1860 - val_accuracy: 0.9294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9295 - val_loss: 0.1843 - val_accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9242 - val_loss: 0.1840 - val_accuracy: 0.9290\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9303 - val_loss: 0.1856 - val_accuracy: 0.9315\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9318 - val_loss: 0.1849 - val_accuracy: 0.9301\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.1842 - val_accuracy: 0.9308\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9251 - val_loss: 0.1839 - val_accuracy: 0.9298\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9276 - val_loss: 0.1848 - val_accuracy: 0.9280\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9333 - val_loss: 0.1852 - val_accuracy: 0.9290\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9307 - val_loss: 0.1842 - val_accuracy: 0.9315\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9367 - val_loss: 0.1834 - val_accuracy: 0.9308\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9323 - val_loss: 0.1832 - val_accuracy: 0.9298\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9317 - val_loss: 0.1844 - val_accuracy: 0.9298\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9272 - val_loss: 0.1839 - val_accuracy: 0.9269\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9311 - val_loss: 0.1834 - val_accuracy: 0.9294\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9317 - val_loss: 0.1840 - val_accuracy: 0.9280\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9277 - val_loss: 0.1832 - val_accuracy: 0.9290\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9333 - val_loss: 0.1830 - val_accuracy: 0.9308\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9245 - val_loss: 0.1830 - val_accuracy: 0.9305\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9376 - val_loss: 0.1831 - val_accuracy: 0.9301\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9266 - val_loss: 0.1826 - val_accuracy: 0.9308\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9320 - val_loss: 0.1825 - val_accuracy: 0.9319\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9303 - val_loss: 0.1833 - val_accuracy: 0.9315\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9297 - val_loss: 0.1838 - val_accuracy: 0.9290\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9363 - val_loss: 0.1824 - val_accuracy: 0.9305\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9294 - val_loss: 0.1829 - val_accuracy: 0.9312\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9291 - val_loss: 0.1834 - val_accuracy: 0.9298\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9265 - val_loss: 0.1824 - val_accuracy: 0.9305\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9188 - val_loss: 0.1826 - val_accuracy: 0.9319\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9391 - val_loss: 0.1826 - val_accuracy: 0.9312\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9338 - val_loss: 0.1822 - val_accuracy: 0.9298\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9305 - val_loss: 0.1826 - val_accuracy: 0.9294\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9344 - val_loss: 0.1818 - val_accuracy: 0.9319\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9344 - val_loss: 0.1822 - val_accuracy: 0.9308\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9313 - val_loss: 0.1822 - val_accuracy: 0.9301\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9276 - val_loss: 0.1816 - val_accuracy: 0.9326\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9235 - val_loss: 0.1818 - val_accuracy: 0.9322\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9199 - val_loss: 0.1823 - val_accuracy: 0.9315\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9283 - val_loss: 0.1815 - val_accuracy: 0.9322\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9319 - val_loss: 0.1819 - val_accuracy: 0.9298\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9370 - val_loss: 0.1817 - val_accuracy: 0.9319\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9358 - val_loss: 0.1842 - val_accuracy: 0.9298\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9242 - val_loss: 0.1828 - val_accuracy: 0.9294\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9250 - val_loss: 0.1814 - val_accuracy: 0.9322\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9264 - val_loss: 0.1829 - val_accuracy: 0.9287\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9331 - val_loss: 0.1844 - val_accuracy: 0.9326\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9258 - val_loss: 0.1814 - val_accuracy: 0.9294\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9283 - val_loss: 0.1847 - val_accuracy: 0.9273\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9281 - val_loss: 0.1839 - val_accuracy: 0.9294\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9348 - val_loss: 0.1819 - val_accuracy: 0.9294\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9285 - val_loss: 0.1820 - val_accuracy: 0.9287\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9277 - val_loss: 0.1815 - val_accuracy: 0.9326\n",
      "8\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 1s 4ms/step - loss: 0.4647 - accuracy: 0.9036 - val_loss: 0.2221 - val_accuracy: 0.9168\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9169 - val_loss: 0.2034 - val_accuracy: 0.9213\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9215 - val_loss: 0.1994 - val_accuracy: 0.9217\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9196 - val_loss: 0.1988 - val_accuracy: 0.9241\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9319 - val_loss: 0.1974 - val_accuracy: 0.9248\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9287 - val_loss: 0.1970 - val_accuracy: 0.9255\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9223 - val_loss: 0.1957 - val_accuracy: 0.9248\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9269 - val_loss: 0.1980 - val_accuracy: 0.9206\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9091 - val_loss: 0.1964 - val_accuracy: 0.9220\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9220 - val_loss: 0.1939 - val_accuracy: 0.9255\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9260 - val_loss: 0.1942 - val_accuracy: 0.9227\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9231 - val_loss: 0.1936 - val_accuracy: 0.9241\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9276 - val_loss: 0.1928 - val_accuracy: 0.9245\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9284 - val_loss: 0.1923 - val_accuracy: 0.9255\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9251 - val_loss: 0.1929 - val_accuracy: 0.9238\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9237 - val_loss: 0.1919 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9192 - val_loss: 0.1921 - val_accuracy: 0.9238\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9210 - val_loss: 0.1933 - val_accuracy: 0.9227\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9128 - val_loss: 0.1908 - val_accuracy: 0.9287\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9249 - val_loss: 0.1920 - val_accuracy: 0.9273\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9227 - val_loss: 0.1911 - val_accuracy: 0.9266\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9240 - val_loss: 0.1903 - val_accuracy: 0.9276\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9348 - val_loss: 0.1915 - val_accuracy: 0.9266\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9214 - val_loss: 0.1914 - val_accuracy: 0.9266\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9248 - val_loss: 0.1900 - val_accuracy: 0.9276\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9303 - val_loss: 0.1902 - val_accuracy: 0.9273\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9309 - val_loss: 0.1899 - val_accuracy: 0.9273\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9302 - val_loss: 0.1892 - val_accuracy: 0.9294\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9248 - val_loss: 0.1892 - val_accuracy: 0.9305\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9292 - val_loss: 0.1895 - val_accuracy: 0.9280\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9295 - val_loss: 0.1894 - val_accuracy: 0.9266\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9265 - val_loss: 0.1897 - val_accuracy: 0.9255\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9242 - val_loss: 0.1881 - val_accuracy: 0.9287\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9318 - val_loss: 0.1902 - val_accuracy: 0.9312\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9322 - val_loss: 0.1886 - val_accuracy: 0.9273\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9236 - val_loss: 0.1886 - val_accuracy: 0.9280\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9286 - val_loss: 0.1876 - val_accuracy: 0.9280\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9279 - val_loss: 0.1874 - val_accuracy: 0.9276\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9232 - val_loss: 0.1870 - val_accuracy: 0.9294\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9230 - val_loss: 0.1884 - val_accuracy: 0.9266\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9264 - val_loss: 0.1888 - val_accuracy: 0.9266\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9324 - val_loss: 0.1876 - val_accuracy: 0.9319\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9266 - val_loss: 0.1870 - val_accuracy: 0.9276\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9266 - val_loss: 0.1865 - val_accuracy: 0.9287\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9284 - val_loss: 0.1870 - val_accuracy: 0.9315\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9284 - val_loss: 0.1866 - val_accuracy: 0.9290\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9276 - val_loss: 0.1870 - val_accuracy: 0.9276\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9249 - val_loss: 0.1856 - val_accuracy: 0.9308\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9259 - val_loss: 0.1855 - val_accuracy: 0.9301\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9372 - val_loss: 0.1853 - val_accuracy: 0.9301\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.1854 - val_accuracy: 0.9301\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9234 - val_loss: 0.1864 - val_accuracy: 0.9287\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9289 - val_loss: 0.1856 - val_accuracy: 0.9312\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9260 - val_loss: 0.1862 - val_accuracy: 0.9283\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9200 - val_loss: 0.1869 - val_accuracy: 0.9266\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9265 - val_loss: 0.1861 - val_accuracy: 0.9280\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9287 - val_loss: 0.1862 - val_accuracy: 0.9308\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9289 - val_loss: 0.1858 - val_accuracy: 0.9269\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9245 - val_loss: 0.1846 - val_accuracy: 0.9301\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9281 - val_loss: 0.1846 - val_accuracy: 0.9322\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9290 - val_loss: 0.1844 - val_accuracy: 0.9301\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9300 - val_loss: 0.1842 - val_accuracy: 0.9301\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9257 - val_loss: 0.1846 - val_accuracy: 0.9294\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9289 - val_loss: 0.1839 - val_accuracy: 0.9308\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9330 - val_loss: 0.1840 - val_accuracy: 0.9290\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9337 - val_loss: 0.1840 - val_accuracy: 0.9301\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9237 - val_loss: 0.1833 - val_accuracy: 0.9308\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9200 - val_loss: 0.1851 - val_accuracy: 0.9269\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9240 - val_loss: 0.1832 - val_accuracy: 0.9308\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9272 - val_loss: 0.1840 - val_accuracy: 0.9287\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9328 - val_loss: 0.1831 - val_accuracy: 0.9298\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9297 - val_loss: 0.1830 - val_accuracy: 0.9298\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9264 - val_loss: 0.1831 - val_accuracy: 0.9322\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9348 - val_loss: 0.1827 - val_accuracy: 0.9312\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9335 - val_loss: 0.1832 - val_accuracy: 0.9298\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9354 - val_loss: 0.1827 - val_accuracy: 0.9319\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9311 - val_loss: 0.1828 - val_accuracy: 0.9301\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9274 - val_loss: 0.1824 - val_accuracy: 0.9329\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9410 - val_loss: 0.1833 - val_accuracy: 0.9312\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9313 - val_loss: 0.1844 - val_accuracy: 0.9315\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9334 - val_loss: 0.1820 - val_accuracy: 0.9312\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9321 - val_loss: 0.1824 - val_accuracy: 0.9322\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9303 - val_loss: 0.1840 - val_accuracy: 0.9308\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9366 - val_loss: 0.1818 - val_accuracy: 0.9308\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9343 - val_loss: 0.1817 - val_accuracy: 0.9305\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9287 - val_loss: 0.1819 - val_accuracy: 0.9308\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9338 - val_loss: 0.1817 - val_accuracy: 0.9315\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9257 - val_loss: 0.1814 - val_accuracy: 0.9315\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9206 - val_loss: 0.1824 - val_accuracy: 0.9315\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9287 - val_loss: 0.1814 - val_accuracy: 0.9319\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9331 - val_loss: 0.1817 - val_accuracy: 0.9305\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9279 - val_loss: 0.1844 - val_accuracy: 0.9255\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9232 - val_loss: 0.1813 - val_accuracy: 0.9312\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9219 - val_loss: 0.1818 - val_accuracy: 0.9329\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9288 - val_loss: 0.1806 - val_accuracy: 0.9326\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9392 - val_loss: 0.1809 - val_accuracy: 0.9312\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.9252 - val_loss: 0.1820 - val_accuracy: 0.9308\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9281 - val_loss: 0.1818 - val_accuracy: 0.9319\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9260 - val_loss: 0.1838 - val_accuracy: 0.9273\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9342 - val_loss: 0.1806 - val_accuracy: 0.9301\n",
      "9\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 3, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.8444 - val_loss: 0.2208 - val_accuracy: 0.9161\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9180 - val_loss: 0.2026 - val_accuracy: 0.9217\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9128 - val_loss: 0.1994 - val_accuracy: 0.9210\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9205 - val_loss: 0.2001 - val_accuracy: 0.9262\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9192 - val_loss: 0.1955 - val_accuracy: 0.9245\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9316 - val_loss: 0.1951 - val_accuracy: 0.9245\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9203 - val_loss: 0.1936 - val_accuracy: 0.9252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9303 - val_loss: 0.1934 - val_accuracy: 0.9259\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9278 - val_loss: 0.1931 - val_accuracy: 0.9245\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9237 - val_loss: 0.1935 - val_accuracy: 0.9231\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9209 - val_loss: 0.1924 - val_accuracy: 0.9280\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9228 - val_loss: 0.1957 - val_accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9292 - val_loss: 0.1928 - val_accuracy: 0.9273\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9223 - val_loss: 0.1938 - val_accuracy: 0.9217\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9222 - val_loss: 0.1914 - val_accuracy: 0.9269\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9362 - val_loss: 0.1940 - val_accuracy: 0.9227\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9220 - val_loss: 0.1949 - val_accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9296 - val_loss: 0.1909 - val_accuracy: 0.9259\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9257 - val_loss: 0.1905 - val_accuracy: 0.9266\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9257 - val_loss: 0.1927 - val_accuracy: 0.9269\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9164 - val_loss: 0.1900 - val_accuracy: 0.9262\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9264 - val_loss: 0.1907 - val_accuracy: 0.9269\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9228 - val_loss: 0.1898 - val_accuracy: 0.9280\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9250 - val_loss: 0.1900 - val_accuracy: 0.9280\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9262 - val_loss: 0.1895 - val_accuracy: 0.9269\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9238 - val_loss: 0.1891 - val_accuracy: 0.9269\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9288 - val_loss: 0.1884 - val_accuracy: 0.9287\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9226 - val_loss: 0.1889 - val_accuracy: 0.9266\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9331 - val_loss: 0.1898 - val_accuracy: 0.9269\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9278 - val_loss: 0.1896 - val_accuracy: 0.9266\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9199 - val_loss: 0.1876 - val_accuracy: 0.9294\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.9334 - val_loss: 0.1872 - val_accuracy: 0.9273\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9213 - val_loss: 0.1886 - val_accuracy: 0.9269\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9248 - val_loss: 0.1902 - val_accuracy: 0.9273\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9294 - val_loss: 0.1894 - val_accuracy: 0.9266\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9250 - val_loss: 0.1870 - val_accuracy: 0.9290\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9296 - val_loss: 0.1864 - val_accuracy: 0.9276\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9178 - val_loss: 0.1864 - val_accuracy: 0.9298\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9264 - val_loss: 0.1870 - val_accuracy: 0.9308\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9260 - val_loss: 0.1867 - val_accuracy: 0.9273\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9065 - val_loss: 0.1865 - val_accuracy: 0.9283\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9291 - val_loss: 0.1862 - val_accuracy: 0.9283\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9349 - val_loss: 0.1858 - val_accuracy: 0.9315\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9294 - val_loss: 0.1874 - val_accuracy: 0.9301\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9418 - val_loss: 0.1879 - val_accuracy: 0.9305\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9239 - val_loss: 0.1884 - val_accuracy: 0.9269\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9297 - val_loss: 0.1854 - val_accuracy: 0.9290\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9231 - val_loss: 0.1855 - val_accuracy: 0.9280\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9342 - val_loss: 0.1878 - val_accuracy: 0.9298\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9396 - val_loss: 0.1871 - val_accuracy: 0.9319\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9383 - val_loss: 0.1848 - val_accuracy: 0.9305\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9292 - val_loss: 0.1849 - val_accuracy: 0.9308\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1871 - accuracy: 0.9310 - val_loss: 0.1868 - val_accuracy: 0.9227\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9201 - val_loss: 0.1845 - val_accuracy: 0.9290\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9172 - val_loss: 0.1844 - val_accuracy: 0.9305\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9219 - val_loss: 0.1844 - val_accuracy: 0.9294\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9397 - val_loss: 0.1850 - val_accuracy: 0.9283\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9377 - val_loss: 0.1844 - val_accuracy: 0.9312\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9263 - val_loss: 0.1841 - val_accuracy: 0.9301\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9280 - val_loss: 0.1843 - val_accuracy: 0.9301\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9258 - val_loss: 0.1837 - val_accuracy: 0.9301\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9359 - val_loss: 0.1841 - val_accuracy: 0.9305\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9303 - val_loss: 0.1858 - val_accuracy: 0.9290\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9284 - val_loss: 0.1839 - val_accuracy: 0.9305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9300 - val_loss: 0.1846 - val_accuracy: 0.9287\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9316 - val_loss: 0.1835 - val_accuracy: 0.9305\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9248 - val_loss: 0.1846 - val_accuracy: 0.9301\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9348 - val_loss: 0.1834 - val_accuracy: 0.9312\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9308 - val_loss: 0.1832 - val_accuracy: 0.9308\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9293 - val_loss: 0.1838 - val_accuracy: 0.9280\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9344 - val_loss: 0.1845 - val_accuracy: 0.9280\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9296 - val_loss: 0.1837 - val_accuracy: 0.9283\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9314 - val_loss: 0.1850 - val_accuracy: 0.9262\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9330 - val_loss: 0.1832 - val_accuracy: 0.9301\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9325 - val_loss: 0.1869 - val_accuracy: 0.9305\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9262 - val_loss: 0.1828 - val_accuracy: 0.9287\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9348 - val_loss: 0.1845 - val_accuracy: 0.9312\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9246 - val_loss: 0.1853 - val_accuracy: 0.9241\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9235 - val_loss: 0.1862 - val_accuracy: 0.9308\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9302 - val_loss: 0.1824 - val_accuracy: 0.9301\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9307 - val_loss: 0.1832 - val_accuracy: 0.9326\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9358 - val_loss: 0.1833 - val_accuracy: 0.9273\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9239 - val_loss: 0.1818 - val_accuracy: 0.9326\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9260 - val_loss: 0.1822 - val_accuracy: 0.9290\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9305 - val_loss: 0.1824 - val_accuracy: 0.9319\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9299 - val_loss: 0.1823 - val_accuracy: 0.9319\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9308 - val_loss: 0.1835 - val_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9305 - val_loss: 0.1815 - val_accuracy: 0.9319\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9382 - val_loss: 0.1823 - val_accuracy: 0.9287\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9226 - val_loss: 0.1822 - val_accuracy: 0.9308\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9349 - val_loss: 0.1841 - val_accuracy: 0.9255\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9358 - val_loss: 0.1814 - val_accuracy: 0.9308\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9293 - val_loss: 0.1811 - val_accuracy: 0.9329\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9243 - val_loss: 0.1821 - val_accuracy: 0.9283\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9326 - val_loss: 0.1822 - val_accuracy: 0.9312\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9308 - val_loss: 0.1840 - val_accuracy: 0.9273\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9203 - val_loss: 0.1817 - val_accuracy: 0.9305\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9321 - val_loss: 0.1810 - val_accuracy: 0.9333\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9301 - val_loss: 0.1808 - val_accuracy: 0.9326\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9289 - val_loss: 0.1813 - val_accuracy: 0.9312\n"
     ]
    }
   ],
   "source": [
    "df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "t_enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    enm_mlp, model = ensemble_cnn()\n",
    "    t_enm_mlp_df = pd.concat([t_enm_mlp_df, enm_mlp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble mlp\n",
      "[0.8078, 0.7286, 0.7603, 0.9116, 105.4209, 40.7473]\n",
      "[0.0031, 0.0117, 0.0076, 0.0008, 3.4649, 0.0363]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>114.6736</td>\n",
       "      <td>40.7947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8070</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>102.1866</td>\n",
       "      <td>40.7021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8061</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>102.4799</td>\n",
       "      <td>40.7131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8041</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>105.4898</td>\n",
       "      <td>40.8130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8043</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>105.1634</td>\n",
       "      <td>40.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.7461</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>105.1248</td>\n",
       "      <td>40.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8063</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.9114</td>\n",
       "      <td>103.9168</td>\n",
       "      <td>40.7542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8083</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>104.9754</td>\n",
       "      <td>40.7561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8131</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>104.5984</td>\n",
       "      <td>40.7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>105.6004</td>\n",
       "      <td>40.7372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision  Recall  F1 score     AUC  Train time  Test time\n",
       "0     0.8115  0.7229    0.7577  0.9101    114.6736    40.7947\n",
       "1     0.8070  0.7328    0.7633  0.9113    102.1866    40.7021\n",
       "2     0.8061  0.7301    0.7611  0.9106    102.4799    40.7131\n",
       "3     0.8041  0.7436    0.7695  0.9126    105.4898    40.8130\n",
       "4     0.8043  0.7393    0.7667  0.9123    105.1634    40.7579\n",
       "5     0.8110  0.7076    0.7461  0.9115    105.1248    40.7378\n",
       "6     0.8063  0.7284    0.7600  0.9114    103.9168    40.7542\n",
       "7     0.8083  0.7422    0.7701  0.9124    104.9754    40.7561\n",
       "8     0.8131  0.7152    0.7524  0.9124    104.5984    40.7070\n",
       "9     0.8065  0.7234    0.7565  0.9118    105.6004    40.7372"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Ensemble mlp')\n",
    "metrics_name = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "mean_mlp = []\n",
    "std_mlp = []\n",
    "for each in metrics_name:\n",
    "    mean_mlp.append(round(t_enm_mlp_df[each].mean(), ndigits=4))\n",
    "    std_mlp.append(round(t_enm_mlp_df[each].std(), ndigits=4))\n",
    "print(mean_mlp)\n",
    "print(std_mlp)\n",
    "t_enm_mlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
