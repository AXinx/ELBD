{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "data_name = 'SMD'\n",
    "data_file = os.path.join(path, 'processed', data_name)\n",
    "train_data_ = open(os.path.join(data_file, 'machine-1-1_train.pkl'),'rb')\n",
    "train_data = pd.DataFrame(pkl.load(train_data_))\n",
    "test_data_ = open(os.path.join(data_file, 'machine-1-1_test.pkl'),'rb')\n",
    "test_data = pd.DataFrame(pkl.load(test_data_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "28474    0.0\n",
       "28475    0.0\n",
       "28476    0.0\n",
       "28477    0.0\n",
       "28478    0.0\n",
       "Name: label, Length: 28479, dtype: float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_label_ = open(os.path.join(data_file, 'machine-1-1_test_label.pkl'),'rb')\n",
    "test_data_label = pd.DataFrame(pkl.load(test_data_label_),columns=['label'])\n",
    "test_data_label.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09459601811861372"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_num = len(test_data_label[test_data_label.label==1])\n",
    "anomaly_num / len(test_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(test_data_label.label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(test_data[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.068156</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.269886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.068036</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.064432</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.073742</td>\n",
       "      <td>0.075582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.070020</td>\n",
       "      <td>0.050437</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.065228</td>\n",
       "      <td>0.065224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.064619</td>\n",
       "      <td>0.069273</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.069684</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.067111</td>\n",
       "      <td>0.067178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.048729</td>\n",
       "      <td>0.061452</td>\n",
       "      <td>0.069768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.268940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027250</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.073253</td>\n",
       "      <td>0.051467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.066676</td>\n",
       "      <td>0.066744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.051907</td>\n",
       "      <td>0.060335</td>\n",
       "      <td>0.069768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.269886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.070932</td>\n",
       "      <td>0.051467</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.066604</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28474</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.051907</td>\n",
       "      <td>0.045810</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896551</td>\n",
       "      <td>0.252841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>0.040144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.042931</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28475</th>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.036871</td>\n",
       "      <td>0.043024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893678</td>\n",
       "      <td>0.252841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.047438</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.046619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28476</th>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.048044</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896551</td>\n",
       "      <td>0.253788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.046797</td>\n",
       "      <td>0.040144</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28477</th>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.056144</td>\n",
       "      <td>0.045810</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890805</td>\n",
       "      <td>0.252841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027339</td>\n",
       "      <td>0.041884</td>\n",
       "      <td>0.043232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.039890</td>\n",
       "      <td>0.039959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28478</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.039106</td>\n",
       "      <td>0.043024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879311</td>\n",
       "      <td>0.251894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28479 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3    4         5         6    7   \\\n",
       "0      0.065217  0.065678  0.068156  0.073256  0.0  0.925287  0.269886  0.0   \n",
       "1      0.076087  0.080508  0.073742  0.075582  0.0  0.922414  0.270833  0.0   \n",
       "2      0.065217  0.064619  0.069273  0.073256  0.0  0.919540  0.270833  0.0   \n",
       "3      0.076087  0.048729  0.061452  0.069768  0.0  0.919540  0.268940  0.0   \n",
       "4      0.076087  0.051907  0.060335  0.069768  0.0  0.925287  0.269886  0.0   \n",
       "...         ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "28474  0.065217  0.051907  0.045810  0.046512  0.0  0.896551  0.252841  0.0   \n",
       "28475  0.054347  0.025424  0.036871  0.043024  0.0  0.893678  0.252841  0.0   \n",
       "28476  0.054347  0.080508  0.048044  0.046512  0.0  0.896551  0.253788  0.0   \n",
       "28477  0.054347  0.056144  0.045810  0.045350  0.0  0.890805  0.252841  0.0   \n",
       "28478  0.000000  0.029661  0.039106  0.043024  0.0  0.879311  0.251894  0.0   \n",
       "\n",
       "             8         9   ...   28        29        30        31        32  \\\n",
       "0      0.031081  0.000000  ...  0.0  0.004317  0.068036  0.048893  0.000386   \n",
       "1      0.031081  0.000122  ...  0.0  0.004317  0.070020  0.050437  0.000386   \n",
       "2      0.030940  0.000366  ...  0.0  0.004317  0.069684  0.055069  0.000386   \n",
       "3      0.027250  0.000244  ...  0.0  0.005756  0.073253  0.051467  0.000000   \n",
       "4      0.030940  0.000244  ...  0.0  0.004317  0.070932  0.051467  0.000386   \n",
       "...         ...       ...  ...  ...       ...       ...       ...       ...   \n",
       "28474  0.043571  0.000244  ...  0.0  0.027339  0.046733  0.040144  0.000000   \n",
       "28475  0.032501  0.000000  ...  0.0  0.027339  0.047438  0.048893  0.000000   \n",
       "28476  0.026114  0.000611  ...  0.0  0.027339  0.046797  0.040144  0.000386   \n",
       "28477  0.033210  0.000122  ...  0.0  0.027339  0.041884  0.043232  0.000000   \n",
       "28478  0.030656  0.001966  ...  0.0  0.030216  0.000000  0.000000  0.000386   \n",
       "\n",
       "             33        34        35   36   37  \n",
       "0      0.000023  0.064432  0.064500  0.0  0.0  \n",
       "1      0.000011  0.065228  0.065224  0.0  0.0  \n",
       "2      0.000034  0.067111  0.067178  0.0  0.0  \n",
       "3      0.000023  0.066676  0.066744  0.0  0.0  \n",
       "4      0.000011  0.066604  0.066671  0.0  0.0  \n",
       "...         ...       ...       ...  ...  ...  \n",
       "28474  0.000011  0.042931  0.043000  0.0  0.0  \n",
       "28475  0.000045  0.046550  0.046619  0.0  0.0  \n",
       "28476  0.000034  0.043003  0.043000  0.0  0.0  \n",
       "28477  0.000034  0.039890  0.039959  0.0  0.0  \n",
       "28478  0.000135  0.000000  0.000000  0.0  0.0  \n",
       "\n",
       "[28479 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_train_data = pd.DataFrame(scaler.fit_transform(train_data))\n",
    "normalized_test_data = pd.DataFrame(scaler.fit_transform(test_data))\n",
    "normalized_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyuexin/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: (0.6973527396696735, 0.0),\n",
       " 1: (0.30764505836646333, 0.0),\n",
       " 2: (0.3175970455564924, 0.0),\n",
       " 3: (0.3038517526821894, 0.0),\n",
       " 4: (nan, nan),\n",
       " 5: (0.11743536033480964, 5.376067656024853e-88),\n",
       " 6: (0.2525655682687791, 0.0),\n",
       " 7: (nan, nan),\n",
       " 8: (0.1337066473039637, 9.969331195518177e-114),\n",
       " 9: (0.1663960964129524, 6.696615466525581e-176),\n",
       " 10: (0.14804277442789915, 2.953306774696296e-139),\n",
       " 11: (0.23684414196135742, 0.0),\n",
       " 12: (0.24368784191147552, 0.0),\n",
       " 13: (0.13857288789582525, 4.316762166030914e-122),\n",
       " 14: (0.10251825803745851, 2.1274541372228407e-67),\n",
       " 15: (0.14621726761579826, 7.428515327812208e-136),\n",
       " 16: (nan, nan),\n",
       " 17: (nan, nan),\n",
       " 18: (0.22611279095465234, 0.0),\n",
       " 19: (0.26760023429824426, 0.0),\n",
       " 20: (0.2744659032917104, 0.0),\n",
       " 21: (0.28331286338284717, 0.0),\n",
       " 22: (-0.10442223127834657, 7.196404952192433e-70),\n",
       " 23: (0.13592296748240043, 1.6898665032624605e-117),\n",
       " 24: (0.3099196607365322, 0.0),\n",
       " 25: (0.13494195376510357, 8.032214575535645e-116),\n",
       " 26: (0.073354802038049, 2.770717537344301e-35),\n",
       " 27: (0.285618338185542, 0.0),\n",
       " 28: (0.09132799749546275, 8.297538937235209e-54),\n",
       " 29: (0.23814237826178694, 0.0),\n",
       " 30: (0.2906033292943572, 0.0),\n",
       " 31: (0.3231542613541429, 0.0),\n",
       " 32: (0.09209557212332804, 1.089802789195036e-54),\n",
       " 33: (0.0966369085565096, 4.665732660932999e-60),\n",
       " 34: (0.29031375291114186, 0.0),\n",
       " 35: (0.2903143783395753, 0.0),\n",
       " 36: (nan, nan),\n",
       " 37: (nan, nan)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "correlation_txn_failure = {}\n",
    "for metric in normalized_test_data.columns[:]:\n",
    "    r,p = stats.pearsonr(test_data[metric], test_data_label.label)\n",
    "    correlation_txn_failure[metric] = (r,p)\n",
    "correlation_txn_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          r  p-value\n",
      "0  0.697353      0.0\n"
     ]
    }
   ],
   "source": [
    "txn_failure_correlation = pd.DataFrame.from_dict(correlation_txn_failure, orient='index').rename(columns={0:'r', 1:'p-value'}).sort_values('r', ascending=False)\n",
    "txn_failure_correlation = txn_failure_correlation.dropna(axis=0, how='any')\n",
    "#print(txn_failure_correlation)\n",
    "txn_failure_correlation = txn_failure_correlation[txn_failure_correlation['p-value']<0.05]\n",
    "txn_failure_correlation = txn_failure_correlation[np.abs(txn_failure_correlation['r'])>0.5]\n",
    "print(txn_failure_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6472448  0.23495755 0.03814473 0.01958585 0.01584372]\n",
      "[67.19859  40.487465 16.31335  11.689532 10.513675]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca_train_data = pca.fit_transform(normalized_train_data)\n",
    "pca_test_data = pca.fit_transform(normalized_test_data)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "# supress warnings for clean output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from pyod.models.combination import aom, moa, average, maximization, majority_vote\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_labels(y_test, test_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, test_scores)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    pred_label = []\n",
    "    for each in test_scores:\n",
    "        if each > cutoff:\n",
    "            pred_label.append(1)\n",
    "        else:\n",
    "            pred_label.append(0)    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eval(label, pred_label, scores):\n",
    "    pr = round(metrics.precision_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    re = round(metrics.recall_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    f1 = round(metrics.f1_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    roc = round(roc_auc_score(label, scores), ndigits=4)\n",
    "    return pr,re,f1,roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca_test_data\n",
    "X_test = pca_test_data\n",
    "y_train = test_data_label\n",
    "y_test = test_data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base detector 1 is fitted for prediction\n",
      "67.4012\n"
     ]
    }
   ],
   "source": [
    "outliers_fraction = np.count_nonzero(y_train) / len(y_train)\n",
    "outliers_percentage = round(outliers_fraction * 100, ndigits=4)\n",
    "    \n",
    "random_state = np.random.RandomState(42)\n",
    "classifiers = {\n",
    "        #'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "        #                            random_state=random_state),\n",
    "        #'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "        #'Local Outlier Factor (LOF)': LOF(\n",
    "        #    contamination=outliers_fraction),\n",
    "        'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction)\n",
    "    }\n",
    "\n",
    "n_clf = len(classifiers)\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
    "p_labels = np.zeros([X_test.shape[0], n_clf])\n",
    "\n",
    "i = 0\n",
    "train_duration = 0\n",
    "test_duration = 0\n",
    "for clf_name, clf in classifiers.items():\n",
    "    t0 = time()\n",
    "    clf.fit(X_train)\n",
    "    t1 = time()\n",
    "    test_sccore = clf.decision_function(X_test)\n",
    "    t_t = time()\n",
    "    test_mean_score = np.nanmean(test_scores)\n",
    "    test_scores[np.isnan(test_scores)] = test_mean_score\n",
    "    test_scores[:, i] = test_sccore\n",
    "    p_labels[:, i] = pred_labels(y_test, test_sccore)\n",
    "    i += 1\n",
    "    print('Base detector %i is fitted for prediction' % i)\n",
    "    train_duration += round(t1 - t0, ndigits=4)\n",
    "    test_duration += round(t_t - t1, ndigits=4)\n",
    "    \n",
    "# standardize test score\n",
    "test_scores_norm = standardizer(test_scores)\n",
    "print(train_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from time import time\n",
    "\n",
    "#train_x, test_x, train_y, test_y = train_test_split(test_scores_norm, y_test, test_size=0.5, random_state=random_state)\n",
    "train_x, test_x, train_y, test_y = train_test_split(test_scores_norm[:,0], y_test, test_size=0.7, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(len(train_x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ensemble_mlp():\n",
    "    df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "    enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    t2 = time()\n",
    "    model = models.Sequential()\n",
    "    # Input - Layer\n",
    "    model.add(layers.Dense(4, activation = \"relu\", input_shape=(len(train_y),1)))\n",
    "    model.add(layers.Dense(20, activation = \"relu\"))\n",
    "    model.add(layers.Dense(20, activation = \"relu\"))\n",
    "    # Output- Layer\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "    model.summary()\n",
    "    # compiling the model\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    results = model.fit(\n",
    "     train_x, train_y,\n",
    "     epochs= 100,\n",
    "     batch_size = 20,\n",
    "     validation_data = (train_x, train_y)\n",
    "    )\n",
    "    t3 = time()\n",
    "    #print(results.history['val_accuracy'])\n",
    "    pred_test = model.predict(test_scores_norm[:,0].reshape(len(test_scores_norm),1)).reshape(-1,1)\n",
    "    #pred_test = model.predict(test_scores_norm)\n",
    "    #pred_test = model.predict(test_x)\n",
    "    t4 = time()\n",
    "    train_time = t3 - t2\n",
    "    test_time = t4 - t3\n",
    "    train_time_mlp =  round(train_duration+train_time, ndigits=4)\n",
    "    test_time_mlp = round(train_duration+test_time, ndigits=4)\n",
    "    \n",
    "    pred_nn = []\n",
    "    for each in pred_test:\n",
    "        if each[0] > 0.5:\n",
    "            pred_nn.append(1)\n",
    "        else:\n",
    "            pred_nn.append(0)\n",
    "    print(y_test.shape)\n",
    "    print(pred_test.shape)\n",
    "    pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(y_test, pred_nn, pred_test)\n",
    "    #pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(test_y, pred_nn, pred_test)\n",
    "    enm_mlp = pd.DataFrame([pr_mlp, re_mlp, f1_mlp, roc_mlp, train_time_mlp, test_time_mlp]).transpose()\n",
    "    enm_mlp.columns = df_columns\n",
    "    enm_mlp_df = pd.concat([enm_mlp_df, enm_mlp], axis=0)\n",
    "    return enm_mlp_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 16:30:30.093231: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 16:30:30.370754: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "387/428 [==========================>...] - ETA: 0s - loss: 0.5246 - accuracy: 0.8859WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 14s 2ms/step - loss: 0.5100 - accuracy: 0.8879 - val_loss: 0.2436 - val_accuracy: 0.9154\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.9139 - val_loss: 0.2381 - val_accuracy: 0.9150\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9105 - val_loss: 0.2342 - val_accuracy: 0.9148\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.9083 - val_loss: 0.2344 - val_accuracy: 0.9140\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9214 - val_loss: 0.2298 - val_accuracy: 0.9151\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9193 - val_loss: 0.2276 - val_accuracy: 0.9151\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2330 - accuracy: 0.9120 - val_loss: 0.2264 - val_accuracy: 0.9145\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9137 - val_loss: 0.2258 - val_accuracy: 0.9153\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9182 - val_loss: 0.2259 - val_accuracy: 0.9137\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9139 - val_loss: 0.2251 - val_accuracy: 0.9147\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9186 - val_loss: 0.2254 - val_accuracy: 0.9153\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9103 - val_loss: 0.2271 - val_accuracy: 0.9137\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9139 - val_loss: 0.2251 - val_accuracy: 0.9143\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9121 - val_loss: 0.2270 - val_accuracy: 0.9142\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9171 - val_loss: 0.2253 - val_accuracy: 0.9137\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9162 - val_loss: 0.2250 - val_accuracy: 0.9150\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9142 - val_loss: 0.2247 - val_accuracy: 0.9155\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9148 - val_loss: 0.2241 - val_accuracy: 0.9154\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9154 - val_loss: 0.2258 - val_accuracy: 0.9136\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9120 - val_loss: 0.2246 - val_accuracy: 0.9153\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9186 - val_loss: 0.2242 - val_accuracy: 0.9150\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9118 - val_loss: 0.2241 - val_accuracy: 0.9151\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9117 - val_loss: 0.2250 - val_accuracy: 0.9138\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9144 - val_loss: 0.2247 - val_accuracy: 0.9137\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9131 - val_loss: 0.2237 - val_accuracy: 0.9147\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2219 - accuracy: 0.9142 - val_loss: 0.2236 - val_accuracy: 0.9148\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9134 - val_loss: 0.2239 - val_accuracy: 0.9154\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9143 - val_loss: 0.2237 - val_accuracy: 0.9150\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9181 - val_loss: 0.2244 - val_accuracy: 0.9154\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9159 - val_loss: 0.2233 - val_accuracy: 0.9151\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9168 - val_loss: 0.2232 - val_accuracy: 0.9154\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9159 - val_loss: 0.2236 - val_accuracy: 0.9154\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9101 - val_loss: 0.2252 - val_accuracy: 0.9141\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 0.9182 - val_loss: 0.2244 - val_accuracy: 0.9151\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9150 - val_loss: 0.2230 - val_accuracy: 0.9148\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9190 - val_loss: 0.2230 - val_accuracy: 0.9148\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.9164 - val_loss: 0.2229 - val_accuracy: 0.9150\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9168 - val_loss: 0.2235 - val_accuracy: 0.9147\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9152 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9187 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9105 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9141 - val_loss: 0.2234 - val_accuracy: 0.9153\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9125 - val_loss: 0.2237 - val_accuracy: 0.9134\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9162 - val_loss: 0.2231 - val_accuracy: 0.9151\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9178 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2263 - accuracy: 0.9150 - val_loss: 0.2227 - val_accuracy: 0.9151\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9127 - val_loss: 0.2229 - val_accuracy: 0.9150\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9153 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9113 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9150 - val_loss: 0.2226 - val_accuracy: 0.9148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9125 - val_loss: 0.2238 - val_accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9196 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 53/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2268 - accuracy: 0.9137 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9136 - val_loss: 0.2230 - val_accuracy: 0.9150\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9156 - val_loss: 0.2233 - val_accuracy: 0.9153\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9153 - val_loss: 0.2237 - val_accuracy: 0.9147\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9168 - val_loss: 0.2234 - val_accuracy: 0.9154\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9171 - val_loss: 0.2234 - val_accuracy: 0.9133\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9156 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9164 - val_loss: 0.2226 - val_accuracy: 0.9150\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9142 - val_loss: 0.2225 - val_accuracy: 0.9144\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9137 - val_loss: 0.2238 - val_accuracy: 0.9150\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9147 - val_loss: 0.2227 - val_accuracy: 0.9150\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9178 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9139 - val_loss: 0.2232 - val_accuracy: 0.9136\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9168 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9181 - val_loss: 0.2232 - val_accuracy: 0.9153\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9113 - val_loss: 0.2224 - val_accuracy: 0.9154\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9124 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9110 - val_loss: 0.2225 - val_accuracy: 0.9147\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9156 - val_loss: 0.2229 - val_accuracy: 0.9142\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2297 - accuracy: 0.9099 - val_loss: 0.2232 - val_accuracy: 0.9150\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9188 - val_loss: 0.2234 - val_accuracy: 0.9154\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9199 - val_loss: 0.2231 - val_accuracy: 0.9155\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9059 - val_loss: 0.2228 - val_accuracy: 0.9151\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9156 - val_loss: 0.2229 - val_accuracy: 0.9142\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9162 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9073 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.9143 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9152 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9121 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9084 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9220 - val_loss: 0.2229 - val_accuracy: 0.9148\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9161 - val_loss: 0.2227 - val_accuracy: 0.9150\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.9183 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.9205 - val_loss: 0.2226 - val_accuracy: 0.9144\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9168 - val_loss: 0.2231 - val_accuracy: 0.9137\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.9193 - val_loss: 0.2228 - val_accuracy: 0.9151\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9129 - val_loss: 0.2228 - val_accuracy: 0.9145\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9111 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2288 - accuracy: 0.9104 - val_loss: 0.2230 - val_accuracy: 0.9134\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9133 - val_loss: 0.2224 - val_accuracy: 0.9150\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9134 - val_loss: 0.2226 - val_accuracy: 0.9145\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9175 - val_loss: 0.2225 - val_accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.9196 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9167 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9136 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9147 - val_loss: 0.2231 - val_accuracy: 0.9153\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9162 - val_loss: 0.2224 - val_accuracy: 0.9147\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9157 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "382/428 [=========================>....] - ETA: 0s - loss: 0.4390 - accuracy: 0.9047WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 2s 2ms/step - loss: 0.4260 - accuracy: 0.9048 - val_loss: 0.2463 - val_accuracy: 0.9059\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9088 - val_loss: 0.2430 - val_accuracy: 0.9059\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9063 - val_loss: 0.2421 - val_accuracy: 0.9059\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.9045 - val_loss: 0.2403 - val_accuracy: 0.9059\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.9069 - val_loss: 0.2393 - val_accuracy: 0.9059\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9102 - val_loss: 0.2395 - val_accuracy: 0.9059\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9065 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9094 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.9058 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9040 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9021 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9006 - val_loss: 0.2387 - val_accuracy: 0.9059\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.9023 - val_loss: 0.2394 - val_accuracy: 0.9059\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9096 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9034 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9058 - val_loss: 0.2391 - val_accuracy: 0.9059\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9048 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9066 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9045 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9072 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9057 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.9024 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.9059 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9091 - val_loss: 0.2393 - val_accuracy: 0.9059\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9064 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.9037 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.9087 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9042 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.9045 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9080 - val_loss: 0.2387 - val_accuracy: 0.9059\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.9037 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9054 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9073 - val_loss: 0.2388 - val_accuracy: 0.9059\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9075 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9078 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9049 - val_loss: 0.2390 - val_accuracy: 0.9059\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9100 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9045 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9071 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9093 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9072 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9059 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9119 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9084 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9063 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.9036 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9057 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2287 - accuracy: 0.9128 - val_loss: 0.2388 - val_accuracy: 0.9059\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2330 - accuracy: 0.9085 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9069 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.9002 - val_loss: 0.2393 - val_accuracy: 0.9059\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9092 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9075 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.9063 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9095 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9040 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9091 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9045 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9118 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9083 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.8975 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9044 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9082 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9058 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.9074 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9042 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9082 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.9035 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9067 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.9078 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.9044 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.9059 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9084 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.9075 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.9046 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9065 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9093 - val_loss: 0.2397 - val_accuracy: 0.9059\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.9051 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.9087 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.8989 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.9014 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9055 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9072 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9035 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9067 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.9058 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.8982 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9065 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9076 - val_loss: 0.2389 - val_accuracy: 0.9059\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.9002 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9029 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.8999 - val_loss: 0.2398 - val_accuracy: 0.9059\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.9057 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2337 - accuracy: 0.9072 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.9047 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9146 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.9039 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9077 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9080 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9012 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "392/428 [==========================>...] - ETA: 0s - loss: 0.4155 - accuracy: 0.9098WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 2s 2ms/step - loss: 0.4057 - accuracy: 0.9099 - val_loss: 0.2327 - val_accuracy: 0.9149\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.9118 - val_loss: 0.2284 - val_accuracy: 0.9150\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9096 - val_loss: 0.2258 - val_accuracy: 0.9145\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9144 - val_loss: 0.2257 - val_accuracy: 0.9147\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9140 - val_loss: 0.2240 - val_accuracy: 0.9137\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9142 - val_loss: 0.2233 - val_accuracy: 0.9154\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9157 - val_loss: 0.2240 - val_accuracy: 0.9137\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.9223 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9176 - val_loss: 0.2239 - val_accuracy: 0.9153\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9175 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9160 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9104 - val_loss: 0.2245 - val_accuracy: 0.9148\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9175 - val_loss: 0.2227 - val_accuracy: 0.9155\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9174 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9151 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9123 - val_loss: 0.2259 - val_accuracy: 0.9148\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9189 - val_loss: 0.2231 - val_accuracy: 0.9144\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9141 - val_loss: 0.2232 - val_accuracy: 0.9142\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9124 - val_loss: 0.2233 - val_accuracy: 0.9135\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9155 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9137 - val_loss: 0.2241 - val_accuracy: 0.9142\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9151 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9196 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9162 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9164 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9137 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2160 - accuracy: 0.9184 - val_loss: 0.2237 - val_accuracy: 0.9137\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9148 - val_loss: 0.2236 - val_accuracy: 0.9136\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9141 - val_loss: 0.2231 - val_accuracy: 0.9150\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9091 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9140 - val_loss: 0.2226 - val_accuracy: 0.9155\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9180 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9127 - val_loss: 0.2230 - val_accuracy: 0.9145\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9110 - val_loss: 0.2234 - val_accuracy: 0.9144\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9159 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9140 - val_loss: 0.2232 - val_accuracy: 0.9153\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9141 - val_loss: 0.2232 - val_accuracy: 0.9150\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9177 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9122 - val_loss: 0.2223 - val_accuracy: 0.9153\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9150 - val_loss: 0.2226 - val_accuracy: 0.9150\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9127 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.9088 - val_loss: 0.2235 - val_accuracy: 0.9153\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9164 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.9176 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9156 - val_loss: 0.2225 - val_accuracy: 0.9147\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9151 - val_loss: 0.2224 - val_accuracy: 0.9150\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9149 - val_loss: 0.2229 - val_accuracy: 0.9150\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9169 - val_loss: 0.2229 - val_accuracy: 0.9142\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.9171 - val_loss: 0.2227 - val_accuracy: 0.9151\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9135 - val_loss: 0.2236 - val_accuracy: 0.9153\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9182 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9158 - val_loss: 0.2226 - val_accuracy: 0.9144\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.9190 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9163 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9134 - val_loss: 0.2224 - val_accuracy: 0.9150\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9122 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9134 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9116 - val_loss: 0.2226 - val_accuracy: 0.9145\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9143 - val_loss: 0.2225 - val_accuracy: 0.9143\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9123 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9184 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9181 - val_loss: 0.2223 - val_accuracy: 0.9153\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9136 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9206 - val_loss: 0.2228 - val_accuracy: 0.9150\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.9177 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.9158 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.9059 - val_loss: 0.2223 - val_accuracy: 0.9153\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9207 - val_loss: 0.2247 - val_accuracy: 0.9149\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9175 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9145 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9165 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9153 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9197 - val_loss: 0.2225 - val_accuracy: 0.9150\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.9142 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9121 - val_loss: 0.2225 - val_accuracy: 0.9147\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9186 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9175 - val_loss: 0.2223 - val_accuracy: 0.9153\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9136 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9153 - val_loss: 0.2227 - val_accuracy: 0.9155\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9106 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9177 - val_loss: 0.2224 - val_accuracy: 0.9148\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9135 - val_loss: 0.2222 - val_accuracy: 0.9154\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9112 - val_loss: 0.2226 - val_accuracy: 0.9145\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9158 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9132 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9122 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9107 - val_loss: 0.2224 - val_accuracy: 0.9147\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.9059 - val_loss: 0.2223 - val_accuracy: 0.9149\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9156 - val_loss: 0.2228 - val_accuracy: 0.9145\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.9091 - val_loss: 0.2230 - val_accuracy: 0.9148\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9123 - val_loss: 0.2223 - val_accuracy: 0.9153\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9144 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9162 - val_loss: 0.2228 - val_accuracy: 0.9155\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9182 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9176 - val_loss: 0.2231 - val_accuracy: 0.9135\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9183 - val_loss: 0.2223 - val_accuracy: 0.9151\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9109 - val_loss: 0.2225 - val_accuracy: 0.9150\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9149 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.9203 - val_loss: 0.2227 - val_accuracy: 0.9144\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9144 - val_loss: 0.2226 - val_accuracy: 0.9155\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "3\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "377/428 [=========================>....] - ETA: 0s - loss: 0.4985 - accuracy: 0.7523WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 2s 2ms/step - loss: 0.4797 - accuracy: 0.7663 - val_loss: 0.2435 - val_accuracy: 0.9059\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.9053 - val_loss: 0.2409 - val_accuracy: 0.9059\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2357 - accuracy: 0.9092 - val_loss: 0.2399 - val_accuracy: 0.9059\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9099 - val_loss: 0.2397 - val_accuracy: 0.9059\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.9073 - val_loss: 0.2388 - val_accuracy: 0.9059\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9055 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9092 - val_loss: 0.2393 - val_accuracy: 0.9059\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.9092 - val_loss: 0.2396 - val_accuracy: 0.9059\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9108 - val_loss: 0.2400 - val_accuracy: 0.9059\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9068 - val_loss: 0.2393 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9104 - val_loss: 0.2390 - val_accuracy: 0.9059\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9095 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.9071 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9054 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.9096 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9075 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.9053 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.9044 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9050 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.9007 - val_loss: 0.2388 - val_accuracy: 0.9059\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.9044 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.9084 - val_loss: 0.2389 - val_accuracy: 0.9059\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.9054 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9092 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9064 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9095 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.9040 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9043 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9099 - val_loss: 0.2388 - val_accuracy: 0.9059\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.9102 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9049 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9064 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9070 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9026 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.9027 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9076 - val_loss: 0.2387 - val_accuracy: 0.9059\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.9042 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9083 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9034 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.9047 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9018 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9075 - val_loss: 0.2389 - val_accuracy: 0.9059\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9083 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9105 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9074 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9122 - val_loss: 0.2387 - val_accuracy: 0.9059\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.9017 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9092 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9065 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.9040 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9074 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9089 - val_loss: 0.2390 - val_accuracy: 0.9059\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9079 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.9014 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9043 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.9025 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.9082 - val_loss: 0.2390 - val_accuracy: 0.9059\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.9054 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9027 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9090 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.9017 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9088 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9056 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9114 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9013 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.9085 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.9100 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.9001 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2497 - accuracy: 0.9014 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9052 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9061 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9075 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9068 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9039 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9067 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9071 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.9057 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.9060 - val_loss: 0.2396 - val_accuracy: 0.9059\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.9032 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9049 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9062 - val_loss: 0.2385 - val_accuracy: 0.9059\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9073 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.9019 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9060 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9035 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.8992 - val_loss: 0.2384 - val_accuracy: 0.9059\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9048 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.9060 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.9003 - val_loss: 0.2399 - val_accuracy: 0.9059\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.9035 - val_loss: 0.2386 - val_accuracy: 0.9059\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.8987 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.8979 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.9008 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.9111 - val_loss: 0.2388 - val_accuracy: 0.9059\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9051 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9084 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9032 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.9077 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.9026 - val_loss: 0.2382 - val_accuracy: 0.9059\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9079 - val_loss: 0.2383 - val_accuracy: 0.9059\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "4\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "381/428 [=========================>....] - ETA: 0s - loss: 0.4957 - accuracy: 0.8932WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 2s 2ms/step - loss: 0.4794 - accuracy: 0.8947 - val_loss: 0.2333 - val_accuracy: 0.9153\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9153 - val_loss: 0.2299 - val_accuracy: 0.9143\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9159 - val_loss: 0.2270 - val_accuracy: 0.9150\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9168 - val_loss: 0.2261 - val_accuracy: 0.9151\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9174 - val_loss: 0.2246 - val_accuracy: 0.9150\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9148 - val_loss: 0.2239 - val_accuracy: 0.9153\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9163 - val_loss: 0.2236 - val_accuracy: 0.9155\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9161 - val_loss: 0.2244 - val_accuracy: 0.9137\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9126 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2320 - accuracy: 0.9129 - val_loss: 0.2230 - val_accuracy: 0.9148\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2123 - accuracy: 0.9190 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2181 - accuracy: 0.9179 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2238 - accuracy: 0.9151 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2305 - accuracy: 0.9125 - val_loss: 0.2225 - val_accuracy: 0.9148\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2327 - accuracy: 0.9105 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9141 - val_loss: 0.2225 - val_accuracy: 0.9148\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9112 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9145 - val_loss: 0.2234 - val_accuracy: 0.9151\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9139 - val_loss: 0.2230 - val_accuracy: 0.9155\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9210 - val_loss: 0.2229 - val_accuracy: 0.9151\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9163 - val_loss: 0.2230 - val_accuracy: 0.9148\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9117 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2247 - accuracy: 0.9145 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2243 - accuracy: 0.9098 - val_loss: 0.2228 - val_accuracy: 0.9150\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9146 - val_loss: 0.2232 - val_accuracy: 0.9155\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2217 - accuracy: 0.9165 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2292 - accuracy: 0.9160 - val_loss: 0.2234 - val_accuracy: 0.9153\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2334 - accuracy: 0.9096 - val_loss: 0.2225 - val_accuracy: 0.9148\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9147 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9139 - val_loss: 0.2235 - val_accuracy: 0.9143\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9122 - val_loss: 0.2228 - val_accuracy: 0.9150\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 0.9179 - val_loss: 0.2226 - val_accuracy: 0.9145\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2140 - accuracy: 0.9206 - val_loss: 0.2231 - val_accuracy: 0.9147\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2191 - accuracy: 0.9178 - val_loss: 0.2231 - val_accuracy: 0.9144\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2260 - accuracy: 0.9140 - val_loss: 0.2226 - val_accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9113 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9141 - val_loss: 0.2227 - val_accuracy: 0.9151\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.9177 - val_loss: 0.2232 - val_accuracy: 0.9153\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9089 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2263 - accuracy: 0.9150 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2266 - accuracy: 0.9115 - val_loss: 0.2228 - val_accuracy: 0.9148\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2338 - accuracy: 0.9105 - val_loss: 0.2233 - val_accuracy: 0.9154\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9145 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9182 - val_loss: 0.2225 - val_accuracy: 0.9150\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.9195 - val_loss: 0.2231 - val_accuracy: 0.9150\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2340 - accuracy: 0.9099 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9068 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2290 - accuracy: 0.9120 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2212 - accuracy: 0.9151 - val_loss: 0.2228 - val_accuracy: 0.9155\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.9187 - val_loss: 0.2232 - val_accuracy: 0.9155\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9190 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9115 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9183 - val_loss: 0.2236 - val_accuracy: 0.9154\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9146 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9219 - val_loss: 0.2234 - val_accuracy: 0.9147\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9167 - val_loss: 0.2229 - val_accuracy: 0.9150\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9141 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9146 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9181 - val_loss: 0.2228 - val_accuracy: 0.9155\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9160 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9197 - val_loss: 0.2239 - val_accuracy: 0.9136\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2199 - accuracy: 0.9146 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2198 - accuracy: 0.9156 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2267 - accuracy: 0.9162 - val_loss: 0.2227 - val_accuracy: 0.9155\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9148 - val_loss: 0.2226 - val_accuracy: 0.9144\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9133 - val_loss: 0.2228 - val_accuracy: 0.9155\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9123 - val_loss: 0.2228 - val_accuracy: 0.9150\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9157 - val_loss: 0.2228 - val_accuracy: 0.9150\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9110 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9134 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9135 - val_loss: 0.2226 - val_accuracy: 0.9155\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9136 - val_loss: 0.2225 - val_accuracy: 0.9144\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9101 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9150 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9148 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9134 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9175 - val_loss: 0.2228 - val_accuracy: 0.9143\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9170 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9117 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9071 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9145 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2226 - accuracy: 0.9164 - val_loss: 0.2227 - val_accuracy: 0.9148\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9144 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9191 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9185 - val_loss: 0.2241 - val_accuracy: 0.9151\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9077 - val_loss: 0.2234 - val_accuracy: 0.9145\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9153 - val_loss: 0.2233 - val_accuracy: 0.9145\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9158 - val_loss: 0.2231 - val_accuracy: 0.9133\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9190 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9127 - val_loss: 0.2225 - val_accuracy: 0.9150\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2254 - accuracy: 0.9173 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9104 - val_loss: 0.2227 - val_accuracy: 0.9154\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9117 - val_loss: 0.2231 - val_accuracy: 0.9148\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9118 - val_loss: 0.2238 - val_accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9186 - val_loss: 0.2225 - val_accuracy: 0.9147\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9179 - val_loss: 0.2227 - val_accuracy: 0.9155\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9169 - val_loss: 0.2230 - val_accuracy: 0.9143\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9140 - val_loss: 0.2223 - val_accuracy: 0.9151\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9165 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9124 - val_loss: 0.2225 - val_accuracy: 0.9148\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "5\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "393/428 [==========================>...] - ETA: 0s - loss: 0.4713 - accuracy: 0.9019WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 2s 2ms/step - loss: 0.4600 - accuracy: 0.9025 - val_loss: 0.2379 - val_accuracy: 0.9145\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9168 - val_loss: 0.2297 - val_accuracy: 0.9144\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9150 - val_loss: 0.2277 - val_accuracy: 0.9154\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9131 - val_loss: 0.2268 - val_accuracy: 0.9137\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.9118 - val_loss: 0.2253 - val_accuracy: 0.9153\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2232 - accuracy: 0.9163 - val_loss: 0.2253 - val_accuracy: 0.9154\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9188 - val_loss: 0.2253 - val_accuracy: 0.9137\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2169 - accuracy: 0.9170 - val_loss: 0.2250 - val_accuracy: 0.9151\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2343 - accuracy: 0.9114 - val_loss: 0.2251 - val_accuracy: 0.9144\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2316 - accuracy: 0.9078 - val_loss: 0.2265 - val_accuracy: 0.9140\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.9144 - val_loss: 0.2248 - val_accuracy: 0.9148\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9100 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9145 - val_loss: 0.2252 - val_accuracy: 0.9155\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9145 - val_loss: 0.2251 - val_accuracy: 0.9154\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9149 - val_loss: 0.2247 - val_accuracy: 0.9150\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2387 - accuracy: 0.9086 - val_loss: 0.2259 - val_accuracy: 0.9144\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9118 - val_loss: 0.2246 - val_accuracy: 0.9151\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9192 - val_loss: 0.2251 - val_accuracy: 0.9148\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9120 - val_loss: 0.2284 - val_accuracy: 0.9138\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9136 - val_loss: 0.2247 - val_accuracy: 0.9147\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9137 - val_loss: 0.2246 - val_accuracy: 0.9147\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9146 - val_loss: 0.2255 - val_accuracy: 0.9148\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9171 - val_loss: 0.2259 - val_accuracy: 0.9142\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9173 - val_loss: 0.2245 - val_accuracy: 0.9150\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9123 - val_loss: 0.2266 - val_accuracy: 0.9142\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9109 - val_loss: 0.2240 - val_accuracy: 0.9148\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9166 - val_loss: 0.2238 - val_accuracy: 0.9144\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2243 - accuracy: 0.9160 - val_loss: 0.2240 - val_accuracy: 0.9136\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2239 - accuracy: 0.9148 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2168 - accuracy: 0.9185 - val_loss: 0.2236 - val_accuracy: 0.9147\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2244 - accuracy: 0.9176 - val_loss: 0.2232 - val_accuracy: 0.9151\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9082 - val_loss: 0.2244 - val_accuracy: 0.9145\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2269 - accuracy: 0.9141 - val_loss: 0.2231 - val_accuracy: 0.9150\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9169 - val_loss: 0.2230 - val_accuracy: 0.9154\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2184 - accuracy: 0.9165 - val_loss: 0.2242 - val_accuracy: 0.9138\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2410 - accuracy: 0.9068 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9149 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2226 - accuracy: 0.9123 - val_loss: 0.2245 - val_accuracy: 0.9151\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9157 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9081 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9168 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2198 - accuracy: 0.9184 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9204 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.9152 - val_loss: 0.2228 - val_accuracy: 0.9148\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2242 - accuracy: 0.9151 - val_loss: 0.2240 - val_accuracy: 0.9144\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2264 - accuracy: 0.9164 - val_loss: 0.2229 - val_accuracy: 0.9151\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2283 - accuracy: 0.9128 - val_loss: 0.2228 - val_accuracy: 0.9148\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2168 - accuracy: 0.9157 - val_loss: 0.2227 - val_accuracy: 0.9145\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2105 - accuracy: 0.9196 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2192 - accuracy: 0.9143 - val_loss: 0.2226 - val_accuracy: 0.9150\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9131 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9133 - val_loss: 0.2231 - val_accuracy: 0.9144\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2263 - accuracy: 0.9130 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2151 - accuracy: 0.9170 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9158 - val_loss: 0.2230 - val_accuracy: 0.9151\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9154 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9181 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9220 - val_loss: 0.2234 - val_accuracy: 0.9143\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2245 - accuracy: 0.9128 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9176 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9153 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9125 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9149 - val_loss: 0.2225 - val_accuracy: 0.9150\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9157 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9151 - val_loss: 0.2226 - val_accuracy: 0.9145\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9085 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9133 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2233 - accuracy: 0.9098 - val_loss: 0.2235 - val_accuracy: 0.9153\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9154 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9089 - val_loss: 0.2230 - val_accuracy: 0.9144\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2210 - accuracy: 0.9153 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9126 - val_loss: 0.2225 - val_accuracy: 0.9145\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9144 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9132 - val_loss: 0.2227 - val_accuracy: 0.9145\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9135 - val_loss: 0.2233 - val_accuracy: 0.9154\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.9161 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9178 - val_loss: 0.2231 - val_accuracy: 0.9148\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9130 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9163 - val_loss: 0.2244 - val_accuracy: 0.9153\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9131 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9127 - val_loss: 0.2236 - val_accuracy: 0.9153\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9126 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9188 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9076 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9123 - val_loss: 0.2236 - val_accuracy: 0.9134\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9156 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9196 - val_loss: 0.2231 - val_accuracy: 0.9153\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9144 - val_loss: 0.2226 - val_accuracy: 0.9150\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2299 - accuracy: 0.9101 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9136 - val_loss: 0.2226 - val_accuracy: 0.9150\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9137 - val_loss: 0.2234 - val_accuracy: 0.9154\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9130 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9196 - val_loss: 0.2232 - val_accuracy: 0.9147\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9178 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9120 - val_loss: 0.2238 - val_accuracy: 0.9144\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9157 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9119 - val_loss: 0.2230 - val_accuracy: 0.9136\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9127 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9129 - val_loss: 0.2233 - val_accuracy: 0.9143\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9180 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "6\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "376/428 [=========================>....] - ETA: 0s - loss: 0.4921 - accuracy: 0.9121WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 2s 2ms/step - loss: 0.4752 - accuracy: 0.9122 - val_loss: 0.2495 - val_accuracy: 0.9141\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2372 - accuracy: 0.9176 - val_loss: 0.2375 - val_accuracy: 0.9150\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.9112 - val_loss: 0.2304 - val_accuracy: 0.9149\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9111 - val_loss: 0.2300 - val_accuracy: 0.9142\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9150 - val_loss: 0.2306 - val_accuracy: 0.9126\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9199 - val_loss: 0.2252 - val_accuracy: 0.9151\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9193 - val_loss: 0.2252 - val_accuracy: 0.9153\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2225 - accuracy: 0.9182 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9154 - val_loss: 0.2239 - val_accuracy: 0.9144\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2219 - accuracy: 0.9166 - val_loss: 0.2230 - val_accuracy: 0.9151\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.9205 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2258 - accuracy: 0.9143 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9139 - val_loss: 0.2236 - val_accuracy: 0.9153\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9182 - val_loss: 0.2237 - val_accuracy: 0.9133\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9168 - val_loss: 0.2265 - val_accuracy: 0.9154\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9119 - val_loss: 0.2250 - val_accuracy: 0.9138\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2321 - accuracy: 0.9123 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9131 - val_loss: 0.2232 - val_accuracy: 0.9145\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2255 - accuracy: 0.9117 - val_loss: 0.2227 - val_accuracy: 0.9148\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2239 - accuracy: 0.9154 - val_loss: 0.2228 - val_accuracy: 0.9145\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2243 - accuracy: 0.9146 - val_loss: 0.2247 - val_accuracy: 0.9154\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2315 - accuracy: 0.9117 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2261 - accuracy: 0.9128 - val_loss: 0.2231 - val_accuracy: 0.9147\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2254 - accuracy: 0.9152 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2354 - accuracy: 0.9086 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2190 - accuracy: 0.9159 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9182 - val_loss: 0.2251 - val_accuracy: 0.9137\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2330 - accuracy: 0.9129 - val_loss: 0.2252 - val_accuracy: 0.9141\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2290 - accuracy: 0.9091 - val_loss: 0.2227 - val_accuracy: 0.9154\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2236 - accuracy: 0.9141 - val_loss: 0.2236 - val_accuracy: 0.9144\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2247 - accuracy: 0.9112 - val_loss: 0.2235 - val_accuracy: 0.9144\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2351 - accuracy: 0.9121 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2122 - accuracy: 0.9221 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2189 - accuracy: 0.9168 - val_loss: 0.2232 - val_accuracy: 0.9153\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9137 - val_loss: 0.2233 - val_accuracy: 0.9155\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2279 - accuracy: 0.9157 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9199 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2253 - accuracy: 0.9166 - val_loss: 0.2230 - val_accuracy: 0.9150\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2238 - accuracy: 0.9157 - val_loss: 0.2252 - val_accuracy: 0.9136\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2334 - accuracy: 0.9087 - val_loss: 0.2237 - val_accuracy: 0.9143\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2306 - accuracy: 0.9126 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9168 - val_loss: 0.2231 - val_accuracy: 0.9145\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9167 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2277 - accuracy: 0.9145 - val_loss: 0.2238 - val_accuracy: 0.9147\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2274 - accuracy: 0.9145 - val_loss: 0.2240 - val_accuracy: 0.9154\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2322 - accuracy: 0.9125 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9158 - val_loss: 0.2230 - val_accuracy: 0.9141\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2195 - accuracy: 0.9171 - val_loss: 0.2231 - val_accuracy: 0.9144\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2243 - accuracy: 0.9130 - val_loss: 0.2250 - val_accuracy: 0.9150\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9207 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2185 - accuracy: 0.9151 - val_loss: 0.2228 - val_accuracy: 0.9148\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2153 - accuracy: 0.9190 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2258 - accuracy: 0.9123 - val_loss: 0.2226 - val_accuracy: 0.9150\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.9135 - val_loss: 0.2233 - val_accuracy: 0.9155\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9158 - val_loss: 0.2228 - val_accuracy: 0.9150\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9128 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2296 - accuracy: 0.9127 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2285 - accuracy: 0.9129 - val_loss: 0.2233 - val_accuracy: 0.9144\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2191 - accuracy: 0.9161 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2229 - accuracy: 0.9165 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2303 - accuracy: 0.9110 - val_loss: 0.2237 - val_accuracy: 0.9153\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9110 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2264 - accuracy: 0.9148 - val_loss: 0.2232 - val_accuracy: 0.9147\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9134 - val_loss: 0.2238 - val_accuracy: 0.9150\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2270 - accuracy: 0.9158 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.9182 - val_loss: 0.2237 - val_accuracy: 0.9138\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2154 - accuracy: 0.9153 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2212 - accuracy: 0.9146 - val_loss: 0.2253 - val_accuracy: 0.9143\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9168 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9144 - val_loss: 0.2228 - val_accuracy: 0.9151\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2288 - accuracy: 0.9127 - val_loss: 0.2234 - val_accuracy: 0.9144\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9136 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2340 - accuracy: 0.9094 - val_loss: 0.2239 - val_accuracy: 0.9153\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9116 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9127 - val_loss: 0.2234 - val_accuracy: 0.9153\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2265 - accuracy: 0.9115 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9145 - val_loss: 0.2235 - val_accuracy: 0.9135\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.2294 - accuracy: 0.9108 - val_loss: 0.2243 - val_accuracy: 0.9150\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9163 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2269 - accuracy: 0.9094 - val_loss: 0.2228 - val_accuracy: 0.9151\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2267 - accuracy: 0.9138 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2205 - accuracy: 0.9151 - val_loss: 0.2228 - val_accuracy: 0.9145\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2194 - accuracy: 0.9158 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2318 - accuracy: 0.9094 - val_loss: 0.2227 - val_accuracy: 0.9151\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.9106 - val_loss: 0.2225 - val_accuracy: 0.9145\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9135 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9116 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2165 - accuracy: 0.9200 - val_loss: 0.2243 - val_accuracy: 0.9154\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9077 - val_loss: 0.2230 - val_accuracy: 0.9154\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2222 - accuracy: 0.9166 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2259 - accuracy: 0.9171 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9104 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9155 - val_loss: 0.2224 - val_accuracy: 0.9150\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9142 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.9196 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9101 - val_loss: 0.2225 - val_accuracy: 0.9150\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9165 - val_loss: 0.2238 - val_accuracy: 0.9148\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2373 - accuracy: 0.9051 - val_loss: 0.2243 - val_accuracy: 0.9148\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.9179 - val_loss: 0.2234 - val_accuracy: 0.9153\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9082 - val_loss: 0.2234 - val_accuracy: 0.9153\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "419/428 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.9007WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 2s 3ms/step - loss: 0.4829 - accuracy: 0.9009 - val_loss: 0.2341 - val_accuracy: 0.9149\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2289 - accuracy: 0.9170 - val_loss: 0.2297 - val_accuracy: 0.9153\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2420 - accuracy: 0.9093 - val_loss: 0.2316 - val_accuracy: 0.9138\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2340 - accuracy: 0.9130 - val_loss: 0.2255 - val_accuracy: 0.9151\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2229 - accuracy: 0.9163 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9136 - val_loss: 0.2235 - val_accuracy: 0.9151\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9177 - val_loss: 0.2243 - val_accuracy: 0.9154\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2194 - accuracy: 0.9155 - val_loss: 0.2259 - val_accuracy: 0.9142\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2175 - accuracy: 0.9165 - val_loss: 0.2229 - val_accuracy: 0.9147\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2335 - accuracy: 0.9093 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2280 - accuracy: 0.9111 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2218 - accuracy: 0.9155 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2165 - accuracy: 0.9214 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9156 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2196 - accuracy: 0.9158 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2209 - accuracy: 0.9161 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2088 - accuracy: 0.9220 - val_loss: 0.2235 - val_accuracy: 0.9138\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2211 - accuracy: 0.9159 - val_loss: 0.2227 - val_accuracy: 0.9148\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2229 - accuracy: 0.9137 - val_loss: 0.2225 - val_accuracy: 0.9144\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2177 - accuracy: 0.9168 - val_loss: 0.2225 - val_accuracy: 0.9145\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2187 - accuracy: 0.9125 - val_loss: 0.2231 - val_accuracy: 0.9153\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2306 - accuracy: 0.9104 - val_loss: 0.2230 - val_accuracy: 0.9154\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2193 - accuracy: 0.9150 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9115 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2164 - accuracy: 0.9201 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9156 - val_loss: 0.2223 - val_accuracy: 0.9148\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9163 - val_loss: 0.2223 - val_accuracy: 0.9151\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2264 - accuracy: 0.9127 - val_loss: 0.2225 - val_accuracy: 0.9148\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2265 - accuracy: 0.9159 - val_loss: 0.2227 - val_accuracy: 0.9137\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2190 - accuracy: 0.9186 - val_loss: 0.2224 - val_accuracy: 0.9147\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2107 - accuracy: 0.9189 - val_loss: 0.2233 - val_accuracy: 0.9154\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9169 - val_loss: 0.2230 - val_accuracy: 0.9143\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2237 - accuracy: 0.9136 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9129 - val_loss: 0.2226 - val_accuracy: 0.9151\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9157 - val_loss: 0.2240 - val_accuracy: 0.9140\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9163 - val_loss: 0.2222 - val_accuracy: 0.9150\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9110 - val_loss: 0.2223 - val_accuracy: 0.9154\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 0.9188 - val_loss: 0.2227 - val_accuracy: 0.9136\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9107 - val_loss: 0.2223 - val_accuracy: 0.9153\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9148 - val_loss: 0.2234 - val_accuracy: 0.9133\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9146 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9153 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9143 - val_loss: 0.2223 - val_accuracy: 0.9148\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9096 - val_loss: 0.2228 - val_accuracy: 0.9145\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9100 - val_loss: 0.2242 - val_accuracy: 0.9142\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9068 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9141 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2297 - accuracy: 0.9119 - val_loss: 0.2234 - val_accuracy: 0.9151\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9126 - val_loss: 0.2227 - val_accuracy: 0.9143\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9134 - val_loss: 0.2227 - val_accuracy: 0.9144\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9147 - val_loss: 0.2241 - val_accuracy: 0.9153\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9114 - val_loss: 0.2221 - val_accuracy: 0.9151\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9140 - val_loss: 0.2221 - val_accuracy: 0.9154\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9152 - val_loss: 0.2222 - val_accuracy: 0.9145\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9141 - val_loss: 0.2222 - val_accuracy: 0.9148\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9136 - val_loss: 0.2224 - val_accuracy: 0.9154\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9129 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9110 - val_loss: 0.2224 - val_accuracy: 0.9148\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9129 - val_loss: 0.2222 - val_accuracy: 0.9148\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9123 - val_loss: 0.2226 - val_accuracy: 0.9137\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9117 - val_loss: 0.2222 - val_accuracy: 0.9147\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9177 - val_loss: 0.2223 - val_accuracy: 0.9147\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.9065 - val_loss: 0.2224 - val_accuracy: 0.9147\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9156 - val_loss: 0.2260 - val_accuracy: 0.9149\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9148 - val_loss: 0.2222 - val_accuracy: 0.9147\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9208 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9081 - val_loss: 0.2234 - val_accuracy: 0.9133\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9130 - val_loss: 0.2221 - val_accuracy: 0.9151\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9109 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9123 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9108 - val_loss: 0.2223 - val_accuracy: 0.9148\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9137 - val_loss: 0.2225 - val_accuracy: 0.9143\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9145 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9094 - val_loss: 0.2223 - val_accuracy: 0.9154\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9155 - val_loss: 0.2224 - val_accuracy: 0.9154\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9149 - val_loss: 0.2231 - val_accuracy: 0.9140\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9142 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9099 - val_loss: 0.2223 - val_accuracy: 0.9148\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9125 - val_loss: 0.2224 - val_accuracy: 0.9148\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.9168 - val_loss: 0.2222 - val_accuracy: 0.9135\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9130 - val_loss: 0.2237 - val_accuracy: 0.9143\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9139 - val_loss: 0.2225 - val_accuracy: 0.9154\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9183 - val_loss: 0.2230 - val_accuracy: 0.9142\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9123 - val_loss: 0.2223 - val_accuracy: 0.9154\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9193 - val_loss: 0.2222 - val_accuracy: 0.9147\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9201 - val_loss: 0.2220 - val_accuracy: 0.9153\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9119 - val_loss: 0.2220 - val_accuracy: 0.9153\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9153 - val_loss: 0.2221 - val_accuracy: 0.9151\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9172 - val_loss: 0.2222 - val_accuracy: 0.9145\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9140 - val_loss: 0.2223 - val_accuracy: 0.9145\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9161 - val_loss: 0.2223 - val_accuracy: 0.9143\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9111 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2366 - accuracy: 0.9076 - val_loss: 0.2230 - val_accuracy: 0.9147\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9068 - val_loss: 0.2224 - val_accuracy: 0.9151\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9134 - val_loss: 0.2221 - val_accuracy: 0.9151\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.9098 - val_loss: 0.2221 - val_accuracy: 0.9147\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9124 - val_loss: 0.2222 - val_accuracy: 0.9150\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.9164 - val_loss: 0.2224 - val_accuracy: 0.9148\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9114 - val_loss: 0.2220 - val_accuracy: 0.9151\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9121 - val_loss: 0.2220 - val_accuracy: 0.9153\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "8\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "402/428 [===========================>..] - ETA: 0s - loss: 0.4689 - accuracy: 0.9132WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.9131 - val_loss: 0.2404 - val_accuracy: 0.9154\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9166 - val_loss: 0.2301 - val_accuracy: 0.9150\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9115 - val_loss: 0.2258 - val_accuracy: 0.9154\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9147 - val_loss: 0.2252 - val_accuracy: 0.9154\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9154 - val_loss: 0.2268 - val_accuracy: 0.9151\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9140 - val_loss: 0.2231 - val_accuracy: 0.9153\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9143 - val_loss: 0.2239 - val_accuracy: 0.9154\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9089 - val_loss: 0.2234 - val_accuracy: 0.9147\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9117 - val_loss: 0.2238 - val_accuracy: 0.9147\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9141 - val_loss: 0.2257 - val_accuracy: 0.9148\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9166 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.9200 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9112 - val_loss: 0.2227 - val_accuracy: 0.9150\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.9143 - val_loss: 0.2233 - val_accuracy: 0.9153\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9194 - val_loss: 0.2238 - val_accuracy: 0.9153\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9113 - val_loss: 0.2236 - val_accuracy: 0.9153\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9173 - val_loss: 0.2230 - val_accuracy: 0.9154\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9134 - val_loss: 0.2240 - val_accuracy: 0.9144\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9143 - val_loss: 0.2230 - val_accuracy: 0.9140\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9142 - val_loss: 0.2234 - val_accuracy: 0.9143\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9160 - val_loss: 0.2229 - val_accuracy: 0.9151\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9237 - val_loss: 0.2230 - val_accuracy: 0.9143\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.9150 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9142 - val_loss: 0.2227 - val_accuracy: 0.9144\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9186 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9125 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9143 - val_loss: 0.2248 - val_accuracy: 0.9153\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9133 - val_loss: 0.2241 - val_accuracy: 0.9142\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9171 - val_loss: 0.2227 - val_accuracy: 0.9145\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9149 - val_loss: 0.2231 - val_accuracy: 0.9151\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9173 - val_loss: 0.2225 - val_accuracy: 0.9148\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.9163 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.9200 - val_loss: 0.2229 - val_accuracy: 0.9143\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9137 - val_loss: 0.2229 - val_accuracy: 0.9155\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.9094 - val_loss: 0.2224 - val_accuracy: 0.9150\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9153 - val_loss: 0.2224 - val_accuracy: 0.9153\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9133 - val_loss: 0.2235 - val_accuracy: 0.9155\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9130 - val_loss: 0.2233 - val_accuracy: 0.9138\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9143 - val_loss: 0.2237 - val_accuracy: 0.9144\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9131 - val_loss: 0.2226 - val_accuracy: 0.9144\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.9139 - val_loss: 0.2225 - val_accuracy: 0.9145\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9129 - val_loss: 0.2227 - val_accuracy: 0.9147\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9130 - val_loss: 0.2232 - val_accuracy: 0.9150\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9163 - val_loss: 0.2245 - val_accuracy: 0.9154\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9135 - val_loss: 0.2237 - val_accuracy: 0.9136\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9129 - val_loss: 0.2223 - val_accuracy: 0.9150\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9141 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9177 - val_loss: 0.2224 - val_accuracy: 0.9150\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9142 - val_loss: 0.2231 - val_accuracy: 0.9143\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.9207 - val_loss: 0.2229 - val_accuracy: 0.9150\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9139 - val_loss: 0.2224 - val_accuracy: 0.9145\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2263 - accuracy: 0.9156 - val_loss: 0.2232 - val_accuracy: 0.9153\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9181 - val_loss: 0.2223 - val_accuracy: 0.9151\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9116 - val_loss: 0.2224 - val_accuracy: 0.9147\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9126 - val_loss: 0.2223 - val_accuracy: 0.9150\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9198 - val_loss: 0.2225 - val_accuracy: 0.9145\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9156 - val_loss: 0.2226 - val_accuracy: 0.9133\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9149 - val_loss: 0.2255 - val_accuracy: 0.9137\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.9080 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9161 - val_loss: 0.2221 - val_accuracy: 0.9147\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9136 - val_loss: 0.2221 - val_accuracy: 0.9144\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.9103 - val_loss: 0.2245 - val_accuracy: 0.9147\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.9087 - val_loss: 0.2222 - val_accuracy: 0.9154\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9120 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.9123 - val_loss: 0.2224 - val_accuracy: 0.9154\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9188 - val_loss: 0.2226 - val_accuracy: 0.9145\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9172 - val_loss: 0.2225 - val_accuracy: 0.9143\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9104 - val_loss: 0.2224 - val_accuracy: 0.9143\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9161 - val_loss: 0.2223 - val_accuracy: 0.9148\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9094 - val_loss: 0.2224 - val_accuracy: 0.9154\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9206 - val_loss: 0.2228 - val_accuracy: 0.9145\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.9177 - val_loss: 0.2233 - val_accuracy: 0.9155\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9231 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9136 - val_loss: 0.2221 - val_accuracy: 0.9148\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9146 - val_loss: 0.2225 - val_accuracy: 0.9150\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9100 - val_loss: 0.2223 - val_accuracy: 0.9153\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9141 - val_loss: 0.2225 - val_accuracy: 0.9153\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9128 - val_loss: 0.2223 - val_accuracy: 0.9154\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9182 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9139 - val_loss: 0.2225 - val_accuracy: 0.9144\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9142 - val_loss: 0.2220 - val_accuracy: 0.9154\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9133 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.9138 - val_loss: 0.2221 - val_accuracy: 0.9150\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9103 - val_loss: 0.2221 - val_accuracy: 0.9147\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9181 - val_loss: 0.2224 - val_accuracy: 0.9145\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9169 - val_loss: 0.2221 - val_accuracy: 0.9153\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.9188 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9139 - val_loss: 0.2220 - val_accuracy: 0.9153\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.9158 - val_loss: 0.2220 - val_accuracy: 0.9148\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.9184 - val_loss: 0.2232 - val_accuracy: 0.9148\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9142 - val_loss: 0.2220 - val_accuracy: 0.9154\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.9167 - val_loss: 0.2220 - val_accuracy: 0.9153\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9147 - val_loss: 0.2222 - val_accuracy: 0.9150\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9147 - val_loss: 0.2221 - val_accuracy: 0.9137\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2263 - accuracy: 0.9154 - val_loss: 0.2221 - val_accuracy: 0.9150\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9158 - val_loss: 0.2223 - val_accuracy: 0.9154\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9153 - val_loss: 0.2220 - val_accuracy: 0.9150\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9173 - val_loss: 0.2219 - val_accuracy: 0.9145\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9148 - val_loss: 0.2223 - val_accuracy: 0.9150\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9162 - val_loss: 0.2219 - val_accuracy: 0.9148\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n",
      "9\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 8543, 4)           8         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 8543, 20)          100       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 8543, 20)          420       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 8543, 1)           21        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "401/428 [===========================>..] - ETA: 0s - loss: 0.5128 - accuracy: 0.9093WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.9096 - val_loss: 0.2550 - val_accuracy: 0.9129\n",
      "Epoch 2/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.9148 - val_loss: 0.2312 - val_accuracy: 0.9144\n",
      "Epoch 3/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9126 - val_loss: 0.2268 - val_accuracy: 0.9144\n",
      "Epoch 4/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9187 - val_loss: 0.2264 - val_accuracy: 0.9137\n",
      "Epoch 5/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9145 - val_loss: 0.2247 - val_accuracy: 0.9154\n",
      "Epoch 6/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9177 - val_loss: 0.2257 - val_accuracy: 0.9153\n",
      "Epoch 7/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9134 - val_loss: 0.2258 - val_accuracy: 0.9137\n",
      "Epoch 8/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9162 - val_loss: 0.2247 - val_accuracy: 0.9136\n",
      "Epoch 9/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9147 - val_loss: 0.2240 - val_accuracy: 0.9150\n",
      "Epoch 10/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9114 - val_loss: 0.2235 - val_accuracy: 0.9145\n",
      "Epoch 11/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9117 - val_loss: 0.2236 - val_accuracy: 0.9151\n",
      "Epoch 12/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2373 - accuracy: 0.9077 - val_loss: 0.2284 - val_accuracy: 0.9142\n",
      "Epoch 13/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9131 - val_loss: 0.2235 - val_accuracy: 0.9144\n",
      "Epoch 14/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9112 - val_loss: 0.2245 - val_accuracy: 0.9149\n",
      "Epoch 15/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9145 - val_loss: 0.2230 - val_accuracy: 0.9144\n",
      "Epoch 16/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9154 - val_loss: 0.2230 - val_accuracy: 0.9151\n",
      "Epoch 17/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9160 - val_loss: 0.2236 - val_accuracy: 0.9144\n",
      "Epoch 18/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9109 - val_loss: 0.2246 - val_accuracy: 0.9148\n",
      "Epoch 19/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2256 - accuracy: 0.9126 - val_loss: 0.2233 - val_accuracy: 0.9142\n",
      "Epoch 20/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.9118 - val_loss: 0.2233 - val_accuracy: 0.9141\n",
      "Epoch 21/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9171 - val_loss: 0.2233 - val_accuracy: 0.9153\n",
      "Epoch 22/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9189 - val_loss: 0.2238 - val_accuracy: 0.9148\n",
      "Epoch 23/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9203 - val_loss: 0.2241 - val_accuracy: 0.9138\n",
      "Epoch 24/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9103 - val_loss: 0.2227 - val_accuracy: 0.9150\n",
      "Epoch 25/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.9055 - val_loss: 0.2243 - val_accuracy: 0.9143\n",
      "Epoch 26/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9128 - val_loss: 0.2229 - val_accuracy: 0.9154\n",
      "Epoch 27/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9168 - val_loss: 0.2235 - val_accuracy: 0.9137\n",
      "Epoch 28/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9121 - val_loss: 0.2230 - val_accuracy: 0.9145\n",
      "Epoch 29/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9154 - val_loss: 0.2243 - val_accuracy: 0.9155\n",
      "Epoch 30/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.9100 - val_loss: 0.2236 - val_accuracy: 0.9147\n",
      "Epoch 31/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.9113 - val_loss: 0.2230 - val_accuracy: 0.9145\n",
      "Epoch 32/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9159 - val_loss: 0.2232 - val_accuracy: 0.9151\n",
      "Epoch 33/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9136 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 34/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9173 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 35/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9135 - val_loss: 0.2233 - val_accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9134 - val_loss: 0.2230 - val_accuracy: 0.9151\n",
      "Epoch 37/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9104 - val_loss: 0.2234 - val_accuracy: 0.9151\n",
      "Epoch 38/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9184 - val_loss: 0.2228 - val_accuracy: 0.9148\n",
      "Epoch 39/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9150 - val_loss: 0.2226 - val_accuracy: 0.9154\n",
      "Epoch 40/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9165 - val_loss: 0.2227 - val_accuracy: 0.9150\n",
      "Epoch 41/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9136 - val_loss: 0.2227 - val_accuracy: 0.9150\n",
      "Epoch 42/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9129 - val_loss: 0.2236 - val_accuracy: 0.9155\n",
      "Epoch 43/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9146 - val_loss: 0.2242 - val_accuracy: 0.9137\n",
      "Epoch 44/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9135 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 45/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9151 - val_loss: 0.2244 - val_accuracy: 0.9153\n",
      "Epoch 46/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9170 - val_loss: 0.2230 - val_accuracy: 0.9147\n",
      "Epoch 47/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9081 - val_loss: 0.2228 - val_accuracy: 0.9154\n",
      "Epoch 48/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9155 - val_loss: 0.2229 - val_accuracy: 0.9145\n",
      "Epoch 49/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9095 - val_loss: 0.2228 - val_accuracy: 0.9144\n",
      "Epoch 50/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9196 - val_loss: 0.2233 - val_accuracy: 0.9150\n",
      "Epoch 51/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9171 - val_loss: 0.2243 - val_accuracy: 0.9153\n",
      "Epoch 52/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9143 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9218 - val_loss: 0.2231 - val_accuracy: 0.9150\n",
      "Epoch 54/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9137 - val_loss: 0.2231 - val_accuracy: 0.9151\n",
      "Epoch 55/100\n",
      "428/428 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9158 - val_loss: 0.2230 - val_accuracy: 0.9147\n",
      "Epoch 56/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9199 - val_loss: 0.2247 - val_accuracy: 0.9149\n",
      "Epoch 57/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9182 - val_loss: 0.2235 - val_accuracy: 0.9137\n",
      "Epoch 58/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9142 - val_loss: 0.2229 - val_accuracy: 0.9151\n",
      "Epoch 59/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9132 - val_loss: 0.2232 - val_accuracy: 0.9144\n",
      "Epoch 60/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9185 - val_loss: 0.2230 - val_accuracy: 0.9143\n",
      "Epoch 61/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.9142 - val_loss: 0.2230 - val_accuracy: 0.9153\n",
      "Epoch 62/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9194 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 63/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9170 - val_loss: 0.2231 - val_accuracy: 0.9142\n",
      "Epoch 64/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9121 - val_loss: 0.2225 - val_accuracy: 0.9151\n",
      "Epoch 65/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9136 - val_loss: 0.2226 - val_accuracy: 0.9144\n",
      "Epoch 66/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9148 - val_loss: 0.2231 - val_accuracy: 0.9153\n",
      "Epoch 67/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9150 - val_loss: 0.2230 - val_accuracy: 0.9154\n",
      "Epoch 68/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9171 - val_loss: 0.2251 - val_accuracy: 0.9153\n",
      "Epoch 69/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9180 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 70/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9111 - val_loss: 0.2247 - val_accuracy: 0.9143\n",
      "Epoch 71/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9111 - val_loss: 0.2226 - val_accuracy: 0.9148\n",
      "Epoch 72/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9123 - val_loss: 0.2231 - val_accuracy: 0.9154\n",
      "Epoch 73/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9162 - val_loss: 0.2229 - val_accuracy: 0.9150\n",
      "Epoch 74/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9179 - val_loss: 0.2235 - val_accuracy: 0.9155\n",
      "Epoch 75/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.9222 - val_loss: 0.2227 - val_accuracy: 0.9153\n",
      "Epoch 76/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9125 - val_loss: 0.2239 - val_accuracy: 0.9133\n",
      "Epoch 77/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9141 - val_loss: 0.2229 - val_accuracy: 0.9153\n",
      "Epoch 78/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9104 - val_loss: 0.2237 - val_accuracy: 0.9153\n",
      "Epoch 79/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9177 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "Epoch 80/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.9169 - val_loss: 0.2230 - val_accuracy: 0.9154\n",
      "Epoch 81/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9113 - val_loss: 0.2231 - val_accuracy: 0.9153\n",
      "Epoch 82/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9201 - val_loss: 0.2230 - val_accuracy: 0.9148\n",
      "Epoch 83/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9145 - val_loss: 0.2257 - val_accuracy: 0.9149\n",
      "Epoch 84/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9115 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 85/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9117 - val_loss: 0.2235 - val_accuracy: 0.9136\n",
      "Epoch 86/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9148 - val_loss: 0.2236 - val_accuracy: 0.9153\n",
      "Epoch 87/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9127 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 88/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9195 - val_loss: 0.2243 - val_accuracy: 0.9150\n",
      "Epoch 89/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.9122 - val_loss: 0.2230 - val_accuracy: 0.9144\n",
      "Epoch 90/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.9107 - val_loss: 0.2228 - val_accuracy: 0.9151\n",
      "Epoch 91/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9161 - val_loss: 0.2225 - val_accuracy: 0.9148\n",
      "Epoch 92/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.9208 - val_loss: 0.2229 - val_accuracy: 0.9142\n",
      "Epoch 93/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9105 - val_loss: 0.2228 - val_accuracy: 0.9151\n",
      "Epoch 94/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.9181 - val_loss: 0.2228 - val_accuracy: 0.9151\n",
      "Epoch 95/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9140 - val_loss: 0.2226 - val_accuracy: 0.9150\n",
      "Epoch 96/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9081 - val_loss: 0.2224 - val_accuracy: 0.9150\n",
      "Epoch 97/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.9114 - val_loss: 0.2230 - val_accuracy: 0.9148\n",
      "Epoch 98/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9170 - val_loss: 0.2230 - val_accuracy: 0.9142\n",
      "Epoch 99/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.9145 - val_loss: 0.2226 - val_accuracy: 0.9147\n",
      "Epoch 100/100\n",
      "428/428 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9110 - val_loss: 0.2228 - val_accuracy: 0.9147\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8543, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8543, 1), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "(28479, 1)\n",
      "(28479, 1)\n"
     ]
    }
   ],
   "source": [
    "df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "t_enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    enm_mlp = ensemble_mlp()\n",
    "    t_enm_mlp_df = pd.concat([t_enm_mlp_df, enm_mlp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble mlp\n",
      "[0.7382, 0.5592, 0.5779, 0.8495, 117.4519, 67.8365]\n",
      "[0.151, 0.0324, 0.0554, 0.0135, 4.3103, 0.0478]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8195</td>\n",
       "      <td>0.5657</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.8559</td>\n",
       "      <td>127.1384</td>\n",
       "      <td>67.9558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4752</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>115.2460</td>\n",
       "      <td>67.8536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.6197</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>114.7007</td>\n",
       "      <td>67.8243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4752</td>\n",
       "      <td>0.8238</td>\n",
       "      <td>114.7314</td>\n",
       "      <td>67.8170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8016</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>117.1932</td>\n",
       "      <td>67.8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8342</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.8568</td>\n",
       "      <td>118.0349</td>\n",
       "      <td>67.8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.6220</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>122.3532</td>\n",
       "      <td>67.8687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>117.8220</td>\n",
       "      <td>67.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.5964</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>113.4779</td>\n",
       "      <td>67.8016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.5675</td>\n",
       "      <td>0.5946</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>113.8208</td>\n",
       "      <td>67.7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision  Recall  F1 score     AUC  Train time  Test time\n",
       "0     0.8195  0.5657    0.5922  0.8559    127.1384    67.9558\n",
       "1     0.4527  0.5000    0.4752  0.8240    115.2460    67.8536\n",
       "2     0.7929  0.5860    0.6197  0.8551    114.7007    67.8243\n",
       "3     0.4527  0.5000    0.4752  0.8238    114.7314    67.8170\n",
       "4     0.8016  0.5812    0.6138  0.8564    117.1932    67.8251\n",
       "5     0.8342  0.5625    0.5877  0.8568    118.0349    67.8216\n",
       "6     0.7926  0.5877    0.6220  0.8541    122.3532    67.8687\n",
       "7     0.8122  0.5730    0.6026  0.8569    117.8220    67.7975\n",
       "8     0.8118  0.5687    0.5964  0.8558    113.4779    67.8016\n",
       "9     0.8118  0.5675    0.5946  0.8566    113.8208    67.7999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Ensemble mlp')\n",
    "metrics = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "mean_mlp = []\n",
    "std_mlp = []\n",
    "for each in metrics:\n",
    "    mean_mlp.append(round(t_enm_mlp_df[each].mean(), ndigits=4))\n",
    "    std_mlp.append(round(t_enm_mlp_df[each].std(), ndigits=4))\n",
    "print(mean_mlp)\n",
    "print(std_mlp)\n",
    "t_enm_mlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
