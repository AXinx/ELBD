{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "      <th>txn_fail_num</th>\n",
       "      <th>CPU Busy</th>\n",
       "      <th>Sys Load (5m avg)</th>\n",
       "      <th>Sys Load (15m avg)</th>\n",
       "      <th>RAM Used</th>\n",
       "      <th>SWAP Used</th>\n",
       "      <th>CPU Cores</th>\n",
       "      <th>Uptime</th>\n",
       "      <th>...</th>\n",
       "      <th>InErrs - Segments received in error (e.g., bad TCP checksums)</th>\n",
       "      <th>CurrEstab - TCP connections for which the current state is either ESTABLISHED or CLOSE- WAIT</th>\n",
       "      <th>SyncookiesFailed - Invalid SYN cookies received</th>\n",
       "      <th>SyncookiesRecv - SYN cookies received</th>\n",
       "      <th>SyncookiesSent - SYN cookies sent</th>\n",
       "      <th>ActiveOpens - TCP connections that have made a direct transition to the SYN-SENT state from the CLOSED state</th>\n",
       "      <th>PassiveOpens - TCP connections that have made a direct transition to the SYN-RCVD state from the LISTEN state</th>\n",
       "      <th>arp - Scrape duration</th>\n",
       "      <th>arp - Scrape success</th>\n",
       "      <th>{{collector}} - Scrape textfile error (1 = true)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-17 09:33:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.634746</td>\n",
       "      <td>35.25</td>\n",
       "      <td>36.50</td>\n",
       "      <td>1.761575e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.347665e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-17 09:33:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.043220</td>\n",
       "      <td>38.50</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1.824432e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.347667e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-17 09:33:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.499153</td>\n",
       "      <td>40.75</td>\n",
       "      <td>38.25</td>\n",
       "      <td>1.876513e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.347668e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-17 09:33:45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.869492</td>\n",
       "      <td>45.25</td>\n",
       "      <td>39.75</td>\n",
       "      <td>1.886544e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.347670e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-17 09:34:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.991525</td>\n",
       "      <td>60.75</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1.889354e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.347671e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>2021-06-17 23:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.907627</td>\n",
       "      <td>85.25</td>\n",
       "      <td>144.25</td>\n",
       "      <td>2.379063e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.352513e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>2021-06-17 23:01:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.467797</td>\n",
       "      <td>82.75</td>\n",
       "      <td>142.50</td>\n",
       "      <td>2.384826e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.352515e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2021-06-17 23:01:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.074576</td>\n",
       "      <td>78.50</td>\n",
       "      <td>140.25</td>\n",
       "      <td>2.390565e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.352516e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>2021-06-17 23:01:45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.477119</td>\n",
       "      <td>75.25</td>\n",
       "      <td>138.00</td>\n",
       "      <td>2.391216e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.352518e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>2021-06-17 23:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.132203</td>\n",
       "      <td>71.75</td>\n",
       "      <td>136.00</td>\n",
       "      <td>2.393104e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.352519e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3237 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  label  txn_fail_num   CPU Busy  Sys Load (5m avg)  \\\n",
       "0    2021-06-17 09:33:00      0           0.0  11.634746              35.25   \n",
       "1    2021-06-17 09:33:15      0           0.0  13.043220              38.50   \n",
       "2    2021-06-17 09:33:30      0           0.0  14.499153              40.75   \n",
       "3    2021-06-17 09:33:45      0           0.0  15.869492              45.25   \n",
       "4    2021-06-17 09:34:00      0           0.0  16.991525              60.75   \n",
       "...                  ...    ...           ...        ...                ...   \n",
       "3232 2021-06-17 23:01:00      1         130.0  23.907627              85.25   \n",
       "3233 2021-06-17 23:01:15      0           0.0  22.467797              82.75   \n",
       "3234 2021-06-17 23:01:30      0           0.0  21.074576              78.50   \n",
       "3235 2021-06-17 23:01:45      0           0.0  20.477119              75.25   \n",
       "3236 2021-06-17 23:02:00      0           0.0  19.132203              71.75   \n",
       "\n",
       "      Sys Load (15m avg)      RAM Used  SWAP Used  CPU Cores        Uptime  \\\n",
       "0                  36.50  1.761575e+09        0.0        4.0  1.347665e+07   \n",
       "1                  37.50  1.824432e+09        0.0        4.0  1.347667e+07   \n",
       "2                  38.25  1.876513e+09        0.0        4.0  1.347668e+07   \n",
       "3                  39.75  1.886544e+09        0.0        4.0  1.347670e+07   \n",
       "4                  45.00  1.889354e+09        0.0        4.0  1.347671e+07   \n",
       "...                  ...           ...        ...        ...           ...   \n",
       "3232              144.25  2.379063e+09        0.0        4.0  1.352513e+07   \n",
       "3233              142.50  2.384826e+09        0.0        4.0  1.352515e+07   \n",
       "3234              140.25  2.390565e+09        0.0        4.0  1.352516e+07   \n",
       "3235              138.00  2.391216e+09        0.0        4.0  1.352518e+07   \n",
       "3236              136.00  2.393104e+09        0.0        4.0  1.352519e+07   \n",
       "\n",
       "      ...  InErrs - Segments received in error (e.g., bad TCP checksums)  \\\n",
       "0     ...                                                0.0               \n",
       "1     ...                                                0.0               \n",
       "2     ...                                                0.0               \n",
       "3     ...                                                0.0               \n",
       "4     ...                                                0.0               \n",
       "...   ...                                                ...               \n",
       "3232  ...                                                0.0               \n",
       "3233  ...                                                0.0               \n",
       "3234  ...                                                0.0               \n",
       "3235  ...                                                0.0               \n",
       "3236  ...                                                0.0               \n",
       "\n",
       "      CurrEstab - TCP connections for which the current state is either ESTABLISHED or CLOSE- WAIT  \\\n",
       "0                                                   1.0                                              \n",
       "1                                                   1.0                                              \n",
       "2                                                   1.0                                              \n",
       "3                                                   1.0                                              \n",
       "4                                                   1.0                                              \n",
       "...                                                 ...                                              \n",
       "3232                                                1.0                                              \n",
       "3233                                                1.0                                              \n",
       "3234                                                1.0                                              \n",
       "3235                                                1.0                                              \n",
       "3236                                                1.0                                              \n",
       "\n",
       "      SyncookiesFailed - Invalid SYN cookies received  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "3232                                              0.0   \n",
       "3233                                              0.0   \n",
       "3234                                              0.0   \n",
       "3235                                              0.0   \n",
       "3236                                              0.0   \n",
       "\n",
       "      SyncookiesRecv - SYN cookies received  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "3232                                    0.0   \n",
       "3233                                    0.0   \n",
       "3234                                    0.0   \n",
       "3235                                    0.0   \n",
       "3236                                    0.0   \n",
       "\n",
       "      SyncookiesSent - SYN cookies sent  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "...                                 ...   \n",
       "3232                                0.0   \n",
       "3233                                0.0   \n",
       "3234                                0.0   \n",
       "3235                                0.0   \n",
       "3236                                0.0   \n",
       "\n",
       "      ActiveOpens - TCP connections that have made a direct transition to the SYN-SENT state from the CLOSED state  \\\n",
       "0                                                   0.0                                                              \n",
       "1                                                   0.0                                                              \n",
       "2                                                   0.0                                                              \n",
       "3                                                   0.0                                                              \n",
       "4                                                   0.0                                                              \n",
       "...                                                 ...                                                              \n",
       "3232                                                0.0                                                              \n",
       "3233                                                0.0                                                              \n",
       "3234                                                0.0                                                              \n",
       "3235                                                0.0                                                              \n",
       "3236                                                0.0                                                              \n",
       "\n",
       "      PassiveOpens - TCP connections that have made a direct transition to the SYN-RCVD state from the LISTEN state  \\\n",
       "0                                                   0.0                                                               \n",
       "1                                                   0.0                                                               \n",
       "2                                                   0.0                                                               \n",
       "3                                                   0.0                                                               \n",
       "4                                                   0.0                                                               \n",
       "...                                                 ...                                                               \n",
       "3232                                                0.0                                                               \n",
       "3233                                                0.0                                                               \n",
       "3234                                                0.0                                                               \n",
       "3235                                                0.0                                                               \n",
       "3236                                                0.0                                                               \n",
       "\n",
       "      arp - Scrape duration  arp - Scrape success  \\\n",
       "0                  0.000097                   1.0   \n",
       "1                  0.000083                   1.0   \n",
       "2                  0.013587                   1.0   \n",
       "3                  0.000112                   1.0   \n",
       "4                  0.000108                   1.0   \n",
       "...                     ...                   ...   \n",
       "3232               0.000104                   1.0   \n",
       "3233               0.000081                   1.0   \n",
       "3234               0.000089                   1.0   \n",
       "3235               0.000120                   1.0   \n",
       "3236               0.000092                   1.0   \n",
       "\n",
       "      {{collector}} - Scrape textfile error (1 = true)  \n",
       "0                                                  0.0  \n",
       "1                                                  0.0  \n",
       "2                                                  0.0  \n",
       "3                                                  0.0  \n",
       "4                                                  0.0  \n",
       "...                                                ...  \n",
       "3232                                               0.0  \n",
       "3233                                               0.0  \n",
       "3234                                               0.0  \n",
       "3235                                               0.0  \n",
       "3236                                               0.0  \n",
       "\n",
       "[3237 rows x 201 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "f1 = open('all_metrics_data_12h.pkl', 'rb')\n",
    "label_data = pkl.load(f1)\n",
    "f2 = open('related_metrics_12h.pkl', 'rb')\n",
    "txn_failure_correlation = pkl.load(f2)\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28143342601173926"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_fraction = len(label_data[label_data['label'] == 1])/len(label_data)\n",
    "outlier_fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "      <th>txn_fail_num</th>\n",
       "      <th>CPU Busy</th>\n",
       "      <th>Sys Load (5m avg)</th>\n",
       "      <th>Sys Load (15m avg)</th>\n",
       "      <th>RAM Used</th>\n",
       "      <th>SWAP Used</th>\n",
       "      <th>CPU Cores</th>\n",
       "      <th>Uptime</th>\n",
       "      <th>...</th>\n",
       "      <th>InErrs - Segments received in error (e.g., bad TCP checksums)</th>\n",
       "      <th>CurrEstab - TCP connections for which the current state is either ESTABLISHED or CLOSE- WAIT</th>\n",
       "      <th>SyncookiesFailed - Invalid SYN cookies received</th>\n",
       "      <th>SyncookiesRecv - SYN cookies received</th>\n",
       "      <th>SyncookiesSent - SYN cookies sent</th>\n",
       "      <th>ActiveOpens - TCP connections that have made a direct transition to the SYN-SENT state from the CLOSED state</th>\n",
       "      <th>PassiveOpens - TCP connections that have made a direct transition to the SYN-RCVD state from the LISTEN state</th>\n",
       "      <th>arp - Scrape duration</th>\n",
       "      <th>arp - Scrape success</th>\n",
       "      <th>{{collector}} - Scrape textfile error (1 = true)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-17 09:33:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.078088</td>\n",
       "      <td>0.078054</td>\n",
       "      <td>0.104827</td>\n",
       "      <td>0.266319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-17 09:33:15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.093869</td>\n",
       "      <td>0.085407</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.288054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-17 09:33:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.110182</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.110106</td>\n",
       "      <td>0.306063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-17 09:33:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.125535</td>\n",
       "      <td>0.100679</td>\n",
       "      <td>0.114630</td>\n",
       "      <td>0.309532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-17 09:34:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.138107</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.130468</td>\n",
       "      <td>0.310503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>2021-06-17 23:01:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981353</td>\n",
       "      <td>0.215597</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.479838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>2021-06-17 23:01:15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.199464</td>\n",
       "      <td>0.185520</td>\n",
       "      <td>0.424585</td>\n",
       "      <td>0.481831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2021-06-17 23:01:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.183854</td>\n",
       "      <td>0.175905</td>\n",
       "      <td>0.417798</td>\n",
       "      <td>0.483815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>2021-06-17 23:01:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.177160</td>\n",
       "      <td>0.168552</td>\n",
       "      <td>0.411011</td>\n",
       "      <td>0.484041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>2021-06-17 23:02:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.162091</td>\n",
       "      <td>0.160633</td>\n",
       "      <td>0.404977</td>\n",
       "      <td>0.484694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3237 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  label  txn_fail_num  CPU Busy  Sys Load (5m avg)  \\\n",
       "0    2021-06-17 09:33:00    0.0      0.978715  0.078088           0.078054   \n",
       "1    2021-06-17 09:33:15    0.0      0.978715  0.093869           0.085407   \n",
       "2    2021-06-17 09:33:30    0.0      0.978715  0.110182           0.090498   \n",
       "3    2021-06-17 09:33:45    0.0      0.978715  0.125535           0.100679   \n",
       "4    2021-06-17 09:34:00    0.0      0.978715  0.138107           0.135747   \n",
       "...                  ...    ...           ...       ...                ...   \n",
       "3232 2021-06-17 23:01:00    1.0      0.981353  0.215597           0.191176   \n",
       "3233 2021-06-17 23:01:15    0.0      0.978715  0.199464           0.185520   \n",
       "3234 2021-06-17 23:01:30    0.0      0.978715  0.183854           0.175905   \n",
       "3235 2021-06-17 23:01:45    0.0      0.978715  0.177160           0.168552   \n",
       "3236 2021-06-17 23:02:00    0.0      0.978715  0.162091           0.160633   \n",
       "\n",
       "      Sys Load (15m avg)  RAM Used  SWAP Used  CPU Cores    Uptime  ...  \\\n",
       "0               0.104827  0.266319        0.0        0.0  0.000000  ...   \n",
       "1               0.107843  0.288054        0.0        0.0  0.000309  ...   \n",
       "2               0.110106  0.306063        0.0        0.0  0.000618  ...   \n",
       "3               0.114630  0.309532        0.0        0.0  0.000927  ...   \n",
       "4               0.130468  0.310503        0.0        0.0  0.001236  ...   \n",
       "...                  ...       ...        ...        ...       ...  ...   \n",
       "3232            0.429864  0.479838        0.0        0.0  0.998764  ...   \n",
       "3233            0.424585  0.481831        0.0        0.0  0.999073  ...   \n",
       "3234            0.417798  0.483815        0.0        0.0  0.999382  ...   \n",
       "3235            0.411011  0.484041        0.0        0.0  0.999691  ...   \n",
       "3236            0.404977  0.484694        0.0        0.0  1.000000  ...   \n",
       "\n",
       "      InErrs - Segments received in error (e.g., bad TCP checksums)  \\\n",
       "0                                                   0.0               \n",
       "1                                                   0.0               \n",
       "2                                                   0.0               \n",
       "3                                                   0.0               \n",
       "4                                                   0.0               \n",
       "...                                                 ...               \n",
       "3232                                                0.0               \n",
       "3233                                                0.0               \n",
       "3234                                                0.0               \n",
       "3235                                                0.0               \n",
       "3236                                                0.0               \n",
       "\n",
       "      CurrEstab - TCP connections for which the current state is either ESTABLISHED or CLOSE- WAIT  \\\n",
       "0                                                   0.0                                              \n",
       "1                                                   0.0                                              \n",
       "2                                                   0.0                                              \n",
       "3                                                   0.0                                              \n",
       "4                                                   0.0                                              \n",
       "...                                                 ...                                              \n",
       "3232                                                0.0                                              \n",
       "3233                                                0.0                                              \n",
       "3234                                                0.0                                              \n",
       "3235                                                0.0                                              \n",
       "3236                                                0.0                                              \n",
       "\n",
       "      SyncookiesFailed - Invalid SYN cookies received  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "3232                                              0.0   \n",
       "3233                                              0.0   \n",
       "3234                                              0.0   \n",
       "3235                                              0.0   \n",
       "3236                                              0.0   \n",
       "\n",
       "      SyncookiesRecv - SYN cookies received  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "3232                                    0.0   \n",
       "3233                                    0.0   \n",
       "3234                                    0.0   \n",
       "3235                                    0.0   \n",
       "3236                                    0.0   \n",
       "\n",
       "      SyncookiesSent - SYN cookies sent  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "...                                 ...   \n",
       "3232                                0.0   \n",
       "3233                                0.0   \n",
       "3234                                0.0   \n",
       "3235                                0.0   \n",
       "3236                                0.0   \n",
       "\n",
       "      ActiveOpens - TCP connections that have made a direct transition to the SYN-SENT state from the CLOSED state  \\\n",
       "0                                                   0.0                                                              \n",
       "1                                                   0.0                                                              \n",
       "2                                                   0.0                                                              \n",
       "3                                                   0.0                                                              \n",
       "4                                                   0.0                                                              \n",
       "...                                                 ...                                                              \n",
       "3232                                                0.0                                                              \n",
       "3233                                                0.0                                                              \n",
       "3234                                                0.0                                                              \n",
       "3235                                                0.0                                                              \n",
       "3236                                                0.0                                                              \n",
       "\n",
       "      PassiveOpens - TCP connections that have made a direct transition to the SYN-RCVD state from the LISTEN state  \\\n",
       "0                                                   0.0                                                               \n",
       "1                                                   0.0                                                               \n",
       "2                                                   0.0                                                               \n",
       "3                                                   0.0                                                               \n",
       "4                                                   0.0                                                               \n",
       "...                                                 ...                                                               \n",
       "3232                                                0.0                                                               \n",
       "3233                                                0.0                                                               \n",
       "3234                                                0.0                                                               \n",
       "3235                                                0.0                                                               \n",
       "3236                                                0.0                                                               \n",
       "\n",
       "      arp - Scrape duration  arp - Scrape success  \\\n",
       "0                  0.000999                   0.0   \n",
       "1                  0.000527                   0.0   \n",
       "2                  0.437333                   0.0   \n",
       "3                  0.001488                   0.0   \n",
       "4                  0.001362                   0.0   \n",
       "...                     ...                   ...   \n",
       "3232               0.001213                   0.0   \n",
       "3233               0.000466                   0.0   \n",
       "3234               0.000734                   0.0   \n",
       "3235               0.001724                   0.0   \n",
       "3236               0.000822                   0.0   \n",
       "\n",
       "      {{collector}} - Scrape textfile error (1 = true)  \n",
       "0                                                  0.0  \n",
       "1                                                  0.0  \n",
       "2                                                  0.0  \n",
       "3                                                  0.0  \n",
       "4                                                  0.0  \n",
       "...                                                ...  \n",
       "3232                                               0.0  \n",
       "3233                                               0.0  \n",
       "3234                                               0.0  \n",
       "3235                                               0.0  \n",
       "3236                                               0.0  \n",
       "\n",
       "[3237 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = pd.DataFrame(scaler.fit_transform(label_data.drop(['time'], axis=1)))\n",
    "normalized_data.columns = label_data.columns[1:]\n",
    "normalized_label_data = pd.merge(label_data.time, normalized_data, left_index=True, right_index=True, how='left')\n",
    "normalized_label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.628476</td>\n",
       "      <td>-0.629605</td>\n",
       "      <td>2.652079</td>\n",
       "      <td>1.099140</td>\n",
       "      <td>1.614239</td>\n",
       "      <td>0.153452</td>\n",
       "      <td>1.368393</td>\n",
       "      <td>0.081433</td>\n",
       "      <td>0.224311</td>\n",
       "      <td>-0.088355</td>\n",
       "      <td>0.488833</td>\n",
       "      <td>0.571502</td>\n",
       "      <td>0.471916</td>\n",
       "      <td>-0.373341</td>\n",
       "      <td>0.276795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.514359</td>\n",
       "      <td>-0.683051</td>\n",
       "      <td>2.611074</td>\n",
       "      <td>1.078258</td>\n",
       "      <td>1.602711</td>\n",
       "      <td>0.152961</td>\n",
       "      <td>1.385538</td>\n",
       "      <td>0.089866</td>\n",
       "      <td>0.205289</td>\n",
       "      <td>-0.088692</td>\n",
       "      <td>0.487518</td>\n",
       "      <td>0.583951</td>\n",
       "      <td>0.465260</td>\n",
       "      <td>-0.339499</td>\n",
       "      <td>0.246520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.399568</td>\n",
       "      <td>-0.739660</td>\n",
       "      <td>2.566976</td>\n",
       "      <td>1.074209</td>\n",
       "      <td>1.616582</td>\n",
       "      <td>0.135461</td>\n",
       "      <td>1.421066</td>\n",
       "      <td>0.071216</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>-0.020982</td>\n",
       "      <td>0.467465</td>\n",
       "      <td>0.559261</td>\n",
       "      <td>0.375916</td>\n",
       "      <td>-0.368485</td>\n",
       "      <td>0.182618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.295562</td>\n",
       "      <td>-0.772949</td>\n",
       "      <td>2.531558</td>\n",
       "      <td>1.017152</td>\n",
       "      <td>1.603817</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>1.444848</td>\n",
       "      <td>0.116725</td>\n",
       "      <td>0.173576</td>\n",
       "      <td>-0.074490</td>\n",
       "      <td>0.477223</td>\n",
       "      <td>0.520178</td>\n",
       "      <td>0.303817</td>\n",
       "      <td>-0.328115</td>\n",
       "      <td>0.200811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.185498</td>\n",
       "      <td>-0.796569</td>\n",
       "      <td>2.492199</td>\n",
       "      <td>0.985679</td>\n",
       "      <td>1.610759</td>\n",
       "      <td>0.126438</td>\n",
       "      <td>1.419630</td>\n",
       "      <td>0.137401</td>\n",
       "      <td>0.154677</td>\n",
       "      <td>-0.094233</td>\n",
       "      <td>0.484262</td>\n",
       "      <td>0.519646</td>\n",
       "      <td>0.302790</td>\n",
       "      <td>-0.289621</td>\n",
       "      <td>0.190954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>-0.124648</td>\n",
       "      <td>-0.544708</td>\n",
       "      <td>0.606105</td>\n",
       "      <td>-1.065107</td>\n",
       "      <td>0.380935</td>\n",
       "      <td>0.489242</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>-0.012139</td>\n",
       "      <td>-0.320114</td>\n",
       "      <td>0.306998</td>\n",
       "      <td>0.271045</td>\n",
       "      <td>0.244867</td>\n",
       "      <td>-0.286807</td>\n",
       "      <td>0.125852</td>\n",
       "      <td>-0.147036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>-0.258835</td>\n",
       "      <td>-0.491280</td>\n",
       "      <td>0.640420</td>\n",
       "      <td>-1.033738</td>\n",
       "      <td>0.350921</td>\n",
       "      <td>0.537932</td>\n",
       "      <td>0.938297</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>-0.306705</td>\n",
       "      <td>0.285675</td>\n",
       "      <td>0.257746</td>\n",
       "      <td>0.257559</td>\n",
       "      <td>-0.283649</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>-0.143130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>-0.347211</td>\n",
       "      <td>-0.456669</td>\n",
       "      <td>0.664849</td>\n",
       "      <td>-0.987720</td>\n",
       "      <td>0.345878</td>\n",
       "      <td>0.552619</td>\n",
       "      <td>0.925334</td>\n",
       "      <td>-0.023656</td>\n",
       "      <td>-0.290638</td>\n",
       "      <td>0.327191</td>\n",
       "      <td>0.255603</td>\n",
       "      <td>0.293123</td>\n",
       "      <td>-0.217731</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>-0.144944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>-0.385334</td>\n",
       "      <td>-0.466455</td>\n",
       "      <td>0.665397</td>\n",
       "      <td>-0.975486</td>\n",
       "      <td>0.192788</td>\n",
       "      <td>0.554839</td>\n",
       "      <td>0.808182</td>\n",
       "      <td>-0.017850</td>\n",
       "      <td>-0.336697</td>\n",
       "      <td>0.316460</td>\n",
       "      <td>0.167265</td>\n",
       "      <td>0.180070</td>\n",
       "      <td>-0.221132</td>\n",
       "      <td>0.100589</td>\n",
       "      <td>-0.122154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>-0.459990</td>\n",
       "      <td>-0.462797</td>\n",
       "      <td>0.638574</td>\n",
       "      <td>-0.942256</td>\n",
       "      <td>-0.110656</td>\n",
       "      <td>0.500622</td>\n",
       "      <td>0.393414</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>-0.418428</td>\n",
       "      <td>0.247494</td>\n",
       "      <td>0.036479</td>\n",
       "      <td>0.151730</td>\n",
       "      <td>-0.292859</td>\n",
       "      <td>0.023642</td>\n",
       "      <td>-0.140114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3237 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.628476 -0.629605  2.652079  1.099140  1.614239  0.153452  1.368393   \n",
       "1    -0.514359 -0.683051  2.611074  1.078258  1.602711  0.152961  1.385538   \n",
       "2    -0.399568 -0.739660  2.566976  1.074209  1.616582  0.135461  1.421066   \n",
       "3    -0.295562 -0.772949  2.531558  1.017152  1.603817  0.119985  1.444848   \n",
       "4    -0.185498 -0.796569  2.492199  0.985679  1.610759  0.126438  1.419630   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3232 -0.124648 -0.544708  0.606105 -1.065107  0.380935  0.489242  0.928313   \n",
       "3233 -0.258835 -0.491280  0.640420 -1.033738  0.350921  0.537932  0.938297   \n",
       "3234 -0.347211 -0.456669  0.664849 -0.987720  0.345878  0.552619  0.925334   \n",
       "3235 -0.385334 -0.466455  0.665397 -0.975486  0.192788  0.554839  0.808182   \n",
       "3236 -0.459990 -0.462797  0.638574 -0.942256 -0.110656  0.500622  0.393414   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0     0.081433  0.224311 -0.088355  0.488833  0.571502  0.471916 -0.373341   \n",
       "1     0.089866  0.205289 -0.088692  0.487518  0.583951  0.465260 -0.339499   \n",
       "2     0.071216  0.204004 -0.020982  0.467465  0.559261  0.375916 -0.368485   \n",
       "3     0.116725  0.173576 -0.074490  0.477223  0.520178  0.303817 -0.328115   \n",
       "4     0.137401  0.154677 -0.094233  0.484262  0.519646  0.302790 -0.289621   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3232 -0.012139 -0.320114  0.306998  0.271045  0.244867 -0.286807  0.125852   \n",
       "3233  0.008353 -0.306705  0.285675  0.257746  0.257559 -0.283649  0.123457   \n",
       "3234 -0.023656 -0.290638  0.327191  0.255603  0.293123 -0.217731  0.099400   \n",
       "3235 -0.017850 -0.336697  0.316460  0.167265  0.180070 -0.221132  0.100589   \n",
       "3236  0.034284 -0.418428  0.247494  0.036479  0.151730 -0.292859  0.023642   \n",
       "\n",
       "            14  \n",
       "0     0.276795  \n",
       "1     0.246520  \n",
       "2     0.182618  \n",
       "3     0.200811  \n",
       "4     0.190954  \n",
       "...        ...  \n",
       "3232 -0.147036  \n",
       "3233 -0.143130  \n",
       "3234 -0.144944  \n",
       "3235 -0.122154  \n",
       "3236 -0.140114  \n",
       "\n",
       "[3237 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# all, cor, pca\n",
    "data_feature = 'pca' \n",
    "if data_feature == 'all':\n",
    "    related_label_data = normalized_label_data.drop(['time', 'label', 'txn_fail_num'], axis=1)\n",
    "if data_feature == 'cor':\n",
    "    related_metrics_name = txn_failure_correlation.index\n",
    "    related_label_data = normalized_label_data[related_metrics_name]\n",
    "if data_feature == 'pca':\n",
    "    pca = PCA(n_components=15)\n",
    "    related_label_data = pca.fit_transform(normalized_label_data.drop(['time', 'label', 'txn_fail_num'], axis=1))\n",
    "    related_label_data = pd.DataFrame(related_label_data)\n",
    "related_label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "# supress warnings for clean output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from pyod.models.combination import aom, moa, average, maximization, majority_vote\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_labels(y_test, test_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, test_scores)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    pred_label = []\n",
    "    for each in test_scores:\n",
    "        if each > cutoff:\n",
    "            pred_label.append(1)\n",
    "        else:\n",
    "            pred_label.append(0)    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eval(label, pred_label, scores):\n",
    "    pr = round(metrics.precision_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    re = round(metrics.recall_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    f1 = round(metrics.f1_score(label, pred_label, average='macro'), ndigits=4)\n",
    "    roc = round(roc_auc_score(label, scores), ndigits=4)\n",
    "    return pr,re,f1,roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame(normalized_label_data[normalized_label_data.columns[:3]]) \n",
    "X_train = related_label_data\n",
    "y_train = labels_df['label']\n",
    "X_test = related_label_data\n",
    "y_test = labels_df['label']\n",
    "outliers_fraction = np.count_nonzero(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base detector 1 is fitted for prediction\n",
      "Base detector 2 is fitted for prediction\n",
      "Base detector 3 is fitted for prediction\n",
      "Base detector 4 is fitted for prediction\n",
      "1.4361000000000002\n"
     ]
    }
   ],
   "source": [
    "outliers_fraction = np.count_nonzero(y_train) / len(y_train)\n",
    "outliers_percentage = round(outliers_fraction * 100, ndigits=4)\n",
    "    \n",
    "random_state = np.random.RandomState(42)\n",
    "classifiers = {\n",
    "        'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                    random_state=random_state),\n",
    "        'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "        'Local Outlier Factor (LOF)': LOF(\n",
    "            contamination=outliers_fraction),\n",
    "        'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction)\n",
    "    }\n",
    "\n",
    "n_clf = len(classifiers)\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
    "p_labels = np.zeros([X_test.shape[0], n_clf])\n",
    "\n",
    "i = 0\n",
    "train_duration = 0\n",
    "test_duration = 0\n",
    "for clf_name, clf in classifiers.items():\n",
    "    t0 = time()\n",
    "    clf.fit(X_train)\n",
    "    t1 = time()\n",
    "    test_sccore = clf.decision_function(X_test)\n",
    "    t_t = time()\n",
    "    test_mean_score = np.nanmean(test_scores)\n",
    "    test_scores[np.isnan(test_scores)] = test_mean_score\n",
    "    test_scores[:, i] = test_sccore\n",
    "    p_labels[:, i] = pred_labels(y_test, test_sccore)\n",
    "    i += 1\n",
    "    print('Base detector %i is fitted for prediction' % i)\n",
    "    train_duration += round(t1 - t0, ndigits=4)\n",
    "    test_duration += round(t_t - t1, ndigits=4)\n",
    "    \n",
    "# standardize test score\n",
    "test_scores_norm = standardizer(test_scores)\n",
    "print(train_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from time import time\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(test_scores_norm, y_test, test_size=0.9, random_state=random_state)\n",
    "#train_x, test_x, train_y, test_y = train_test_split(test_scores_norm[:,3], y_test, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ensemble_mlp():\n",
    "    df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "    enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    t2 = time()\n",
    "    model = models.Sequential()\n",
    "    # Input - Layer\n",
    "    model.add(layers.Dense(4, activation = \"relu\", input_shape=(len(train_y),4)))\n",
    "    model.add(layers.Dense(20, activation = \"relu\"))\n",
    "    model.add(layers.Dense(20, activation = \"relu\"))\n",
    "    # Output- Layer\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "    model.summary()\n",
    "    # compiling the model\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    results = model.fit(\n",
    "     train_x, train_y,\n",
    "     epochs= 100,\n",
    "     batch_size = 20,\n",
    "     validation_data = (train_x, train_y)\n",
    "    )\n",
    "    t3 = time()\n",
    "    #print(results.history['val_accuracy'])\n",
    "    #pred_test = model.predict(test_scores_norm[:,0]).reshape(len(test_scores_norm),1)\n",
    "    pred_test = model.predict(test_scores_norm)\n",
    "    #pred_test = model.predict(test_x)\n",
    "    t4 = time()\n",
    "    train_time = t3 - t2\n",
    "    test_time = t4 - t3\n",
    "    train_time_mlp =  round(train_duration+train_time, ndigits=4)\n",
    "    test_time_mlp = round(test_duration+test_time, ndigits=4)\n",
    "    \n",
    "    pred_nn = []\n",
    "    for each in pred_test:\n",
    "        if each[0] > 0.5:\n",
    "            pred_nn.append(1)\n",
    "        else:\n",
    "            pred_nn.append(0)\n",
    "    #pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(test_y, pred_nn, pred_test)\n",
    "    pr_mlp, re_mlp, f1_mlp, roc_mlp = cal_eval(y_test, pred_nn, pred_test)\n",
    "    enm_mlp = pd.DataFrame([pr_mlp, re_mlp, f1_mlp, roc_mlp, train_time_mlp, test_time_mlp]).transpose()\n",
    "    enm_mlp.columns = df_columns\n",
    "    enm_mlp_df = pd.concat([enm_mlp_df, enm_mlp], axis=0)\n",
    "    return enm_mlp_df, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 14:40:14.707603: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-26 14:40:14.970444: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      " 1/17 [>.............................] - ETA: 4:43 - loss: 0.7058 - accuracy: 0.5000WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 18s 28ms/step - loss: 0.6970 - accuracy: 0.5127 - val_loss: 0.6540 - val_accuracy: 0.7152\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7529 - val_loss: 0.6115 - val_accuracy: 0.7121\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6900 - val_loss: 0.5837 - val_accuracy: 0.7121\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7354 - val_loss: 0.5534 - val_accuracy: 0.7121\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7419 - val_loss: 0.5295 - val_accuracy: 0.7121\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7037 - val_loss: 0.5095 - val_accuracy: 0.7121\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7088 - val_loss: 0.4915 - val_accuracy: 0.7121\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7311 - val_loss: 0.4767 - val_accuracy: 0.7121\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.6707 - val_loss: 0.4669 - val_accuracy: 0.7121\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7282 - val_loss: 0.4559 - val_accuracy: 0.7337\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7755 - val_loss: 0.4476 - val_accuracy: 0.7368\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7107 - val_loss: 0.4397 - val_accuracy: 0.7430\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7234 - val_loss: 0.4324 - val_accuracy: 0.7399\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7227 - val_loss: 0.4279 - val_accuracy: 0.7864\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7834 - val_loss: 0.4216 - val_accuracy: 0.7802\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7896 - val_loss: 0.4165 - val_accuracy: 0.7895\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7908 - val_loss: 0.4123 - val_accuracy: 0.7988\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8315 - val_loss: 0.4088 - val_accuracy: 0.8019\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7987 - val_loss: 0.4038 - val_accuracy: 0.7957\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8084 - val_loss: 0.3992 - val_accuracy: 0.7988\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8327 - val_loss: 0.3946 - val_accuracy: 0.8080\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8338 - val_loss: 0.3899 - val_accuracy: 0.8111\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8042 - val_loss: 0.3871 - val_accuracy: 0.8142\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8278 - val_loss: 0.3838 - val_accuracy: 0.8204\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8200 - val_loss: 0.3782 - val_accuracy: 0.8297\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8076 - val_loss: 0.3741 - val_accuracy: 0.8421\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8506 - val_loss: 0.3697 - val_accuracy: 0.8452\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8503 - val_loss: 0.3652 - val_accuracy: 0.8514\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8584 - val_loss: 0.3626 - val_accuracy: 0.8762\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8879 - val_loss: 0.3581 - val_accuracy: 0.8731\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8852 - val_loss: 0.3543 - val_accuracy: 0.8576\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8696 - val_loss: 0.3510 - val_accuracy: 0.8545\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8764 - val_loss: 0.3484 - val_accuracy: 0.8669\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8238 - val_loss: 0.3458 - val_accuracy: 0.8576\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3274 - accuracy: 0.8810 - val_loss: 0.3432 - val_accuracy: 0.8700\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8715 - val_loss: 0.3406 - val_accuracy: 0.8607\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8683 - val_loss: 0.3383 - val_accuracy: 0.8669\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8695 - val_loss: 0.3364 - val_accuracy: 0.8669\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8764 - val_loss: 0.3351 - val_accuracy: 0.8669\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8734 - val_loss: 0.3329 - val_accuracy: 0.8700\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8487 - val_loss: 0.3325 - val_accuracy: 0.8793\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8606 - val_loss: 0.3290 - val_accuracy: 0.8793\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8769 - val_loss: 0.3268 - val_accuracy: 0.8762\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8663 - val_loss: 0.3244 - val_accuracy: 0.8793\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.9030 - val_loss: 0.3220 - val_accuracy: 0.8824\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8819 - val_loss: 0.3196 - val_accuracy: 0.8854\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8707 - val_loss: 0.3171 - val_accuracy: 0.8854\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.9078 - val_loss: 0.3162 - val_accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8700 - val_loss: 0.3139 - val_accuracy: 0.8854\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8995 - val_loss: 0.3118 - val_accuracy: 0.8885\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8845 - val_loss: 0.3102 - val_accuracy: 0.8854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8901 - val_loss: 0.3079 - val_accuracy: 0.8854\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8727 - val_loss: 0.3064 - val_accuracy: 0.8854\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8855 - val_loss: 0.3056 - val_accuracy: 0.8854\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8776 - val_loss: 0.3038 - val_accuracy: 0.8854\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8977 - val_loss: 0.3023 - val_accuracy: 0.8824\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9120 - val_loss: 0.3012 - val_accuracy: 0.8885\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8717 - val_loss: 0.3007 - val_accuracy: 0.8793\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8814 - val_loss: 0.2988 - val_accuracy: 0.8854\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8661 - val_loss: 0.2979 - val_accuracy: 0.8885\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8710 - val_loss: 0.2968 - val_accuracy: 0.8854\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8719 - val_loss: 0.2960 - val_accuracy: 0.8854\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8954 - val_loss: 0.2969 - val_accuracy: 0.8824\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8816 - val_loss: 0.2944 - val_accuracy: 0.8885\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.9030 - val_loss: 0.2932 - val_accuracy: 0.8854\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8970 - val_loss: 0.2923 - val_accuracy: 0.8854\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8888 - val_loss: 0.2916 - val_accuracy: 0.8885\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9014 - val_loss: 0.2908 - val_accuracy: 0.8885\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.9011 - val_loss: 0.2896 - val_accuracy: 0.8885\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8920 - val_loss: 0.2884 - val_accuracy: 0.8854\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8820 - val_loss: 0.2874 - val_accuracy: 0.8854\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.8942 - val_loss: 0.2865 - val_accuracy: 0.8885\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8978 - val_loss: 0.2852 - val_accuracy: 0.8916\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8916 - val_loss: 0.2842 - val_accuracy: 0.8916\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9061 - val_loss: 0.2829 - val_accuracy: 0.8947\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.9076 - val_loss: 0.2816 - val_accuracy: 0.8978\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8991 - val_loss: 0.2800 - val_accuracy: 0.8947\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8798 - val_loss: 0.2793 - val_accuracy: 0.8947\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8851 - val_loss: 0.2772 - val_accuracy: 0.8947\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8986 - val_loss: 0.2758 - val_accuracy: 0.8947\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8895 - val_loss: 0.2746 - val_accuracy: 0.8947\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9263 - val_loss: 0.2735 - val_accuracy: 0.9040\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8945 - val_loss: 0.2719 - val_accuracy: 0.9009\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8969 - val_loss: 0.2708 - val_accuracy: 0.8947\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9001 - val_loss: 0.2694 - val_accuracy: 0.8947\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.9042 - val_loss: 0.2697 - val_accuracy: 0.8978\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8908 - val_loss: 0.2674 - val_accuracy: 0.8916\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9067 - val_loss: 0.2680 - val_accuracy: 0.8978\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8820 - val_loss: 0.2665 - val_accuracy: 0.8978\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.8885 - val_loss: 0.2648 - val_accuracy: 0.8978\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8871 - val_loss: 0.2625 - val_accuracy: 0.8947\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9186 - val_loss: 0.2609 - val_accuracy: 0.8947\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2404 - accuracy: 0.9032 - val_loss: 0.2600 - val_accuracy: 0.8947\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8916 - val_loss: 0.2596 - val_accuracy: 0.9040\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9275 - val_loss: 0.2589 - val_accuracy: 0.9133\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9188 - val_loss: 0.2569 - val_accuracy: 0.9009\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.8901 - val_loss: 0.2551 - val_accuracy: 0.9071\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9112 - val_loss: 0.2548 - val_accuracy: 0.9071\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8941 - val_loss: 0.2545 - val_accuracy: 0.9102\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8944 - val_loss: 0.2532 - val_accuracy: 0.9071\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      " 1/17 [>.............................] - ETA: 12s - loss: 0.6833 - accuracy: 0.3000WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 1s 15ms/step - loss: 0.7181 - accuracy: 0.4129 - val_loss: 0.6852 - val_accuracy: 0.7399\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.7456 - val_loss: 0.6494 - val_accuracy: 0.8297\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.8083 - val_loss: 0.6173 - val_accuracy: 0.8050\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.7866 - val_loss: 0.5792 - val_accuracy: 0.7988\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.8039 - val_loss: 0.5347 - val_accuracy: 0.8235\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.8254 - val_loss: 0.4904 - val_accuracy: 0.8390\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8152 - val_loss: 0.4517 - val_accuracy: 0.8359\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8510 - val_loss: 0.4225 - val_accuracy: 0.8483\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8389 - val_loss: 0.4024 - val_accuracy: 0.8576\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8662 - val_loss: 0.3854 - val_accuracy: 0.8638\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8512 - val_loss: 0.3742 - val_accuracy: 0.8700\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8715 - val_loss: 0.3656 - val_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8797 - val_loss: 0.3597 - val_accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8911 - val_loss: 0.3551 - val_accuracy: 0.8731\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8794 - val_loss: 0.3519 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8475 - val_loss: 0.3488 - val_accuracy: 0.8731\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8739 - val_loss: 0.3470 - val_accuracy: 0.8731\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8665 - val_loss: 0.3436 - val_accuracy: 0.8731\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8807 - val_loss: 0.3406 - val_accuracy: 0.8762\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8862 - val_loss: 0.3383 - val_accuracy: 0.8762\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8715 - val_loss: 0.3370 - val_accuracy: 0.8762\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8681 - val_loss: 0.3335 - val_accuracy: 0.8793\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8711 - val_loss: 0.3312 - val_accuracy: 0.8731\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8866 - val_loss: 0.3297 - val_accuracy: 0.8854\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.9057 - val_loss: 0.3272 - val_accuracy: 0.8824\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8646 - val_loss: 0.3251 - val_accuracy: 0.8824\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8961 - val_loss: 0.3237 - val_accuracy: 0.8793\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8406 - val_loss: 0.3258 - val_accuracy: 0.8731\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8504 - val_loss: 0.3199 - val_accuracy: 0.8854\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8987 - val_loss: 0.3185 - val_accuracy: 0.8854\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8523 - val_loss: 0.3163 - val_accuracy: 0.8824\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9008 - val_loss: 0.3153 - val_accuracy: 0.8854\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8840 - val_loss: 0.3137 - val_accuracy: 0.8824\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8791 - val_loss: 0.3127 - val_accuracy: 0.8885\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.9000 - val_loss: 0.3115 - val_accuracy: 0.8824\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8867 - val_loss: 0.3100 - val_accuracy: 0.8854\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8758 - val_loss: 0.3087 - val_accuracy: 0.8854\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9213 - val_loss: 0.3070 - val_accuracy: 0.8885\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8748 - val_loss: 0.3057 - val_accuracy: 0.8885\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.9008 - val_loss: 0.3045 - val_accuracy: 0.8854\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8670 - val_loss: 0.3033 - val_accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.8979 - val_loss: 0.3026 - val_accuracy: 0.8916\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8979 - val_loss: 0.3014 - val_accuracy: 0.8916\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8738 - val_loss: 0.3008 - val_accuracy: 0.8916\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.9014 - val_loss: 0.2996 - val_accuracy: 0.8947\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8763 - val_loss: 0.2986 - val_accuracy: 0.8947\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.9130 - val_loss: 0.2980 - val_accuracy: 0.8885\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9033 - val_loss: 0.2972 - val_accuracy: 0.8947\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8926 - val_loss: 0.2969 - val_accuracy: 0.8916\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9034 - val_loss: 0.2962 - val_accuracy: 0.8947\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9084 - val_loss: 0.2946 - val_accuracy: 0.8947\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8983 - val_loss: 0.2942 - val_accuracy: 0.8916\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8642 - val_loss: 0.2933 - val_accuracy: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8670 - val_loss: 0.2925 - val_accuracy: 0.8947\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.9036 - val_loss: 0.2918 - val_accuracy: 0.8978\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.9034 - val_loss: 0.2916 - val_accuracy: 0.8916\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8794 - val_loss: 0.2909 - val_accuracy: 0.8947\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8990 - val_loss: 0.2904 - val_accuracy: 0.8947\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.8993 - val_loss: 0.2905 - val_accuracy: 0.8947\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8891 - val_loss: 0.2905 - val_accuracy: 0.8916\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8779 - val_loss: 0.2884 - val_accuracy: 0.8947\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8843 - val_loss: 0.2883 - val_accuracy: 0.8978\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.9020 - val_loss: 0.2876 - val_accuracy: 0.8978\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9145 - val_loss: 0.2869 - val_accuracy: 0.8916\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.8904 - val_loss: 0.2863 - val_accuracy: 0.9009\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8826 - val_loss: 0.2854 - val_accuracy: 0.8947\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9060 - val_loss: 0.2853 - val_accuracy: 0.8978\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8992 - val_loss: 0.2845 - val_accuracy: 0.8947\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.8872 - val_loss: 0.2843 - val_accuracy: 0.8978\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8997 - val_loss: 0.2833 - val_accuracy: 0.8978\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8945 - val_loss: 0.2832 - val_accuracy: 0.8978\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8904 - val_loss: 0.2824 - val_accuracy: 0.8978\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8870 - val_loss: 0.2817 - val_accuracy: 0.8978\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9196 - val_loss: 0.2819 - val_accuracy: 0.8978\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8963 - val_loss: 0.2809 - val_accuracy: 0.8978\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8964 - val_loss: 0.2800 - val_accuracy: 0.8978\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.9122 - val_loss: 0.2799 - val_accuracy: 0.8978\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9160 - val_loss: 0.2797 - val_accuracy: 0.8978\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8785 - val_loss: 0.2789 - val_accuracy: 0.8978\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.9070 - val_loss: 0.2803 - val_accuracy: 0.9009\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8973 - val_loss: 0.2776 - val_accuracy: 0.8978\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8927 - val_loss: 0.2774 - val_accuracy: 0.8947\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8908 - val_loss: 0.2764 - val_accuracy: 0.8947\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8753 - val_loss: 0.2756 - val_accuracy: 0.8978\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8847 - val_loss: 0.2750 - val_accuracy: 0.8978\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8886 - val_loss: 0.2751 - val_accuracy: 0.8978\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8743 - val_loss: 0.2743 - val_accuracy: 0.8978\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.9128 - val_loss: 0.2742 - val_accuracy: 0.9040\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8900 - val_loss: 0.2733 - val_accuracy: 0.8978\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.9113 - val_loss: 0.2731 - val_accuracy: 0.8947\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8910 - val_loss: 0.2725 - val_accuracy: 0.8978\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2518 - accuracy: 0.9122 - val_loss: 0.2720 - val_accuracy: 0.8978\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9125 - val_loss: 0.2741 - val_accuracy: 0.9009\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9298 - val_loss: 0.2719 - val_accuracy: 0.9009\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8804 - val_loss: 0.2713 - val_accuracy: 0.8978\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.8830 - val_loss: 0.2707 - val_accuracy: 0.8978\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9198 - val_loss: 0.2703 - val_accuracy: 0.9040\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9142 - val_loss: 0.2697 - val_accuracy: 0.9009\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8939 - val_loss: 0.2690 - val_accuracy: 0.9009\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8933 - val_loss: 0.2685 - val_accuracy: 0.9009\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 18s - loss: 0.7100 - accuracy: 0.2500WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 2s 23ms/step - loss: 0.6997 - accuracy: 0.4993 - val_loss: 0.6827 - val_accuracy: 0.7059\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.6920 - val_loss: 0.6635 - val_accuracy: 0.7121\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.7402 - val_loss: 0.6383 - val_accuracy: 0.7121\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.7367 - val_loss: 0.6061 - val_accuracy: 0.7059\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6821 - val_loss: 0.5693 - val_accuracy: 0.7090\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7259 - val_loss: 0.5252 - val_accuracy: 0.7059\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7105 - val_loss: 0.4882 - val_accuracy: 0.7245\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7319 - val_loss: 0.4582 - val_accuracy: 0.7214\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.6983 - val_loss: 0.4353 - val_accuracy: 0.7430\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7391 - val_loss: 0.4214 - val_accuracy: 0.7307\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.7236 - val_loss: 0.4099 - val_accuracy: 0.8328\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8222 - val_loss: 0.4013 - val_accuracy: 0.8266\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8361 - val_loss: 0.3941 - val_accuracy: 0.8266\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7948 - val_loss: 0.3886 - val_accuracy: 0.8266\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8236 - val_loss: 0.3835 - val_accuracy: 0.8328\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8160 - val_loss: 0.3790 - val_accuracy: 0.8390\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8336 - val_loss: 0.3755 - val_accuracy: 0.8359\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8521 - val_loss: 0.3708 - val_accuracy: 0.8452\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8516 - val_loss: 0.3698 - val_accuracy: 0.8669\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8552 - val_loss: 0.3655 - val_accuracy: 0.8483\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.8534 - val_loss: 0.3607 - val_accuracy: 0.8421\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8433 - val_loss: 0.3573 - val_accuracy: 0.8545\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8415 - val_loss: 0.3553 - val_accuracy: 0.8452\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8310 - val_loss: 0.3519 - val_accuracy: 0.8669\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8474 - val_loss: 0.3492 - val_accuracy: 0.8576\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8735 - val_loss: 0.3464 - val_accuracy: 0.8731\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8874 - val_loss: 0.3443 - val_accuracy: 0.8854\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8308 - val_loss: 0.3407 - val_accuracy: 0.8762\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8649 - val_loss: 0.3382 - val_accuracy: 0.8669\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8662 - val_loss: 0.3355 - val_accuracy: 0.8793\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8914 - val_loss: 0.3330 - val_accuracy: 0.8700\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8771 - val_loss: 0.3308 - val_accuracy: 0.8824\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8788 - val_loss: 0.3280 - val_accuracy: 0.8793\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.9087 - val_loss: 0.3285 - val_accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8753 - val_loss: 0.3234 - val_accuracy: 0.8854\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.9066 - val_loss: 0.3208 - val_accuracy: 0.8854\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8924 - val_loss: 0.3187 - val_accuracy: 0.8854\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8725 - val_loss: 0.3169 - val_accuracy: 0.8824\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.8836 - val_loss: 0.3146 - val_accuracy: 0.8824\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2805 - accuracy: 0.8874 - val_loss: 0.3124 - val_accuracy: 0.8854\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8879 - val_loss: 0.3107 - val_accuracy: 0.8885\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8885 - val_loss: 0.3097 - val_accuracy: 0.8885\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8887 - val_loss: 0.3076 - val_accuracy: 0.8916\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8905 - val_loss: 0.3057 - val_accuracy: 0.8947\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.9020 - val_loss: 0.3031 - val_accuracy: 0.8916\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8691 - val_loss: 0.3017 - val_accuracy: 0.8854\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.9070 - val_loss: 0.2997 - val_accuracy: 0.8978\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8755 - val_loss: 0.2984 - val_accuracy: 0.8947\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8833 - val_loss: 0.2966 - val_accuracy: 0.8978\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.8911 - val_loss: 0.2951 - val_accuracy: 0.8947\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8714 - val_loss: 0.2937 - val_accuracy: 0.8916\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.9014 - val_loss: 0.2925 - val_accuracy: 0.8978\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.8812 - val_loss: 0.2917 - val_accuracy: 0.8947\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8625 - val_loss: 0.2899 - val_accuracy: 0.8978\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8815 - val_loss: 0.2885 - val_accuracy: 0.8947\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8874 - val_loss: 0.2871 - val_accuracy: 0.8978\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8998 - val_loss: 0.2861 - val_accuracy: 0.8947\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8934 - val_loss: 0.2857 - val_accuracy: 0.9009\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.9086 - val_loss: 0.2847 - val_accuracy: 0.9009\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8665 - val_loss: 0.2828 - val_accuracy: 0.8947\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8890 - val_loss: 0.2821 - val_accuracy: 0.8978\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9077 - val_loss: 0.2805 - val_accuracy: 0.8947\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8705 - val_loss: 0.2792 - val_accuracy: 0.8978\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8944 - val_loss: 0.2784 - val_accuracy: 0.8978\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8825 - val_loss: 0.2769 - val_accuracy: 0.8978\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8747 - val_loss: 0.2762 - val_accuracy: 0.9009\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.9089 - val_loss: 0.2749 - val_accuracy: 0.8978\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9058 - val_loss: 0.2738 - val_accuracy: 0.9009\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9162 - val_loss: 0.2729 - val_accuracy: 0.8978\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8752 - val_loss: 0.2760 - val_accuracy: 0.8916\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8924 - val_loss: 0.2726 - val_accuracy: 0.8947\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8880 - val_loss: 0.2711 - val_accuracy: 0.9009\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.9012 - val_loss: 0.2703 - val_accuracy: 0.9009\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8690 - val_loss: 0.2709 - val_accuracy: 0.8947\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8825 - val_loss: 0.2686 - val_accuracy: 0.9040\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.9024 - val_loss: 0.2677 - val_accuracy: 0.9071\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.9045 - val_loss: 0.2671 - val_accuracy: 0.9040\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.9063 - val_loss: 0.2663 - val_accuracy: 0.9040\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.8960 - val_loss: 0.2660 - val_accuracy: 0.9071\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2764 - accuracy: 0.9028 - val_loss: 0.2653 - val_accuracy: 0.9040\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8968 - val_loss: 0.2647 - val_accuracy: 0.9071\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.9100 - val_loss: 0.2657 - val_accuracy: 0.8978\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9166 - val_loss: 0.2638 - val_accuracy: 0.9071\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8876 - val_loss: 0.2630 - val_accuracy: 0.9040\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2353 - accuracy: 0.9287 - val_loss: 0.2626 - val_accuracy: 0.9040\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9106 - val_loss: 0.2617 - val_accuracy: 0.9040\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8904 - val_loss: 0.2612 - val_accuracy: 0.9040\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.9161 - val_loss: 0.2609 - val_accuracy: 0.9102\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.9002 - val_loss: 0.2602 - val_accuracy: 0.9040\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.8859 - val_loss: 0.2597 - val_accuracy: 0.9040\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9194 - val_loss: 0.2604 - val_accuracy: 0.9040\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8951 - val_loss: 0.2587 - val_accuracy: 0.9040\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.9048 - val_loss: 0.2583 - val_accuracy: 0.9040\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8960 - val_loss: 0.2579 - val_accuracy: 0.9040\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9085 - val_loss: 0.2586 - val_accuracy: 0.9071\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.9033 - val_loss: 0.2577 - val_accuracy: 0.9040\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8794 - val_loss: 0.2566 - val_accuracy: 0.9071\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.9003 - val_loss: 0.2565 - val_accuracy: 0.9102\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9122 - val_loss: 0.2556 - val_accuracy: 0.9040\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2642 - accuracy: 0.9019 - val_loss: 0.2551 - val_accuracy: 0.9040\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "3\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 16s - loss: 0.7120 - accuracy: 0.4000WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 1s 18ms/step - loss: 0.6955 - accuracy: 0.4695 - val_loss: 0.6765 - val_accuracy: 0.8080\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.8215 - val_loss: 0.6584 - val_accuracy: 0.8235\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.8320 - val_loss: 0.6374 - val_accuracy: 0.8328\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.8397 - val_loss: 0.6128 - val_accuracy: 0.8390\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.8681 - val_loss: 0.5815 - val_accuracy: 0.8452\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.8391 - val_loss: 0.5455 - val_accuracy: 0.8452\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8698 - val_loss: 0.5029 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8687 - val_loss: 0.4575 - val_accuracy: 0.8483\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8345 - val_loss: 0.4179 - val_accuracy: 0.8452\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8232 - val_loss: 0.3857 - val_accuracy: 0.8452\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8350 - val_loss: 0.3642 - val_accuracy: 0.8452\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8379 - val_loss: 0.3514 - val_accuracy: 0.8421\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8478 - val_loss: 0.3430 - val_accuracy: 0.8452\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8281 - val_loss: 0.3383 - val_accuracy: 0.8483\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8682 - val_loss: 0.3352 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8811 - val_loss: 0.3310 - val_accuracy: 0.8669\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8501 - val_loss: 0.3287 - val_accuracy: 0.8638\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8696 - val_loss: 0.3267 - val_accuracy: 0.8669\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8485 - val_loss: 0.3246 - val_accuracy: 0.8638\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8464 - val_loss: 0.3226 - val_accuracy: 0.8576\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8217 - val_loss: 0.3216 - val_accuracy: 0.8576\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8391 - val_loss: 0.3201 - val_accuracy: 0.8638\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8646 - val_loss: 0.3200 - val_accuracy: 0.8669\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8740 - val_loss: 0.3181 - val_accuracy: 0.8638\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8711 - val_loss: 0.3163 - val_accuracy: 0.8638\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8608 - val_loss: 0.3152 - val_accuracy: 0.8669\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8595 - val_loss: 0.3144 - val_accuracy: 0.8669\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8942 - val_loss: 0.3138 - val_accuracy: 0.8731\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8901 - val_loss: 0.3138 - val_accuracy: 0.8700\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8704 - val_loss: 0.3119 - val_accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8736 - val_loss: 0.3107 - val_accuracy: 0.8669\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8854 - val_loss: 0.3099 - val_accuracy: 0.8731\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8513 - val_loss: 0.3089 - val_accuracy: 0.8669\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8676 - val_loss: 0.3077 - val_accuracy: 0.8731\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8781 - val_loss: 0.3088 - val_accuracy: 0.8700\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8596 - val_loss: 0.3065 - val_accuracy: 0.8731\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8323 - val_loss: 0.3057 - val_accuracy: 0.8731\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8591 - val_loss: 0.3050 - val_accuracy: 0.8700\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8809 - val_loss: 0.3045 - val_accuracy: 0.8700\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8571 - val_loss: 0.3035 - val_accuracy: 0.8731\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8533 - val_loss: 0.3028 - val_accuracy: 0.8731\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8523 - val_loss: 0.3024 - val_accuracy: 0.8731\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8691 - val_loss: 0.3023 - val_accuracy: 0.8762\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8651 - val_loss: 0.3019 - val_accuracy: 0.8731\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8912 - val_loss: 0.3010 - val_accuracy: 0.8731\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8593 - val_loss: 0.3011 - val_accuracy: 0.8700\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8475 - val_loss: 0.3015 - val_accuracy: 0.8731\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8676 - val_loss: 0.2991 - val_accuracy: 0.8731\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8614 - val_loss: 0.2982 - val_accuracy: 0.8731\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.9050 - val_loss: 0.2976 - val_accuracy: 0.8793\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8527 - val_loss: 0.2978 - val_accuracy: 0.8700\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8970 - val_loss: 0.2966 - val_accuracy: 0.8762\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8588 - val_loss: 0.2957 - val_accuracy: 0.8762\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8882 - val_loss: 0.2952 - val_accuracy: 0.8762\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.8912 - val_loss: 0.2948 - val_accuracy: 0.8762\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8514 - val_loss: 0.2942 - val_accuracy: 0.8793\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8985 - val_loss: 0.2955 - val_accuracy: 0.8731\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.9006 - val_loss: 0.2938 - val_accuracy: 0.8731\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8593 - val_loss: 0.2929 - val_accuracy: 0.8762\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8859 - val_loss: 0.2922 - val_accuracy: 0.8793\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8666 - val_loss: 0.2917 - val_accuracy: 0.8793\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.9051 - val_loss: 0.2913 - val_accuracy: 0.8793\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8741 - val_loss: 0.2917 - val_accuracy: 0.8793\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.8732 - val_loss: 0.2903 - val_accuracy: 0.8793\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.9056 - val_loss: 0.2900 - val_accuracy: 0.8762\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8834 - val_loss: 0.2893 - val_accuracy: 0.8793\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8881 - val_loss: 0.2889 - val_accuracy: 0.8824\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8778 - val_loss: 0.2882 - val_accuracy: 0.8854\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.9093 - val_loss: 0.2879 - val_accuracy: 0.8854\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8737 - val_loss: 0.2872 - val_accuracy: 0.8824\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8774 - val_loss: 0.2870 - val_accuracy: 0.8793\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8987 - val_loss: 0.2872 - val_accuracy: 0.8824\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.8795 - val_loss: 0.2860 - val_accuracy: 0.8824\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8761 - val_loss: 0.2856 - val_accuracy: 0.8793\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8890 - val_loss: 0.2854 - val_accuracy: 0.8824\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.8710 - val_loss: 0.2846 - val_accuracy: 0.8793\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.8863 - val_loss: 0.2847 - val_accuracy: 0.8793\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8865 - val_loss: 0.2834 - val_accuracy: 0.8824\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8384 - val_loss: 0.2831 - val_accuracy: 0.8854\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8981 - val_loss: 0.2828 - val_accuracy: 0.8916\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8920 - val_loss: 0.2837 - val_accuracy: 0.8916\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8594 - val_loss: 0.2822 - val_accuracy: 0.8947\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8627 - val_loss: 0.2818 - val_accuracy: 0.8916\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9126 - val_loss: 0.2809 - val_accuracy: 0.8854\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.9130 - val_loss: 0.2804 - val_accuracy: 0.8824\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8880 - val_loss: 0.2803 - val_accuracy: 0.8916\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8761 - val_loss: 0.2802 - val_accuracy: 0.8824\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.9014 - val_loss: 0.2797 - val_accuracy: 0.8885\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.9089 - val_loss: 0.2792 - val_accuracy: 0.8885\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.8981 - val_loss: 0.2784 - val_accuracy: 0.8854\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8587 - val_loss: 0.2780 - val_accuracy: 0.8854\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9166 - val_loss: 0.2776 - val_accuracy: 0.8854\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.9067 - val_loss: 0.2772 - val_accuracy: 0.8885\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8902 - val_loss: 0.2767 - val_accuracy: 0.8854\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.8779 - val_loss: 0.2762 - val_accuracy: 0.8885\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8809 - val_loss: 0.2767 - val_accuracy: 0.8854\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8965 - val_loss: 0.2760 - val_accuracy: 0.8885\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8973 - val_loss: 0.2751 - val_accuracy: 0.8854\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8911 - val_loss: 0.2747 - val_accuracy: 0.8916\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8583 - val_loss: 0.2776 - val_accuracy: 0.8762\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "4\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 15s - loss: 0.6980 - accuracy: 0.5500WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 1s 20ms/step - loss: 0.7067 - accuracy: 0.6760 - val_loss: 0.6862 - val_accuracy: 0.7121\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.7101 - val_loss: 0.6566 - val_accuracy: 0.7121\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7304 - val_loss: 0.6263 - val_accuracy: 0.7121\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.7164 - val_loss: 0.5931 - val_accuracy: 0.7121\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7233 - val_loss: 0.5557 - val_accuracy: 0.7276\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7495 - val_loss: 0.5147 - val_accuracy: 0.7678\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7533 - val_loss: 0.4725 - val_accuracy: 0.8080\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7927 - val_loss: 0.4373 - val_accuracy: 0.8452\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.8379 - val_loss: 0.4086 - val_accuracy: 0.8483\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8774 - val_loss: 0.3875 - val_accuracy: 0.8514\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8618 - val_loss: 0.3750 - val_accuracy: 0.8669\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8849 - val_loss: 0.3681 - val_accuracy: 0.8638\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8662 - val_loss: 0.3641 - val_accuracy: 0.8638\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8786 - val_loss: 0.3611 - val_accuracy: 0.8669\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8643 - val_loss: 0.3590 - val_accuracy: 0.8669\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8638 - val_loss: 0.3572 - val_accuracy: 0.8669\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8703 - val_loss: 0.3548 - val_accuracy: 0.8607\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8681 - val_loss: 0.3531 - val_accuracy: 0.8607\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8368 - val_loss: 0.3526 - val_accuracy: 0.8638\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8441 - val_loss: 0.3496 - val_accuracy: 0.8607\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8371 - val_loss: 0.3479 - val_accuracy: 0.8576\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8650 - val_loss: 0.3474 - val_accuracy: 0.8607\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8544 - val_loss: 0.3454 - val_accuracy: 0.8607\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8628 - val_loss: 0.3437 - val_accuracy: 0.8607\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8293 - val_loss: 0.3424 - val_accuracy: 0.8638\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8651 - val_loss: 0.3407 - val_accuracy: 0.8638\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8463 - val_loss: 0.3395 - val_accuracy: 0.8638\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8842 - val_loss: 0.3382 - val_accuracy: 0.8638\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8678 - val_loss: 0.3365 - val_accuracy: 0.8669\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8884 - val_loss: 0.3354 - val_accuracy: 0.8669\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8775 - val_loss: 0.3336 - val_accuracy: 0.8669\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8741 - val_loss: 0.3320 - val_accuracy: 0.8669\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8646 - val_loss: 0.3305 - val_accuracy: 0.8700\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8823 - val_loss: 0.3289 - val_accuracy: 0.8669\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8648 - val_loss: 0.3272 - val_accuracy: 0.8700\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8808 - val_loss: 0.3255 - val_accuracy: 0.8700\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8385 - val_loss: 0.3263 - val_accuracy: 0.8793\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8819 - val_loss: 0.3231 - val_accuracy: 0.8793\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8645 - val_loss: 0.3209 - val_accuracy: 0.8854\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8837 - val_loss: 0.3199 - val_accuracy: 0.8762\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.8961 - val_loss: 0.3188 - val_accuracy: 0.8793\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.9043 - val_loss: 0.3173 - val_accuracy: 0.8854\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8906 - val_loss: 0.3160 - val_accuracy: 0.8854\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8989 - val_loss: 0.3147 - val_accuracy: 0.8854\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8773 - val_loss: 0.3140 - val_accuracy: 0.8793\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8822 - val_loss: 0.3129 - val_accuracy: 0.8885\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8881 - val_loss: 0.3122 - val_accuracy: 0.8854\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8841 - val_loss: 0.3113 - val_accuracy: 0.8885\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8834 - val_loss: 0.3088 - val_accuracy: 0.8885\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8740 - val_loss: 0.3076 - val_accuracy: 0.8854\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.9184 - val_loss: 0.3062 - val_accuracy: 0.8885\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8853 - val_loss: 0.3049 - val_accuracy: 0.8885\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8685 - val_loss: 0.3036 - val_accuracy: 0.8885\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8937 - val_loss: 0.3026 - val_accuracy: 0.8885\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8607 - val_loss: 0.3021 - val_accuracy: 0.8885\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8804 - val_loss: 0.3004 - val_accuracy: 0.8854\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8569 - val_loss: 0.2998 - val_accuracy: 0.8854\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8832 - val_loss: 0.2985 - val_accuracy: 0.8824\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.9100 - val_loss: 0.2981 - val_accuracy: 0.8854\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8786 - val_loss: 0.2958 - val_accuracy: 0.8916\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8986 - val_loss: 0.2943 - val_accuracy: 0.8947\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.8880 - val_loss: 0.2934 - val_accuracy: 0.8854\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.9098 - val_loss: 0.2923 - val_accuracy: 0.8916\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8806 - val_loss: 0.2929 - val_accuracy: 0.8885\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8330 - val_loss: 0.2910 - val_accuracy: 0.8916\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8892 - val_loss: 0.2898 - val_accuracy: 0.8885\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.8937 - val_loss: 0.2883 - val_accuracy: 0.8947\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9045 - val_loss: 0.2879 - val_accuracy: 0.8916\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8793 - val_loss: 0.2863 - val_accuracy: 0.8916\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8931 - val_loss: 0.2855 - val_accuracy: 0.8885\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8962 - val_loss: 0.2843 - val_accuracy: 0.8978\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8923 - val_loss: 0.2836 - val_accuracy: 0.8885\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.9176 - val_loss: 0.2815 - val_accuracy: 0.8947\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8994 - val_loss: 0.2815 - val_accuracy: 0.8916\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8885 - val_loss: 0.2803 - val_accuracy: 0.8916\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8772 - val_loss: 0.2787 - val_accuracy: 0.8916\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8784 - val_loss: 0.2775 - val_accuracy: 0.8947\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8754 - val_loss: 0.2767 - val_accuracy: 0.8947\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8955 - val_loss: 0.2757 - val_accuracy: 0.8916\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8732 - val_loss: 0.2769 - val_accuracy: 0.8978\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.9026 - val_loss: 0.2740 - val_accuracy: 0.8916\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.9053 - val_loss: 0.2729 - val_accuracy: 0.8947\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8851 - val_loss: 0.2748 - val_accuracy: 0.8947\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8641 - val_loss: 0.2722 - val_accuracy: 0.8916\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8963 - val_loss: 0.2702 - val_accuracy: 0.8916\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8870 - val_loss: 0.2695 - val_accuracy: 0.8947\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8820 - val_loss: 0.2692 - val_accuracy: 0.8916\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8936 - val_loss: 0.2680 - val_accuracy: 0.8947\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9066 - val_loss: 0.2688 - val_accuracy: 0.8916\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8735 - val_loss: 0.2683 - val_accuracy: 0.8885\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.8889 - val_loss: 0.2660 - val_accuracy: 0.8916\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9129 - val_loss: 0.2650 - val_accuracy: 0.8947\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9102 - val_loss: 0.2648 - val_accuracy: 0.8885\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8827 - val_loss: 0.2636 - val_accuracy: 0.8947\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.9149 - val_loss: 0.2633 - val_accuracy: 0.8978\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.9065 - val_loss: 0.2622 - val_accuracy: 0.8947\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2231 - accuracy: 0.9043 - val_loss: 0.2621 - val_accuracy: 0.8916\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8793 - val_loss: 0.2608 - val_accuracy: 0.8978\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.8845 - val_loss: 0.2603 - val_accuracy: 0.8947\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.8938 - val_loss: 0.2596 - val_accuracy: 0.9009\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "5\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 18s - loss: 0.6835 - accuracy: 0.7000WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 1s 21ms/step - loss: 0.6764 - accuracy: 0.7092 - val_loss: 0.6317 - val_accuracy: 0.7028\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.7002 - val_loss: 0.5756 - val_accuracy: 0.7090\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7097 - val_loss: 0.5290 - val_accuracy: 0.7121\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7264 - val_loss: 0.4944 - val_accuracy: 0.7121\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7005 - val_loss: 0.4690 - val_accuracy: 0.7121\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.6971 - val_loss: 0.4504 - val_accuracy: 0.7121\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7096 - val_loss: 0.4391 - val_accuracy: 0.7121\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7151 - val_loss: 0.4239 - val_accuracy: 0.7183\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7286 - val_loss: 0.4112 - val_accuracy: 0.7492\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7762 - val_loss: 0.3998 - val_accuracy: 0.8359\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8278 - val_loss: 0.3910 - val_accuracy: 0.8514\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8275 - val_loss: 0.3833 - val_accuracy: 0.8545\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8481 - val_loss: 0.3757 - val_accuracy: 0.8545\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8763 - val_loss: 0.3697 - val_accuracy: 0.8700\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8595 - val_loss: 0.3628 - val_accuracy: 0.8731\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8726 - val_loss: 0.3565 - val_accuracy: 0.8700\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8680 - val_loss: 0.3508 - val_accuracy: 0.8731\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8585 - val_loss: 0.3456 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8647 - val_loss: 0.3414 - val_accuracy: 0.8700\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.8922 - val_loss: 0.3364 - val_accuracy: 0.8731\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8857 - val_loss: 0.3340 - val_accuracy: 0.8700\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8761 - val_loss: 0.3310 - val_accuracy: 0.8762\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8745 - val_loss: 0.3268 - val_accuracy: 0.8731\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8832 - val_loss: 0.3240 - val_accuracy: 0.8731\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8857 - val_loss: 0.3204 - val_accuracy: 0.8793\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8693 - val_loss: 0.3177 - val_accuracy: 0.8824\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.9012 - val_loss: 0.3144 - val_accuracy: 0.8854\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.9036 - val_loss: 0.3115 - val_accuracy: 0.8854\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9194 - val_loss: 0.3091 - val_accuracy: 0.8885\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8789 - val_loss: 0.3068 - val_accuracy: 0.8947\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8902 - val_loss: 0.3048 - val_accuracy: 0.8885\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8895 - val_loss: 0.3025 - val_accuracy: 0.8947\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8747 - val_loss: 0.3008 - val_accuracy: 0.8947\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.8971 - val_loss: 0.2983 - val_accuracy: 0.8947\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.9045 - val_loss: 0.2962 - val_accuracy: 0.8978\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8882 - val_loss: 0.2942 - val_accuracy: 0.8947\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.9016 - val_loss: 0.2934 - val_accuracy: 0.8978\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.9077 - val_loss: 0.2914 - val_accuracy: 0.8947\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8999 - val_loss: 0.2899 - val_accuracy: 0.8947\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8992 - val_loss: 0.2896 - val_accuracy: 0.8978\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8763 - val_loss: 0.2871 - val_accuracy: 0.8947\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.9043 - val_loss: 0.2853 - val_accuracy: 0.8947\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.9076 - val_loss: 0.2843 - val_accuracy: 0.8947\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.9118 - val_loss: 0.2837 - val_accuracy: 0.8947\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.8803 - val_loss: 0.2822 - val_accuracy: 0.8978\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.9013 - val_loss: 0.2808 - val_accuracy: 0.8978\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9205 - val_loss: 0.2796 - val_accuracy: 0.8978\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.9231 - val_loss: 0.2784 - val_accuracy: 0.8978\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.9047 - val_loss: 0.2773 - val_accuracy: 0.9009\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.9169 - val_loss: 0.2762 - val_accuracy: 0.9009\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8952 - val_loss: 0.2750 - val_accuracy: 0.9009\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.9121 - val_loss: 0.2741 - val_accuracy: 0.9009\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.9037 - val_loss: 0.2738 - val_accuracy: 0.9009\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.9023 - val_loss: 0.2726 - val_accuracy: 0.9071\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9288 - val_loss: 0.2709 - val_accuracy: 0.9009\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9147 - val_loss: 0.2694 - val_accuracy: 0.9040\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.9035 - val_loss: 0.2676 - val_accuracy: 0.9071\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8958 - val_loss: 0.2662 - val_accuracy: 0.9071\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2605 - accuracy: 0.9183 - val_loss: 0.2653 - val_accuracy: 0.9071\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9217 - val_loss: 0.2652 - val_accuracy: 0.9102\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8932 - val_loss: 0.2634 - val_accuracy: 0.9071\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.9034 - val_loss: 0.2625 - val_accuracy: 0.9102\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9259 - val_loss: 0.2612 - val_accuracy: 0.9102\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.9055 - val_loss: 0.2604 - val_accuracy: 0.9102\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9171 - val_loss: 0.2594 - val_accuracy: 0.9071\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9174 - val_loss: 0.2586 - val_accuracy: 0.9071\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.9061 - val_loss: 0.2585 - val_accuracy: 0.9102\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9041 - val_loss: 0.2573 - val_accuracy: 0.9071\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9226 - val_loss: 0.2567 - val_accuracy: 0.9071\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.9039 - val_loss: 0.2561 - val_accuracy: 0.9071\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.9046 - val_loss: 0.2554 - val_accuracy: 0.9071\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.9096 - val_loss: 0.2549 - val_accuracy: 0.9071\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9112 - val_loss: 0.2540 - val_accuracy: 0.9071\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9045 - val_loss: 0.2534 - val_accuracy: 0.9071\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 0.9077 - val_loss: 0.2527 - val_accuracy: 0.9071\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9031 - val_loss: 0.2525 - val_accuracy: 0.9071\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.9102 - val_loss: 0.2516 - val_accuracy: 0.9071\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9116 - val_loss: 0.2510 - val_accuracy: 0.9071\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8947 - val_loss: 0.2505 - val_accuracy: 0.9071\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9162 - val_loss: 0.2501 - val_accuracy: 0.9071\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9158 - val_loss: 0.2497 - val_accuracy: 0.9040\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.9076 - val_loss: 0.2492 - val_accuracy: 0.9071\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8907 - val_loss: 0.2485 - val_accuracy: 0.9071\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9156 - val_loss: 0.2484 - val_accuracy: 0.9040\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.8893 - val_loss: 0.2486 - val_accuracy: 0.9102\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9091 - val_loss: 0.2477 - val_accuracy: 0.9040\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.9101 - val_loss: 0.2469 - val_accuracy: 0.9071\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9081 - val_loss: 0.2463 - val_accuracy: 0.9040\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9129 - val_loss: 0.2463 - val_accuracy: 0.9040\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.9077 - val_loss: 0.2458 - val_accuracy: 0.9040\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9208 - val_loss: 0.2497 - val_accuracy: 0.9102\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8938 - val_loss: 0.2475 - val_accuracy: 0.9040\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.9005 - val_loss: 0.2453 - val_accuracy: 0.9040\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.9035 - val_loss: 0.2448 - val_accuracy: 0.9071\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8969 - val_loss: 0.2444 - val_accuracy: 0.9071\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9040 - val_loss: 0.2443 - val_accuracy: 0.9071\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9138 - val_loss: 0.2438 - val_accuracy: 0.9040\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.8903 - val_loss: 0.2436 - val_accuracy: 0.9071\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9285 - val_loss: 0.2430 - val_accuracy: 0.9071\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8911 - val_loss: 0.2427 - val_accuracy: 0.9040\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_20_input'), name='dense_20_input', description=\"created by layer 'dense_20_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "6\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 16s - loss: 0.7468 - accuracy: 0.2500WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 1s 19ms/step - loss: 0.7138 - accuracy: 0.3523 - val_loss: 0.6753 - val_accuracy: 0.6811\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.7152 - val_loss: 0.6358 - val_accuracy: 0.7833\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.7851 - val_loss: 0.5972 - val_accuracy: 0.7957\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.8163 - val_loss: 0.5572 - val_accuracy: 0.7864\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7921 - val_loss: 0.5172 - val_accuracy: 0.7802\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7727 - val_loss: 0.4718 - val_accuracy: 0.7864\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7703 - val_loss: 0.4361 - val_accuracy: 0.8080\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8191 - val_loss: 0.4123 - val_accuracy: 0.8111\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8392 - val_loss: 0.3989 - val_accuracy: 0.8235\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8312 - val_loss: 0.3884 - val_accuracy: 0.8421\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8419 - val_loss: 0.3832 - val_accuracy: 0.8483\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8627 - val_loss: 0.3790 - val_accuracy: 0.8452\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8676 - val_loss: 0.3763 - val_accuracy: 0.8452\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8646 - val_loss: 0.3743 - val_accuracy: 0.8483\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8491 - val_loss: 0.3726 - val_accuracy: 0.8483\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8394 - val_loss: 0.3712 - val_accuracy: 0.8514\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8715 - val_loss: 0.3703 - val_accuracy: 0.8514\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8635 - val_loss: 0.3687 - val_accuracy: 0.8514\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8490 - val_loss: 0.3673 - val_accuracy: 0.8545\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8432 - val_loss: 0.3663 - val_accuracy: 0.8514\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8416 - val_loss: 0.3652 - val_accuracy: 0.8514\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8659 - val_loss: 0.3644 - val_accuracy: 0.8514\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8678 - val_loss: 0.3635 - val_accuracy: 0.8545\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8643 - val_loss: 0.3623 - val_accuracy: 0.8545\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8526 - val_loss: 0.3612 - val_accuracy: 0.8545\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8552 - val_loss: 0.3602 - val_accuracy: 0.8576\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8647 - val_loss: 0.3591 - val_accuracy: 0.8514\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8568 - val_loss: 0.3581 - val_accuracy: 0.8514\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8494 - val_loss: 0.3569 - val_accuracy: 0.8514\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8604 - val_loss: 0.3559 - val_accuracy: 0.8514\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8548 - val_loss: 0.3552 - val_accuracy: 0.8514\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8464 - val_loss: 0.3539 - val_accuracy: 0.8514\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8448 - val_loss: 0.3528 - val_accuracy: 0.8514\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8595 - val_loss: 0.3519 - val_accuracy: 0.8514\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8452 - val_loss: 0.3506 - val_accuracy: 0.8545\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8549 - val_loss: 0.3495 - val_accuracy: 0.8545\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8717 - val_loss: 0.3483 - val_accuracy: 0.8545\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8505 - val_loss: 0.3474 - val_accuracy: 0.8545\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8423 - val_loss: 0.3464 - val_accuracy: 0.8576\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8667 - val_loss: 0.3450 - val_accuracy: 0.8545\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8637 - val_loss: 0.3438 - val_accuracy: 0.8576\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8718 - val_loss: 0.3425 - val_accuracy: 0.8576\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8749 - val_loss: 0.3403 - val_accuracy: 0.8576\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8395 - val_loss: 0.3375 - val_accuracy: 0.8576\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8563 - val_loss: 0.3354 - val_accuracy: 0.8576\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8378 - val_loss: 0.3337 - val_accuracy: 0.8576\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8358 - val_loss: 0.3324 - val_accuracy: 0.8607\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8383 - val_loss: 0.3309 - val_accuracy: 0.8576\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8566 - val_loss: 0.3297 - val_accuracy: 0.8576\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8855 - val_loss: 0.3285 - val_accuracy: 0.8700\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8547 - val_loss: 0.3275 - val_accuracy: 0.8700\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8771 - val_loss: 0.3266 - val_accuracy: 0.8669\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8713 - val_loss: 0.3246 - val_accuracy: 0.8700\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8664 - val_loss: 0.3233 - val_accuracy: 0.8762\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8682 - val_loss: 0.3227 - val_accuracy: 0.8700\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2685 - accuracy: 0.8853 - val_loss: 0.3210 - val_accuracy: 0.8762\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8693 - val_loss: 0.3201 - val_accuracy: 0.8731\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8884 - val_loss: 0.3188 - val_accuracy: 0.8762\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8629 - val_loss: 0.3179 - val_accuracy: 0.8731\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.8628 - val_loss: 0.3172 - val_accuracy: 0.8731\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2872 - accuracy: 0.8846 - val_loss: 0.3163 - val_accuracy: 0.8731\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8814 - val_loss: 0.3151 - val_accuracy: 0.8731\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8361 - val_loss: 0.3141 - val_accuracy: 0.8700\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3068 - accuracy: 0.8663 - val_loss: 0.3132 - val_accuracy: 0.8669\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8772 - val_loss: 0.3119 - val_accuracy: 0.8669\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8771 - val_loss: 0.3111 - val_accuracy: 0.8731\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8874 - val_loss: 0.3101 - val_accuracy: 0.8669\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8781 - val_loss: 0.3097 - val_accuracy: 0.8638\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2952 - accuracy: 0.8705 - val_loss: 0.3083 - val_accuracy: 0.8638\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8640 - val_loss: 0.3073 - val_accuracy: 0.8669\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8652 - val_loss: 0.3062 - val_accuracy: 0.8638\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8504 - val_loss: 0.3059 - val_accuracy: 0.8669\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8626 - val_loss: 0.3042 - val_accuracy: 0.8607\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8736 - val_loss: 0.3031 - val_accuracy: 0.8638\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8547 - val_loss: 0.3018 - val_accuracy: 0.8638\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.8562 - val_loss: 0.3011 - val_accuracy: 0.8607\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8494 - val_loss: 0.2997 - val_accuracy: 0.8638\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8360 - val_loss: 0.2989 - val_accuracy: 0.8638\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8670 - val_loss: 0.2976 - val_accuracy: 0.8638\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8857 - val_loss: 0.2962 - val_accuracy: 0.8638\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.8718 - val_loss: 0.2948 - val_accuracy: 0.8638\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8557 - val_loss: 0.2935 - val_accuracy: 0.8638\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8655 - val_loss: 0.2916 - val_accuracy: 0.8638\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8635 - val_loss: 0.2902 - val_accuracy: 0.8669\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8541 - val_loss: 0.2889 - val_accuracy: 0.8669\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8770 - val_loss: 0.2875 - val_accuracy: 0.8669\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.8814 - val_loss: 0.2861 - val_accuracy: 0.8669\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8887 - val_loss: 0.2853 - val_accuracy: 0.8762\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8869 - val_loss: 0.2833 - val_accuracy: 0.8700\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8799 - val_loss: 0.2815 - val_accuracy: 0.8700\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.8991 - val_loss: 0.2803 - val_accuracy: 0.8700\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8772 - val_loss: 0.2784 - val_accuracy: 0.8700\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.8720 - val_loss: 0.2773 - val_accuracy: 0.8731\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.8830 - val_loss: 0.2764 - val_accuracy: 0.8793\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2785 - accuracy: 0.8745 - val_loss: 0.2745 - val_accuracy: 0.8731\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8965 - val_loss: 0.2730 - val_accuracy: 0.8793\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.8837 - val_loss: 0.2723 - val_accuracy: 0.8824\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8768 - val_loss: 0.2705 - val_accuracy: 0.8824\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.8748 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8829 - val_loss: 0.2685 - val_accuracy: 0.8885\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 15s - loss: 0.6895 - accuracy: 0.7000WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 1s 19ms/step - loss: 0.6422 - accuracy: 0.7084 - val_loss: 0.5907 - val_accuracy: 0.7121\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6888 - val_loss: 0.5470 - val_accuracy: 0.7121\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7068 - val_loss: 0.5081 - val_accuracy: 0.7121\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7366 - val_loss: 0.4783 - val_accuracy: 0.7121\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7214 - val_loss: 0.4575 - val_accuracy: 0.7121\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.6760 - val_loss: 0.4392 - val_accuracy: 0.7121\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7044 - val_loss: 0.4246 - val_accuracy: 0.7121\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.6926 - val_loss: 0.4132 - val_accuracy: 0.7121\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.6859 - val_loss: 0.4051 - val_accuracy: 0.7121\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7088 - val_loss: 0.3976 - val_accuracy: 0.7121\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.7329 - val_loss: 0.3923 - val_accuracy: 0.7214\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.7193 - val_loss: 0.3878 - val_accuracy: 0.7616\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.7697 - val_loss: 0.3840 - val_accuracy: 0.8173\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8208 - val_loss: 0.3808 - val_accuracy: 0.8297\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8246 - val_loss: 0.3782 - val_accuracy: 0.8328\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8484 - val_loss: 0.3756 - val_accuracy: 0.8359\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8105 - val_loss: 0.3734 - val_accuracy: 0.8452\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8826 - val_loss: 0.3716 - val_accuracy: 0.8545\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8520 - val_loss: 0.3698 - val_accuracy: 0.8638\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8800 - val_loss: 0.3683 - val_accuracy: 0.8607\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8483 - val_loss: 0.3669 - val_accuracy: 0.8607\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8687 - val_loss: 0.3653 - val_accuracy: 0.8638\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8450 - val_loss: 0.3639 - val_accuracy: 0.8607\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8863 - val_loss: 0.3621 - val_accuracy: 0.8638\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8653 - val_loss: 0.3598 - val_accuracy: 0.8731\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8640 - val_loss: 0.3578 - val_accuracy: 0.8824\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8875 - val_loss: 0.3555 - val_accuracy: 0.8793\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.9051 - val_loss: 0.3532 - val_accuracy: 0.8854\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.9080 - val_loss: 0.3509 - val_accuracy: 0.8885\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8788 - val_loss: 0.3482 - val_accuracy: 0.8854\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8945 - val_loss: 0.3459 - val_accuracy: 0.8916\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.9099 - val_loss: 0.3436 - val_accuracy: 0.8916\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8848 - val_loss: 0.3407 - val_accuracy: 0.8947\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8943 - val_loss: 0.3384 - val_accuracy: 0.8885\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.9035 - val_loss: 0.3357 - val_accuracy: 0.8854\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8865 - val_loss: 0.3331 - val_accuracy: 0.8885\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.9001 - val_loss: 0.3306 - val_accuracy: 0.8854\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8921 - val_loss: 0.3281 - val_accuracy: 0.8885\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8778 - val_loss: 0.3256 - val_accuracy: 0.8854\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8977 - val_loss: 0.3235 - val_accuracy: 0.8916\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.9003 - val_loss: 0.3212 - val_accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.9076 - val_loss: 0.3190 - val_accuracy: 0.8885\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8737 - val_loss: 0.3167 - val_accuracy: 0.8885\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8580 - val_loss: 0.3145 - val_accuracy: 0.8885\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8854 - val_loss: 0.3121 - val_accuracy: 0.8885\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8909 - val_loss: 0.3101 - val_accuracy: 0.8854\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8867 - val_loss: 0.3106 - val_accuracy: 0.8854\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8848 - val_loss: 0.3071 - val_accuracy: 0.8885\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8902 - val_loss: 0.3037 - val_accuracy: 0.8916\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8902 - val_loss: 0.3020 - val_accuracy: 0.8947\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.8990 - val_loss: 0.2994 - val_accuracy: 0.8916\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8827 - val_loss: 0.2966 - val_accuracy: 0.8947\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8964 - val_loss: 0.2946 - val_accuracy: 0.8916\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.9145 - val_loss: 0.2925 - val_accuracy: 0.8947\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8855 - val_loss: 0.2911 - val_accuracy: 0.8947\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8882 - val_loss: 0.2886 - val_accuracy: 0.8916\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8975 - val_loss: 0.2865 - val_accuracy: 0.8947\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8881 - val_loss: 0.2845 - val_accuracy: 0.8947\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8824 - val_loss: 0.2820 - val_accuracy: 0.8916\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8768 - val_loss: 0.2802 - val_accuracy: 0.8916\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8947 - val_loss: 0.2770 - val_accuracy: 0.8947\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8921 - val_loss: 0.2752 - val_accuracy: 0.8947\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.9008 - val_loss: 0.2744 - val_accuracy: 0.8916\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8778 - val_loss: 0.2701 - val_accuracy: 0.8916\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8930 - val_loss: 0.2680 - val_accuracy: 0.8916\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9077 - val_loss: 0.2657 - val_accuracy: 0.8978\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9123 - val_loss: 0.2633 - val_accuracy: 0.8978\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8974 - val_loss: 0.2612 - val_accuracy: 0.8947\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.8960 - val_loss: 0.2594 - val_accuracy: 0.9009\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.9010 - val_loss: 0.2573 - val_accuracy: 0.8978\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9145 - val_loss: 0.2548 - val_accuracy: 0.8978\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8900 - val_loss: 0.2527 - val_accuracy: 0.8978\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9088 - val_loss: 0.2504 - val_accuracy: 0.9071\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8965 - val_loss: 0.2489 - val_accuracy: 0.8947\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9000 - val_loss: 0.2468 - val_accuracy: 0.9040\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9020 - val_loss: 0.2474 - val_accuracy: 0.9040\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9060 - val_loss: 0.2432 - val_accuracy: 0.9071\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9216 - val_loss: 0.2421 - val_accuracy: 0.9071\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.8886 - val_loss: 0.2397 - val_accuracy: 0.9071\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2202 - accuracy: 0.9158 - val_loss: 0.2381 - val_accuracy: 0.8978\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9123 - val_loss: 0.2393 - val_accuracy: 0.9071\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.8866 - val_loss: 0.2355 - val_accuracy: 0.9071\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9044 - val_loss: 0.2342 - val_accuracy: 0.9040\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8804 - val_loss: 0.2325 - val_accuracy: 0.9040\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9003 - val_loss: 0.2309 - val_accuracy: 0.9040\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9348 - val_loss: 0.2295 - val_accuracy: 0.9040\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.8879 - val_loss: 0.2285 - val_accuracy: 0.9040\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9191 - val_loss: 0.2278 - val_accuracy: 0.9040\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9031 - val_loss: 0.2268 - val_accuracy: 0.9040\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9184 - val_loss: 0.2249 - val_accuracy: 0.9040\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9173 - val_loss: 0.2236 - val_accuracy: 0.9040\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9066 - val_loss: 0.2230 - val_accuracy: 0.9040\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9083 - val_loss: 0.2215 - val_accuracy: 0.9040\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9111 - val_loss: 0.2205 - val_accuracy: 0.9040\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9017 - val_loss: 0.2199 - val_accuracy: 0.9040\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9358 - val_loss: 0.2184 - val_accuracy: 0.9040\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8939 - val_loss: 0.2176 - val_accuracy: 0.9040\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8817 - val_loss: 0.2165 - val_accuracy: 0.9040\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.8956 - val_loss: 0.2155 - val_accuracy: 0.9040\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9124 - val_loss: 0.2146 - val_accuracy: 0.9040\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "8\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 20s - loss: 0.7348 - accuracy: 0.7500WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 2s 18ms/step - loss: 0.7163 - accuracy: 0.7542 - val_loss: 0.6863 - val_accuracy: 0.7121\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.6939 - val_loss: 0.6474 - val_accuracy: 0.7121\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6879 - val_loss: 0.6106 - val_accuracy: 0.7183\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.7124 - val_loss: 0.5683 - val_accuracy: 0.7678\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7799 - val_loss: 0.5221 - val_accuracy: 0.8050\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7946 - val_loss: 0.4808 - val_accuracy: 0.8111\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8029 - val_loss: 0.4463 - val_accuracy: 0.8359\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8390 - val_loss: 0.4217 - val_accuracy: 0.8390\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8416 - val_loss: 0.4052 - val_accuracy: 0.8421\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8145 - val_loss: 0.3962 - val_accuracy: 0.8545\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8573 - val_loss: 0.3867 - val_accuracy: 0.8514\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8545 - val_loss: 0.3797 - val_accuracy: 0.8483\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8217 - val_loss: 0.3735 - val_accuracy: 0.8545\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8586 - val_loss: 0.3681 - val_accuracy: 0.8545\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8571 - val_loss: 0.3632 - val_accuracy: 0.8545\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8323 - val_loss: 0.3593 - val_accuracy: 0.8514\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8752 - val_loss: 0.3564 - val_accuracy: 0.8545\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8514 - val_loss: 0.3531 - val_accuracy: 0.8514\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8143 - val_loss: 0.3494 - val_accuracy: 0.8514\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8261 - val_loss: 0.3462 - val_accuracy: 0.8514\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8503 - val_loss: 0.3428 - val_accuracy: 0.8514\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8576 - val_loss: 0.3400 - val_accuracy: 0.8514\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8531 - val_loss: 0.3357 - val_accuracy: 0.8576\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8636 - val_loss: 0.3340 - val_accuracy: 0.8576\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8810 - val_loss: 0.3297 - val_accuracy: 0.8669\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8602 - val_loss: 0.3293 - val_accuracy: 0.8669\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8616 - val_loss: 0.3245 - val_accuracy: 0.8731\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8833 - val_loss: 0.3219 - val_accuracy: 0.8731\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8699 - val_loss: 0.3207 - val_accuracy: 0.8731\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8847 - val_loss: 0.3181 - val_accuracy: 0.8669\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8619 - val_loss: 0.3153 - val_accuracy: 0.8793\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8608 - val_loss: 0.3133 - val_accuracy: 0.8793\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8783 - val_loss: 0.3132 - val_accuracy: 0.8762\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8855 - val_loss: 0.3102 - val_accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8897 - val_loss: 0.3089 - val_accuracy: 0.8793\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8671 - val_loss: 0.3070 - val_accuracy: 0.8854\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8680 - val_loss: 0.3053 - val_accuracy: 0.8854\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8995 - val_loss: 0.3040 - val_accuracy: 0.8824\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8817 - val_loss: 0.3043 - val_accuracy: 0.8793\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8849 - val_loss: 0.3015 - val_accuracy: 0.8793\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8584 - val_loss: 0.3002 - val_accuracy: 0.8762\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8535 - val_loss: 0.2988 - val_accuracy: 0.8854\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.8972 - val_loss: 0.2977 - val_accuracy: 0.8824\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8950 - val_loss: 0.2969 - val_accuracy: 0.8885\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2763 - accuracy: 0.8979 - val_loss: 0.2957 - val_accuracy: 0.8824\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.8943 - val_loss: 0.2953 - val_accuracy: 0.8885\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.9118 - val_loss: 0.2975 - val_accuracy: 0.8885\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8945 - val_loss: 0.2935 - val_accuracy: 0.8854\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8921 - val_loss: 0.2929 - val_accuracy: 0.8793\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8673 - val_loss: 0.2921 - val_accuracy: 0.8854\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.8914 - val_loss: 0.2914 - val_accuracy: 0.8824\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8897 - val_loss: 0.2912 - val_accuracy: 0.8793\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8687 - val_loss: 0.2903 - val_accuracy: 0.8854\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8700 - val_loss: 0.2896 - val_accuracy: 0.8793\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8677 - val_loss: 0.2892 - val_accuracy: 0.8854\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8780 - val_loss: 0.2883 - val_accuracy: 0.8824\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.8739 - val_loss: 0.2883 - val_accuracy: 0.8824\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8673 - val_loss: 0.2875 - val_accuracy: 0.8824\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8866 - val_loss: 0.2872 - val_accuracy: 0.8885\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8912 - val_loss: 0.2866 - val_accuracy: 0.8824\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8774 - val_loss: 0.2863 - val_accuracy: 0.8824\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8870 - val_loss: 0.2860 - val_accuracy: 0.8824\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8675 - val_loss: 0.2855 - val_accuracy: 0.8824\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9010 - val_loss: 0.2851 - val_accuracy: 0.8854\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9003 - val_loss: 0.2849 - val_accuracy: 0.8824\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.8675 - val_loss: 0.2848 - val_accuracy: 0.8762\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9079 - val_loss: 0.2850 - val_accuracy: 0.8916\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8857 - val_loss: 0.2840 - val_accuracy: 0.8824\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8468 - val_loss: 0.2839 - val_accuracy: 0.8793\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8996 - val_loss: 0.2838 - val_accuracy: 0.8916\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8880 - val_loss: 0.2833 - val_accuracy: 0.8793\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8864 - val_loss: 0.2830 - val_accuracy: 0.8824\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8821 - val_loss: 0.2829 - val_accuracy: 0.8854\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8890 - val_loss: 0.2830 - val_accuracy: 0.8793\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8892 - val_loss: 0.2825 - val_accuracy: 0.8793\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8595 - val_loss: 0.2822 - val_accuracy: 0.8824\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8738 - val_loss: 0.2823 - val_accuracy: 0.8854\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.8929 - val_loss: 0.2816 - val_accuracy: 0.8854\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8992 - val_loss: 0.2822 - val_accuracy: 0.8824\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8829 - val_loss: 0.2832 - val_accuracy: 0.8916\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.9064 - val_loss: 0.2812 - val_accuracy: 0.8824\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8738 - val_loss: 0.2844 - val_accuracy: 0.8916\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8924 - val_loss: 0.2835 - val_accuracy: 0.8885\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.8953 - val_loss: 0.2807 - val_accuracy: 0.8885\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8706 - val_loss: 0.2803 - val_accuracy: 0.8885\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9097 - val_loss: 0.2802 - val_accuracy: 0.8824\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8725 - val_loss: 0.2805 - val_accuracy: 0.8854\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.9070 - val_loss: 0.2800 - val_accuracy: 0.8916\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8888 - val_loss: 0.2796 - val_accuracy: 0.8916\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8929 - val_loss: 0.2794 - val_accuracy: 0.8885\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9142 - val_loss: 0.2795 - val_accuracy: 0.8885\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8974 - val_loss: 0.2805 - val_accuracy: 0.8885\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8940 - val_loss: 0.2788 - val_accuracy: 0.8854\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.8861 - val_loss: 0.2788 - val_accuracy: 0.8854\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8705 - val_loss: 0.2783 - val_accuracy: 0.8854\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8821 - val_loss: 0.2788 - val_accuracy: 0.8854\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.9055 - val_loss: 0.2780 - val_accuracy: 0.8885\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9118 - val_loss: 0.2781 - val_accuracy: 0.8885\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8746 - val_loss: 0.2777 - val_accuracy: 0.8824\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.8985 - val_loss: 0.2778 - val_accuracy: 0.8854\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_32_input'), name='dense_32_input', description=\"created by layer 'dense_32_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "9\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 323, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 323, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 323, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 323, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 16s - loss: 0.6964 - accuracy: 0.4000WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "17/17 [==============================] - 1s 28ms/step - loss: 0.6801 - accuracy: 0.6522 - val_loss: 0.6645 - val_accuracy: 0.8297\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.8450 - val_loss: 0.6436 - val_accuracy: 0.8235\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.8085 - val_loss: 0.6181 - val_accuracy: 0.8235\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.8048 - val_loss: 0.5829 - val_accuracy: 0.8050\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.8148 - val_loss: 0.5415 - val_accuracy: 0.7957\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.8202 - val_loss: 0.5034 - val_accuracy: 0.8080\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8104 - val_loss: 0.4691 - val_accuracy: 0.8173\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8174 - val_loss: 0.4413 - val_accuracy: 0.8235\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8334 - val_loss: 0.4259 - val_accuracy: 0.8297\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8101 - val_loss: 0.4178 - val_accuracy: 0.8297\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8229 - val_loss: 0.4108 - val_accuracy: 0.8359\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8552 - val_loss: 0.4046 - val_accuracy: 0.8328\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8174 - val_loss: 0.3995 - val_accuracy: 0.8328\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8411 - val_loss: 0.3962 - val_accuracy: 0.8297\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8203 - val_loss: 0.3936 - val_accuracy: 0.8297\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8363 - val_loss: 0.3911 - val_accuracy: 0.8328\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8318 - val_loss: 0.3891 - val_accuracy: 0.8297\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8376 - val_loss: 0.3862 - val_accuracy: 0.8359\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8368 - val_loss: 0.3840 - val_accuracy: 0.8390\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8392 - val_loss: 0.3821 - val_accuracy: 0.8390\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8284 - val_loss: 0.3801 - val_accuracy: 0.8390\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8397 - val_loss: 0.3787 - val_accuracy: 0.8359\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8252 - val_loss: 0.3769 - val_accuracy: 0.8390\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3402 - accuracy: 0.8452 - val_loss: 0.3754 - val_accuracy: 0.8421\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8514 - val_loss: 0.3736 - val_accuracy: 0.8390\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8537 - val_loss: 0.3723 - val_accuracy: 0.8452\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8829 - val_loss: 0.3703 - val_accuracy: 0.8452\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8602 - val_loss: 0.3681 - val_accuracy: 0.8452\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8358 - val_loss: 0.3666 - val_accuracy: 0.8452\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8236 - val_loss: 0.3648 - val_accuracy: 0.8452\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8323 - val_loss: 0.3636 - val_accuracy: 0.8421\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8257 - val_loss: 0.3621 - val_accuracy: 0.8452\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8461 - val_loss: 0.3604 - val_accuracy: 0.8452\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8630 - val_loss: 0.3589 - val_accuracy: 0.8421\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8305 - val_loss: 0.3577 - val_accuracy: 0.8452\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8650 - val_loss: 0.3563 - val_accuracy: 0.8421\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8516 - val_loss: 0.3549 - val_accuracy: 0.8452\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8255 - val_loss: 0.3536 - val_accuracy: 0.8483\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8605 - val_loss: 0.3530 - val_accuracy: 0.8545\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8267 - val_loss: 0.3512 - val_accuracy: 0.8514\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8726 - val_loss: 0.3503 - val_accuracy: 0.8514\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8809 - val_loss: 0.3494 - val_accuracy: 0.8545\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8586 - val_loss: 0.3478 - val_accuracy: 0.8545\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8532 - val_loss: 0.3483 - val_accuracy: 0.8669\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8517 - val_loss: 0.3455 - val_accuracy: 0.8607\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8703 - val_loss: 0.3443 - val_accuracy: 0.8700\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8641 - val_loss: 0.3431 - val_accuracy: 0.8607\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8591 - val_loss: 0.3421 - val_accuracy: 0.8638\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8537 - val_loss: 0.3411 - val_accuracy: 0.8638\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8664 - val_loss: 0.3406 - val_accuracy: 0.8576\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8697 - val_loss: 0.3387 - val_accuracy: 0.8669\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8660 - val_loss: 0.3375 - val_accuracy: 0.8669\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8834 - val_loss: 0.3366 - val_accuracy: 0.8700\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8597 - val_loss: 0.3373 - val_accuracy: 0.8576\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8766 - val_loss: 0.3344 - val_accuracy: 0.8700\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8596 - val_loss: 0.3331 - val_accuracy: 0.8700\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8933 - val_loss: 0.3322 - val_accuracy: 0.8762\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8687 - val_loss: 0.3303 - val_accuracy: 0.8669\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8462 - val_loss: 0.3292 - val_accuracy: 0.8669\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2855 - accuracy: 0.8845 - val_loss: 0.3274 - val_accuracy: 0.8669\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8725 - val_loss: 0.3258 - val_accuracy: 0.8669\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.9053 - val_loss: 0.3242 - val_accuracy: 0.8669\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8609 - val_loss: 0.3228 - val_accuracy: 0.8700\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8692 - val_loss: 0.3212 - val_accuracy: 0.8700\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8786 - val_loss: 0.3199 - val_accuracy: 0.8700\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8470 - val_loss: 0.3187 - val_accuracy: 0.8700\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8475 - val_loss: 0.3169 - val_accuracy: 0.8700\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8708 - val_loss: 0.3160 - val_accuracy: 0.8731\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8906 - val_loss: 0.3153 - val_accuracy: 0.8793\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.9029 - val_loss: 0.3144 - val_accuracy: 0.8824\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8601 - val_loss: 0.3122 - val_accuracy: 0.8793\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8816 - val_loss: 0.3109 - val_accuracy: 0.8731\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8784 - val_loss: 0.3091 - val_accuracy: 0.8731\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8718 - val_loss: 0.3089 - val_accuracy: 0.8854\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8849 - val_loss: 0.3076 - val_accuracy: 0.8885\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8797 - val_loss: 0.3059 - val_accuracy: 0.8824\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8706 - val_loss: 0.3043 - val_accuracy: 0.8793\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8935 - val_loss: 0.3032 - val_accuracy: 0.8824\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8916 - val_loss: 0.3016 - val_accuracy: 0.8854\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8995 - val_loss: 0.3000 - val_accuracy: 0.8824\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.8973 - val_loss: 0.3005 - val_accuracy: 0.8824\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8784 - val_loss: 0.2980 - val_accuracy: 0.8885\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.9080 - val_loss: 0.2969 - val_accuracy: 0.8854\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8836 - val_loss: 0.2951 - val_accuracy: 0.8854\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.8989 - val_loss: 0.2939 - val_accuracy: 0.8854\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8659 - val_loss: 0.2942 - val_accuracy: 0.8854\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8964 - val_loss: 0.2916 - val_accuracy: 0.8854\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8917 - val_loss: 0.2906 - val_accuracy: 0.8854\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8593 - val_loss: 0.2890 - val_accuracy: 0.8885\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8982 - val_loss: 0.2894 - val_accuracy: 0.8916\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.9147 - val_loss: 0.2875 - val_accuracy: 0.8947\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8877 - val_loss: 0.2868 - val_accuracy: 0.8854\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.8759 - val_loss: 0.2849 - val_accuracy: 0.8885\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.8957 - val_loss: 0.2867 - val_accuracy: 0.8916\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8870 - val_loss: 0.2819 - val_accuracy: 0.8947\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.9027 - val_loss: 0.2823 - val_accuracy: 0.8947\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8768 - val_loss: 0.2807 - val_accuracy: 0.8947\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8943 - val_loss: 0.2805 - val_accuracy: 0.8978\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9125 - val_loss: 0.2788 - val_accuracy: 0.8978\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8863 - val_loss: 0.2793 - val_accuracy: 0.9009\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 323, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 323, 4), dtype=tf.float32, name='dense_36_input'), name='dense_36_input', description=\"created by layer 'dense_36_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    }
   ],
   "source": [
    "df_columns = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "t_enm_mlp_df = pd.DataFrame(columns=df_columns)\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    enm_mlp, model = ensemble_mlp()\n",
    "    t_enm_mlp_df = pd.concat([t_enm_mlp_df, enm_mlp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble mlp\n",
      "[0.8507, 0.8447, 0.8473, 0.9294, 9.2096, 1.2085]\n",
      "[0.0086, 0.0183, 0.0136, 0.0066, 5.1218, 0.0751]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>23.7007</td>\n",
       "      <td>1.3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>6.8948</td>\n",
       "      <td>1.1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.8403</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>8.6947</td>\n",
       "      <td>1.2303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>7.1710</td>\n",
       "      <td>1.1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>7.3374</td>\n",
       "      <td>1.1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>0.8487</td>\n",
       "      <td>0.9292</td>\n",
       "      <td>7.6476</td>\n",
       "      <td>1.1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>7.3903</td>\n",
       "      <td>1.1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8305</td>\n",
       "      <td>0.8002</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>7.1636</td>\n",
       "      <td>1.1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8513</td>\n",
       "      <td>0.8431</td>\n",
       "      <td>0.8470</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>7.7451</td>\n",
       "      <td>1.1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8609</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>8.3512</td>\n",
       "      <td>1.3293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision  Recall  F1 score     AUC  Train time  Test time\n",
       "0     0.8508  0.8529    0.8519  0.9264     23.7007     1.3570\n",
       "1     0.8571  0.8390    0.8473  0.9284      6.8948     1.1576\n",
       "2     0.8497  0.8403    0.8448  0.9191      8.6947     1.2303\n",
       "3     0.8507  0.8533    0.8520  0.9266      7.1710     1.1470\n",
       "4     0.8588  0.8547    0.8567  0.9357      7.3374     1.1729\n",
       "5     0.8527  0.8450    0.8487  0.9292      7.6476     1.1960\n",
       "6     0.8446  0.8459    0.8453  0.9264      7.3903     1.1686\n",
       "7     0.8305  0.8002    0.8131  0.9407      7.1636     1.1543\n",
       "8     0.8513  0.8431    0.8470  0.9239      7.7451     1.1724\n",
       "9     0.8609  0.8721    0.8662  0.9375      8.3512     1.3293"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Ensemble mlp')\n",
    "metrics_name = ['Precision', 'Recall', 'F1 score', 'AUC', 'Train time', 'Test time']\n",
    "mean_mlp = []\n",
    "std_mlp = []\n",
    "for each in metrics_name:\n",
    "    mean_mlp.append(round(t_enm_mlp_df[each].mean(), ndigits=4))\n",
    "    std_mlp.append(round(t_enm_mlp_df[each].std(), ndigits=4))\n",
    "print(mean_mlp)\n",
    "print(std_mlp)\n",
    "t_enm_mlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
